{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0SR8V5vFwuIQwbj/0lKJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/B(semantic_vectors).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 1: semantic vectors"
      ],
      "metadata": {
        "id": "WJyYifF-r6GA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Was4MPLrWiS"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "import gensim.downloader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "alternative model : fasttext model\n",
        "\n",
        "```\n",
        "!wget 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip'\n",
        "!unzip \"/content/crawl-300d-2M.vec.zip\" -d \"/content/\"\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('./crawl-300d-2M.vec', binary=False)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "xvnn-c6q8Oc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(gensim.downloader.info()['models'].keys()))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOR117KpsvEC",
        "outputId": "76db7590-93c8-4cde-8124-a79309eaa2eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the 'word2vec-google-news-300' embeddings\n",
        "word2vec = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "vNdSNKmosqi9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload log templates\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/HDFS_templates.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODZw-aljwWms",
        "outputId": "093334fb-8f1c-4966-e973-40a867527726"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-23 12:39:03--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/HDFS_templates.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4522 (4.4K) [text/plain]\n",
            "Saving to: ‘HDFS_templates.csv’\n",
            "\n",
            "\rHDFS_templates.csv    0%[                    ]       0  --.-KB/s               \rHDFS_templates.csv  100%[===================>]   4.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-23 12:39:04 (35.8 MB/s) - ‘HDFS_templates.csv’ saved [4522/4522]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read log templates file into a DataFrame\n",
        "df = pd.read_csv('/content/HDFS_templates.csv')\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ZPSOCzd-uVjJ",
        "outputId": "56f9d3a6-a516-4e8a-a584-ce653a89d231"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    EventId                             EventTemplate  Occurrences\n",
              "0  09a53393    Receiving block <*> src: <*> dest: <*>      1723232\n",
              "1  3d91fa85  BLOCK* NameSystem.allocateBlock: <*> <*>       575061\n",
              "2  d38aa58d     PacketResponder <*> for block <*> <*>      1706728"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-54c3d8dd-a497-4bd1-9d7c-ba6d716f23a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EventId</th>\n",
              "      <th>EventTemplate</th>\n",
              "      <th>Occurrences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>09a53393</td>\n",
              "      <td>Receiving block &lt;*&gt; src: &lt;*&gt; dest: &lt;*&gt;</td>\n",
              "      <td>1723232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3d91fa85</td>\n",
              "      <td>BLOCK* NameSystem.allocateBlock: &lt;*&gt; &lt;*&gt;</td>\n",
              "      <td>575061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d38aa58d</td>\n",
              "      <td>PacketResponder &lt;*&gt; for block &lt;*&gt; &lt;*&gt;</td>\n",
              "      <td>1706728</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54c3d8dd-a497-4bd1-9d7c-ba6d716f23a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0ae4040b-a104-4cdc-a2b3-e4cb67fa80b4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ae4040b-a104-4cdc-a2b3-e4cb67fa80b4')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0ae4040b-a104-4cdc-a2b3-e4cb67fa80b4 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54c3d8dd-a497-4bd1-9d7c-ba6d716f23a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54c3d8dd-a497-4bd1-9d7c-ba6d716f23a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "templates = df['EventTemplate'].tolist()\n",
        "templates[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvG_7oXWt8TS",
        "outputId": "a1df7298-a7f2-407f-af8d-aa29fa308aee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Receiving block <*> src: <*> dest: <*>',\n",
              " 'BLOCK* NameSystem.allocateBlock: <*> <*>',\n",
              " 'PacketResponder <*> for block <*> <*>']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# we keep some stop words such as on, over, not, .. which can have significant meaning\n",
        "stop_words = {\n",
        "    'a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren',\n",
        "    \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by',\n",
        "    'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don',\n",
        "    \"don't\", 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\",\n",
        "    'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how',\n",
        "    'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me',\n",
        "    'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'nor', 'now', 'o',\n",
        "    'of', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'own', 're', 's', 'same', 'shan',\n",
        "    \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than',\n",
        "    'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this',\n",
        "    'those', 'through', 'to', 'too', 'until', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren',\n",
        "    \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\",\n",
        "    'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself',\n",
        "    'yourselves'\n",
        "}\n",
        "\n",
        "# Pre-compiling the regular expression pattern using re.compile() can improve the performance of the regular expression operations\n",
        "pattern = re.compile(r'\\W+|\\d')"
      ],
      "metadata": {
        "id": "3axd_hbZt9hA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized(text):\n",
        "    \"\"\"\n",
        "    Normalize text to extract most salient tokens\n",
        "    \"\"\"\n",
        "    # Replace special characters with space and remove digits\n",
        "    text = pattern.sub(' ', text)\n",
        "\n",
        "    # Convert camel case to snake case, then replace _ with space\n",
        "    text = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', text)\n",
        "    text = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', text).lower().replace('_', ' ')\n",
        "\n",
        "    normalized_tokens = [w for w in text.split() if w not in stop_words]\n",
        "\n",
        "    # Return the filtered sentence, our output will be sentences not a list of words\n",
        "    return ' '.join(normalized_tokens)\n"
      ],
      "metadata": {
        "id": "hOK9roIEuAdb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_template = [tokenized(sentence) for sentence in df['EventTemplate'] ]\n",
        "print(tokenized_template[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5QR7lO8uC3N",
        "outputId": "b39fe16b-a606-4967-e5e2-24a4a11fa0cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['receiving block src dest', 'block name system allocate block', 'packet responder block']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTANT POINTS :\n",
        "\n",
        "1 . this model, word2vec_model.get_vector(word) can gives vector for any meaningless word\n",
        "\n",
        "2 . TfidfVectorizer is more commonly used as it combines tokenization and TF-IDF transformation in a single step, making it easier to use for most text tasks. On the other hand, TfidfTransformer is useful when you already have a matrix of term frequencies and want to compute the corresponding TF-IDF matrix. If you have a collection of text documents and want to obtain their TF-IDF representation, it is more straightforward to use TfidfVectorizer.\n",
        "\n",
        "3 . because matrix_weight , are normalized , we dont need for each template, we get the mean of the vectors we sum\n",
        "\n",
        "4 . we use strategy = 'average' in situation we have new template which we havent seen before\n",
        "\n",
        "5 . some points about normalizing word2vec(because of them we dont normalize) :\n",
        "\n",
        "Vectors are normalized to unit length before they are used for similarity calculation, making cosine similarity and dot-product equivalent. Most applications of word embeddings explore not the word vectors themselves, but relations between them to solve, for example, similarity and word relation tasks. For these tasks, it was found that using normalised word vectors improves performance. Word vector length is therefore typically ignored. A word that is consistently used in a similar context will be represented by a longer vector than a word of the same frequency that is used in different contexts(two same meaning words , have same angle but the size depends on ferequency). Not only the direction, but also the length of word vectors carries important information. Word vector length furnishes, in combination with term frequency, a useful measure of word significance.\n",
        "\n",
        "6 . with the methode of tfidf, we find importance of words based on avaible templates not in general"
      ],
      "metadata": {
        "id": "p4zcaE7as3wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings(templates, strategy = 'tfidf'):\n",
        "  \"\"\"\n",
        "  Generate embeddings for templates using fasttext\n",
        "  Parameters\n",
        "  ----------\n",
        "  templates: list of templates\n",
        "  strategy: average or tfidf\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  embeddings: dict of embeddings\n",
        "  \"\"\"\n",
        "\n",
        "  cleaned_templates = [tokenized(template) for template in templates]\n",
        "\n",
        "  embedding_shape = word2vec.get_vector('word').shape\n",
        "  num_templates = len(cleaned_templates)\n",
        "  embeddings = np.zeros((num_templates, embedding_shape[0]))\n",
        "\n",
        "  if strategy == 'average':\n",
        "    for i, cleaned_template in enumerate(cleaned_templates):\n",
        "        words = cleaned_template.split()\n",
        "        word_count = len(words)\n",
        "        vector = np.zeros(embedding_shape)  # Initialize the vector with zeros\n",
        "\n",
        "        for word in words:\n",
        "            if word in word2vec:   # if the word not in model, we ignore\n",
        "                vector += word2vec[word]\n",
        "\n",
        "        vector /= (word_count if word_count > 0 else 1)\n",
        "        embeddings[i] = vector.tolist()\n",
        "\n",
        "  elif strategy == 'tfidf':\n",
        "\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    matrix_weight = vectorizer.fit_transform(cleaned_templates)\n",
        "    dic = vectorizer.vocabulary_\n",
        "\n",
        "    for i, cleaned_template in enumerate(cleaned_templates):\n",
        "        vector = np.zeros(embedding_shape)\n",
        "        for word in cleaned_template.split():\n",
        "            if word in word2vec:   # if the word not in model(meaningless words), we ignore\n",
        "              j = dic.get(word)  # If the key is not present, dic.get(word)(or dic.get(word, default_value)) will return None (or any default value you provide), while dic[word] will raise a KeyError if the key is not found.\n",
        "              if j is not None:\n",
        "                  vector += matrix_weight[i, j] * word2vec[word]\n",
        "\n",
        "        embeddings[i] = vector\n",
        "\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "bniXqQGFs4u0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate semantic vectors from templates\n",
        "embeddings = generate_embeddings(templates)\n",
        "embeddings[0].shape\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fA62IcAtH5L",
        "outputId": "3f2ae20a-1141-4e9f-f333-100edb495eac"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save semantic vectors\n",
        "with open('/content/embeddings_tfidf.json', 'w') as f:\n",
        "        json.dump(embeddings.tolist(), f)"
      ],
      "metadata": {
        "id": "zSvaNr1XtLSj"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 1.2: PCA"
      ],
      "metadata": {
        "id": "-gAQ_N7lvHsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "with open('/content/embeddings_tfidf.json') as f:\n",
        "    gdp_list = json.load(f)\n",
        "    embeddings = list(gdp_list.values())\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "t8STDVKo5AjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "WYvWx4DtvmY0"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dim_reduction(vectors, n_components=20):\n",
        "    estimator = PCA(n_components)\n",
        "    pca_result = estimator.fit_transform(vectors)\n",
        "    print('the percentage of variance for 20D : ', sum(estimator.explained_variance_ratio_ * 100))\n",
        "\n",
        "    # Step1-3 PPA: De-averaged\n",
        "    ppa_result = []\n",
        "    result = pca_result - np.mean(pca_result)\n",
        "    pca = PCA(n_components=20)\n",
        "    pca_result = pca.fit_transform(result)\n",
        "    U = pca.components_\n",
        "    for i, x in enumerate(result):\n",
        "        for u in U[0:7]:\n",
        "            x = x - np.dot(u.transpose(), x) * u\n",
        "        ppa_result.append(list(x))\n",
        "    ppa_result = np.array(ppa_result)\n",
        "\n",
        "    return ppa_result"
      ],
      "metadata": {
        "id": "ZxxpyFzMxz78"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('shape : ', dim_reduction(embeddings).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l2bnhHF4zjp",
        "outputId": "629d572b-07da-4a12-fb51-4edc4b2def49"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the percentage of variance for 20D :  93.05414073077046\n",
            "shape :  (48, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save semantic vectors\n",
        "with open('/content/embeddings_tfidf_pca.json', 'w') as f:\n",
        "        json.dump(dim_reduction(embeddings).tolist(), f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzBWOSqW5Xso",
        "outputId": "52540893-ba8f-46f7-9761-360acdb7a458"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the percentage of variance for 20D :  93.05414073077046\n"
          ]
        }
      ]
    }
  ]
}