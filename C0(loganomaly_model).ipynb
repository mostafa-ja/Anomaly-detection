{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiY3bN5n0CqCNg1XAweRTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/C0(loganomaly_model).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "-cgjPvYjFbKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download datasets\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_train'\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_normal'\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_abnormal'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZYNqcwLIPLF",
        "outputId": "2af8adbf-dddd-4e05-c4a2-8cfb86cd0b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-26 07:37:15--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257875 (252K) [text/plain]\n",
            "Saving to: ‘hdfs_train’\n",
            "\n",
            "hdfs_train          100%[===================>] 251.83K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-26 07:37:15 (7.45 MB/s) - ‘hdfs_train’ saved [257875/257875]\n",
            "\n",
            "--2023-07-26 07:37:15--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_normal\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29284282 (28M) [text/plain]\n",
            "Saving to: ‘hdfs_test_normal’\n",
            "\n",
            "hdfs_test_normal    100%[===================>]  27.93M   135MB/s    in 0.2s    \n",
            "\n",
            "2023-07-26 07:37:16 (135 MB/s) - ‘hdfs_test_normal’ saved [29284282/29284282]\n",
            "\n",
            "--2023-07-26 07:37:16--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_abnormal\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 782479 (764K) [text/plain]\n",
            "Saving to: ‘hdfs_test_abnormal’\n",
            "\n",
            "hdfs_test_abnormal  100%[===================>] 764.14K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-07-26 07:37:16 (13.4 MB/s) - ‘hdfs_test_abnormal’ saved [782479/782479]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count session for each dataset\n",
        "\n",
        "def count_sessions(dataset):\n",
        "    num_sessions = 0\n",
        "    with open('/content/'+ dataset, 'r') as f:\n",
        "        for row in f:\n",
        "            num_sessions += 1\n",
        "    print('Number of sessions({}): {}'.format(dataset, num_sessions))\n",
        "\n",
        "datasets = ['hdfs_train','hdfs_test_normal','hdfs_test_abnormal']\n",
        "\n",
        "for dataset in datasets:\n",
        "  count_sessions(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaCB9o7erHFe",
        "outputId": "a6024334-91d7-49cf-c777-dcaceb6fdf3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_train): 4855\n",
            "Number of sessions(hdfs_test_normal): 553366\n",
            "Number of sessions(hdfs_test_abnormal): 16838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all templates in our datasets\n",
        "\n",
        "datasets = ['hdfs_train','hdfs_test_normal','hdfs_test_abnormal']\n",
        "templates = set()\n",
        "\n",
        "for dataset in datasets:\n",
        "  with open('/content/' + dataset, 'r') as f:\n",
        "          for row in f:\n",
        "            for temp in row.split():\n",
        "              templates.add(temp)\n",
        "\n",
        "print(sorted(templates))\n",
        "print('nember of templates : ',len(templates))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNDAhBmpwKSs",
        "outputId": "5a0be0be-4224-477f-af89-08dc923ebaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '3', '4', '5', '6', '7', '8', '9']\n",
            "nember of templates :  28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'hdfs_train'\n",
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            num_sessions += 1\n",
        "            line = [ (int(i)-1) for i in row.strip().split()]\n",
        "            for i in range(len(line) - window_size):\n",
        "                inputs.append(line[i:i + window_size])\n",
        "                outputs.append(line[i + window_size])\n",
        "\n",
        "print('Number of sessions({}): {}'.format(name, num_sessions))\n",
        "print('Number of seqs({}): {}'.format(name, len(inputs)))\n",
        "dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1P4keFzwKDn",
        "outputId": "3335c0eb-639f-4aac-ba53-090d25a97a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_train): 4855\n",
            "Number of seqs(hdfs_train): 46575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1)\n",
        "for seq, label in dataloader:\n",
        "  print(seq)\n",
        "  print(label)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVPNtxoaL6Ol",
        "outputId": "bc9e6eaf-0cd5-4edf-9613-760b02e57a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4.,  4.,  4., 21., 10.,  8., 10.,  8., 10.,  8.]])\n",
            "tensor([25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter([1, 2, 1, 5, 8, 4, 2, 3, 1])\n",
        "seq1 = [0] * 28\n",
        "log_conuter = Counter(seq0)\n",
        "for key in log_conuter:\n",
        "    seq1[key] = log_conuter[key]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZbVs_Ns-YgY",
        "outputId": "e9084ab9-d8b9-4994-8ca6-4b37e3f548e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 3, 2: 2, 5: 1, 8: 1, 4: 1, 3: 1})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sequential_pattern = [1, 2, 1, 5, 8, 4, 2, 3, 1]\n",
        "np.array(Sequential_pattern)[:, np.newaxis]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wY9jOGuHOLx",
        "outputId": "a7681b47-b080-4846-aa18-a18d2f6d1af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [5],\n",
              "       [8],\n",
              "       [4],\n",
              "       [2],\n",
              "       [3],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sequential_pattern = [1, 2, 1, 5, 8, 4, 2, 3, 1]\n",
        "Quantitative_pattern = [0] * 10  #0 to 9\n",
        "log_counter = Counter(Sequential_pattern)\n",
        "for key in log_counter:\n",
        "    Quantitative_pattern[key] = log_counter[key]\n",
        "np.array(Quantitative_pattern)[:, np.newaxis]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThQv2AixHpSs",
        "outputId": "3d914f67-189c-4746-8d3a-952be72b55f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [3],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import json\n",
        "#def read_json(filename):\n",
        "    #with open(filename, 'r') as load_f:\n",
        "        #file_dict = json.load(load_f)\n",
        "    #return file_dict\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def sliding_window(data_dir, window_size):\n",
        "    '''\n",
        "    dataset structure\n",
        "        result_logs(dict):\n",
        "            result_logs['feature0'] = list()\n",
        "            result_logs['feature1'] = list()\n",
        "            ...\n",
        "        labels(list)\n",
        "    '''\n",
        "    #event2semantic_vec = read_json(data_dir + 'hdfs/event2semantic_vec.json')\n",
        "    num_sessions = 0\n",
        "    result_logs = {}\n",
        "    result_logs['Sequentials'] = []\n",
        "    result_logs['Quantitatives'] = []\n",
        "    #result_logs['Semantics'] = []\n",
        "    labels = []\n",
        "\n",
        "    with open(data_dir, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            num_sessions += 1\n",
        "            line = [(int(i)-1) for i in line.strip().split()]\n",
        "            for i in range(len(line) - window_size):\n",
        "\n",
        "                Sequential_pattern = list(line[i:i + window_size])\n",
        "\n",
        "                Quantitative_pattern = [0] * 28  # 28 templates we have\n",
        "                log_counter = Counter(Sequential_pattern)\n",
        "                for key in log_counter:\n",
        "                    Quantitative_pattern[key] = log_counter[key]\n",
        "\n",
        "                #Semantic_pattern = []\n",
        "                #for event in Sequential_pattern:\n",
        "                    #if event == 0:\n",
        "                        #Semantic_pattern.append([-1] * 300)\n",
        "                    #else:\n",
        "                        #Semantic_pattern.append(event2semantic_vec[str(event - 1)])\n",
        "\n",
        "                #Sequential_pattern = np.array(Sequential_pattern)[:, np.newaxis]\n",
        "                #Quantitative_pattern = np.array(Quantitative_pattern)[:, np.newaxis]\n",
        "                result_logs['Sequentials'].append(Sequential_pattern)\n",
        "                result_logs['Quantitatives'].append(Quantitative_pattern)\n",
        "                #result_logs['Semantics'].append(Semantic_pattern)\n",
        "\n",
        "                labels.append(line[i + window_size])\n",
        "\n",
        "    print('File {}, number of sessions {}'.format(data_dir, num_sessions))\n",
        "    print('File {}, number of seqs {}'.format(data_dir, len(result_logs['Sequentials'])))\n",
        "\n",
        "    return result_logs, labels\n"
      ],
      "metadata": {
        "id": "eZfqkQCoBqMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_logs, labels = sliding_window('/content/hdfs_train', 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpio7sLuIQzV",
        "outputId": "e4e7470c-f20c-43d1-e082-27abfa583c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /content/hdfs_train, number of sessions 4855\n",
            "File /content/hdfs_train, number of seqs 46575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_logs['Sequentials'][0])\n",
        "print(result_logs['Quantitatives'][0])\n",
        "print(labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ribwaCGTKMDP",
        "outputId": "0911d0b1-8c6a-45d1-9416-62b386fb7707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 4, 4, 21, 10, 8, 10, 8, 10, 8]\n",
            "[0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(torch.tensor(result_logs['Sequentials'], dtype=torch.float), torch.tensor(labels))\n",
        "dataloader = DataLoader(dataset, batch_size=1)\n",
        "for seq, label in dataloader:\n",
        "  print(seq)\n",
        "  print(label)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SXIwQWwMZSS",
        "outputId": "827be171-7c72-4521-a185-d74b066a1c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4.,  4.,  4., 21., 10.,  8., 10.,  8., 10.,  8.]])\n",
            "tensor([25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(torch.tensor(result_logs['Sequentials'], dtype=torch.float), torch.tensor(result_logs['Quantitatives'], dtype=torch.float), torch.tensor(labels))\n",
        "dataloader = DataLoader(dataset, batch_size=1)\n",
        "for seq,quan, label in dataloader:\n",
        "  print(seq)\n",
        "  print(quan)\n",
        "  print(label)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHJ6J37wNEPV",
        "outputId": "1eacdfff-2287-428a-c916-b7c8ae2cc448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4.,  4.,  4., 21., 10.,  8., 10.,  8., 10.,  8.]])\n",
            "tensor([[0., 0., 0., 0., 3., 0., 0., 0., 3., 0., 3., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "class loganomaly(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
        "        super(loganomaly, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm0 = nn.LSTM(input_size,\n",
        "                             hidden_size,\n",
        "                             num_layers,\n",
        "                             batch_first=True)\n",
        "        self.lstm1 = nn.LSTM(input_size,\n",
        "                             hidden_size,\n",
        "                             num_layers,\n",
        "                             batch_first=True)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_keys)\n",
        "        self.attention_size = self.hidden_size\n",
        "\n",
        "        self.w_omega = Variable(\n",
        "            torch.zeros(self.hidden_size, self.attention_size))\n",
        "        self.u_omega = Variable(torch.zeros(self.attention_size))\n",
        "\n",
        "        self.sequence_length = 28\n",
        "\n",
        "    def attention_net(self, lstm_output):\n",
        "        output_reshape = torch.Tensor.reshape(lstm_output,\n",
        "                                              [-1, self.hidden_size])\n",
        "        attn_tanh = torch.tanh(torch.mm(output_reshape, self.w_omega))\n",
        "        attn_hidden_layer = torch.mm(\n",
        "            attn_tanh, torch.Tensor.reshape(self.u_omega, [-1, 1]))\n",
        "        exps = torch.Tensor.reshape(torch.exp(attn_hidden_layer),\n",
        "                                    [-1, self.sequence_length])\n",
        "        alphas = exps / torch.Tensor.reshape(torch.sum(exps, 1), [-1, 1])\n",
        "        alphas_reshape = torch.Tensor.reshape(alphas,\n",
        "                                              [-1, self.sequence_length, 1])\n",
        "        state = lstm_output\n",
        "        attn_output = torch.sum(state * alphas_reshape, 1)\n",
        "        return attn_output\n",
        "\n",
        "    def forward(self, features, device):\n",
        "        input0, input1 = features[0], features[1]\n",
        "\n",
        "        h0_0 = torch.zeros(self.num_layers, input0.size(0),\n",
        "                           self.hidden_size).to(device)\n",
        "        c0_0 = torch.zeros(self.num_layers, input0.size(0),\n",
        "                           self.hidden_size).to(device)\n",
        "\n",
        "        out0, _ = self.lstm0(input0, (h0_0, c0_0))\n",
        "\n",
        "        h0_1 = torch.zeros(self.num_layers, input1.size(0),\n",
        "                           self.hidden_size).to(device)\n",
        "        c0_1 = torch.zeros(self.num_layers, input1.size(0),\n",
        "                           self.hidden_size).to(device)\n",
        "\n",
        "        out1, _ = self.lstm1(input1, (h0_1, c0_1))\n",
        "        multi_out = torch.cat((out0[:, -1, :], out1[:, -1, :]), -1)\n",
        "        out = self.fc(multi_out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "v3DBDvgg7P7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 1\n",
        "num_layers = 2\n",
        "hidden_size = 64\n",
        "num_classes = 28  # templates\n",
        "batch_size = 2048\n",
        "num_epochs = 375"
      ],
      "metadata": {
        "id": "R0ht4IKd2QFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = loganomaly(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "Ve9GNCW-2zDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, lr_step=(300, 350), lr_decay_ratio=0.1):\n",
        "    \"\"\"Adjust the learning rate based on the epoch number.\"\"\"\n",
        "    if epoch == 0:\n",
        "        optimizer.param_groups[0]['lr'] /= 32\n",
        "    elif epoch in [1, 2, 3, 4, 5]:  # in step five , we finish warm up ,and start normal learning rate\n",
        "        optimizer.param_groups[0]['lr'] *= 2\n",
        "    if epoch in lr_step: # in these steps , we are geting close to optimal point so we need to have shorter step\n",
        "        optimizer.param_groups[0]['lr'] *= lr_decay_ratio\n",
        "    return optimizer\n",
        "\n",
        "# Define options here\n",
        "options = {\n",
        "    'lr': 0.001,\n",
        "    'lr_step': (300, 350), #steps(epoch) for updating learning rate\n",
        "    'lr_decay_ratio': 0.1,\n",
        "    # Add other options here\n",
        "}\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=options['lr'], betas=(0.9, 0.999))\n"
      ],
      "metadata": {
        "id": "54g6LFd-IkwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "total_step = len(dataloader)\n",
        "for epoch in range(num_epochs):  # Loop over the dataset multiple times\n",
        "    optimizer = adjust_learning_rate(optimizer, epoch, options['lr_step'], options['lr_decay_ratio'])\n",
        "    print(optimizer.param_groups[0]['lr'])\n",
        "    train_loss = 0\n",
        "    for step, (seq,quan,label) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        print('seq : ',seq.shape)\n",
        "        print('quan : ',quan.shape)\n",
        "        seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
        "        quan = quan.clone().detach().view(-1, 28, input_size).to(device)\n",
        "        print('after')\n",
        "        print('seq : ',seq.shape)\n",
        "        print('quan : ',quan.shape)\n",
        "        break\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcGWPHLlTqbU",
        "outputId": "31484f8a-29ed-49e9-e1f0-77a3b62a772a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.862645149230957e-12\n",
            "seq :  torch.Size([2048, 10])\n",
            "quan :  torch.Size([2048, 28])\n",
            "after\n",
            "seq :  torch.Size([2048, 10, 1])\n",
            "quan :  torch.Size([2048, 28, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "total_step = len(dataloader)\n",
        "for epoch in range(num_epochs):  # Loop over the dataset multiple times\n",
        "    optimizer = adjust_learning_rate(optimizer, epoch, options['lr_step'], options['lr_decay_ratio'])\n",
        "    print(optimizer.param_groups[0]['lr'])\n",
        "    train_loss = 0\n",
        "    for step, (seq,quan,label) in enumerate(dataloader):\n",
        "        # Move data to the device\n",
        "        seq = seq.view(-1, window_size, input_size).to(device)\n",
        "        quan = quan.view(-1, 28, input_size).to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(features=(seq, quan), device=device)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss / total_step))\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "A5NxknEJTzNi",
        "outputId": "09e7055f-0c0b-486d-a879-386151a98000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8189894035458565e-15\n",
            "Epoch [1/375], train_loss: 3.3293\n",
            "3.637978807091713e-15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-74aaf56793c9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsa9Wiv-OUfq",
        "outputId": "dacf1c90-0603-428d-9649-87ba25602d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/HDFS/LSTM_model_parameter')"
      ],
      "metadata": {
        "id": "qVHEFEB4NqVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# upload the model\n",
        "model_path = '/content/drive/MyDrive/LSTM_model_parameter'\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "id": "pA_FNHo7ORnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(name):\n",
        "    window_size = 10\n",
        "    hdfs = {} #store the unique sequences and their counts.\n",
        "    length = 0\n",
        "    with open('/content/' + name, 'r') as f:\n",
        "        for ln in f.readlines():\n",
        "            ln = [(int(i)-1) for i in ln.strip().split()]\n",
        "            ln = ln + [-1] * (window_size + 1 - len(ln))     #ensure that all sequences have a fixed length of window_size + 1, even if the original line had fewer elements.\n",
        "            hdfs[tuple(ln)] = hdfs.get(tuple(ln), 0) + 1   #If the tuple is not present in the dictionary, hdfs.get(tuple(ln), 0) returns 0, and the code initializes the count to 1.\n",
        "            length += 1\n",
        "    print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
        "    return hdfs, length"
      ],
      "metadata": {
        "id": "ntfFr0QmwD6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_normal_loader, test_normal_length = generate('hdfs_test_normal')\n",
        "test_abnormal_loader, test_abnormal_length = generate('hdfs_test_abnormal')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NnZp1dT75jI",
        "outputId": "a9b6c899-ba86-4f9d-deff-2f15981a8a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_test_normal): 14177\n",
            "Number of sessions(hdfs_test_abnormal): 4123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in test_normal_loader.keys():\n",
        "  print(i)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsaf82Bqz1qK",
        "outputId": "6d6be1a7-a98e-4921-8201-111a5e1930f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 4, 4, 21, 10, 8, 10, 8, 10, 8, 25, 25, 25, 22, 22, 22, 20, 20, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_candidates = 9 # on paper is g , top-g(here top 9) probabilities to appear next are considered normal"
      ],
      "metadata": {
        "id": "dSDO2VmH8dRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "\n",
        "TP = 0\n",
        "FP = 0\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for line in test_normal_loader.keys():\n",
        "        for i in range(len(line) - window_size):\n",
        "            seq = line[i:i + window_size]\n",
        "            label = line[i + window_size]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            label = torch.tensor(label).view(-1).to(device)\n",
        "            output = model(seq)\n",
        "            predicted = torch.argsort(output, 1)[0][-num_candidates:]\n",
        "            if label not in predicted:\n",
        "                FP += test_normal_loader[line] # numbers of that set we have\n",
        "                break   #with just one wrong prediction in a line , we assume , abnormal\n",
        "with torch.no_grad():\n",
        "    for line in test_abnormal_loader.keys():\n",
        "        for i in range(len(line) - window_size):\n",
        "            seq = line[i:i + window_size]\n",
        "            label = line[i + window_size]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            label = torch.tensor(label).view(-1).to(device)\n",
        "            output = model(seq)\n",
        "            predicted = torch.argsort(output, 1)[0][-num_candidates:]\n",
        "            if label not in predicted:\n",
        "                TP += test_abnormal_loader[line]\n",
        "                break\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "# Compute precision, recall and F1-measure\n",
        "FN = test_abnormal_length - TP\n",
        "P = 100 * TP / (TP + FP)\n",
        "R = 100 * TP / (TP + FN)\n",
        "F1 = 2 * P * R / (P + R)\n",
        "print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
        "print('Finished Predicting')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIDRTh2-8ASi",
        "outputId": "b729cf78-5247-41b7-93e3-90178d94bec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 101.217s\n",
            "false positive (FP): 903, false negative (FN): 254, Precision: 94.836%, Recall: 98.492%, F1-measure: 96.629%\n",
            "Finished Predicting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TP)\n",
        "print(FN)\n",
        "print(FP)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwoQNRr0dfJm",
        "outputId": "bb9183d6-babf-452f-bd3e-23a5269c014b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16584\n",
            "254\n",
            "903\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1VFDfINdlKy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}