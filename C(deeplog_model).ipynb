{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNu2OHvN1Ey5Zsso+mMwt0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/C(deeplog_model).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        ""
      ],
      "metadata": {
        "id": "-cgjPvYjFbKo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdKXioxBmcc",
        "outputId": "53947927-3bb6-4a39-f14c-faca73454ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to upload datasets (csv files)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import train and datasets based on ratio\n",
        "\n",
        "def split_log_file(input_file, train_ratio=0.7):\n",
        "    # Read the log file and split it into lines\n",
        "    with open(input_file, 'r') as log_file:\n",
        "        log_lines = log_file.readlines()\n",
        "\n",
        "    # Calculate the number of lines for the train and test sets\n",
        "    num_lines = len(log_lines)\n",
        "    num_train_lines = int(num_lines * train_ratio)\n",
        "    num_test_lines = num_lines - num_train_lines\n",
        "\n",
        "    # Write the lines corresponding to the train set to a new train log file\n",
        "    with open('hdfs_train', 'w') as train_file:\n",
        "        train_file.writelines(log_lines[:num_train_lines])\n",
        "\n",
        "    # Write the remaining lines (test set) to a new test log file\n",
        "    with open('hdfs_test_normal', 'w') as test_file:\n",
        "        test_file.writelines(log_lines[num_train_lines:])\n",
        "\n",
        "# split normal log file\n",
        "split_log_file('/content/drive/MyDrive/HDFS/structured_hdfs/hdfs_sequence_normal', train_ratio=0.1)\n",
        "\n",
        "#copy test abnormal file to current directory\n",
        "!cp '/content/drive/MyDrive/HDFS/structured_hdfs/hdfs_test_sequence_abnormal' '/content/'"
      ],
      "metadata": {
        "id": "p2LHttoEwKMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "alternative files :\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# download datasets\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_train'\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_normal'\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_abnormal'\n",
        "     \n",
        "```\n",
        "be careful these files are logs , not csv\n"
      ],
      "metadata": {
        "id": "Oa9CLMUMGGyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download datasets\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_train'\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_normal'\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_abnormal'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZYNqcwLIPLF",
        "outputId": "5f2139b7-9cda-48f1-c605-641545f81f41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-24 16:04:15--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257875 (252K) [text/plain]\n",
            "Saving to: ‘hdfs_train’\n",
            "\n",
            "\rhdfs_train            0%[                    ]       0  --.-KB/s               \rhdfs_train          100%[===================>] 251.83K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-07-24 16:04:16 (14.4 MB/s) - ‘hdfs_train’ saved [257875/257875]\n",
            "\n",
            "--2023-07-24 16:04:16--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_normal\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29284282 (28M) [text/plain]\n",
            "Saving to: ‘hdfs_test_normal’\n",
            "\n",
            "hdfs_test_normal    100%[===================>]  27.93M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-24 16:04:18 (203 MB/s) - ‘hdfs_test_normal’ saved [29284282/29284282]\n",
            "\n",
            "--2023-07-24 16:04:19--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_abnormal\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 782479 (764K) [text/plain]\n",
            "Saving to: ‘hdfs_test_abnormal’\n",
            "\n",
            "hdfs_test_abnormal  100%[===================>] 764.14K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-24 16:04:19 (22.3 MB/s) - ‘hdfs_test_abnormal’ saved [782479/782479]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count session for each dataset\n",
        "\n",
        "def count_sessions(dataset):\n",
        "    num_sessions = 0\n",
        "    with open('/content/'+ dataset, 'r') as f:\n",
        "        for row in f:\n",
        "            num_sessions += 1\n",
        "    print('Number of sessions({}): {}'.format(dataset, num_sessions))\n",
        "\n",
        "datasets = ['hdfs_train','hdfs_test_normal','hdfs_test_abnormal']\n",
        "\n",
        "for dataset in datasets:\n",
        "  count_sessions(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaCB9o7erHFe",
        "outputId": "34b06767-a6de-46f4-f51c-2ff6b2af4931"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_train): 4855\n",
            "Number of sessions(hdfs_test_normal): 553366\n",
            "Number of sessions(hdfs_test_abnormal): 16838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all templates in our datasets\n",
        "\n",
        "datasets = ['hdfs_train','hdfs_test_normal','hdfs_test_abnormal']\n",
        "templates = set()\n",
        "\n",
        "for dataset in datasets:\n",
        "  with open('/content/' + dataset, 'r') as f:\n",
        "          for row in f:\n",
        "            for temp in row.split():\n",
        "              templates.add(temp)\n",
        "\n",
        "print(sorted(templates))\n",
        "print('nember of templates : ',len(templates))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNDAhBmpwKSs",
        "outputId": "fac11ffc-0491-4fb8-f908-1170ad1b783c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '3', '4', '5', '6', '7', '8', '9']\n",
            "nember of templates :  28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test:\n",
        "\n",
        "\n",
        "```\n",
        "name = 'hdfs_train_sequence'\n",
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            num_sessions += 1\n",
        "            line = [ int(i) for i in row.strip().split()]\n",
        "            print(line)\n",
        "            for i in range(len(line) - window_size):\n",
        "                print(line[i:i + window_size])\n",
        "                print(line[i + window_size])\n",
        "                break\n",
        "            break\n",
        "\n",
        "ans:\n",
        "[0, 1, 0, 0, 2, 2, 3, 3, 2, 3, 4, 4, 4, 5,...]\n",
        "[0, 1, 0, 0, 2, 2, 3, 3, 2, 3]\n",
        "4\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "IXB3Npq912Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'hdfs_train'\n",
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            num_sessions += 1\n",
        "            line = [ int(i) for i in row.strip().split()]\n",
        "            for i in range(len(line) - window_size):\n",
        "                inputs.append(line[i:i + window_size])\n",
        "                outputs.append(line[i + window_size])\n",
        "\n",
        "print('Number of sessions({}): {}'.format(name, num_sessions))\n",
        "print('Number of seqs({}): {}'.format(name, len(inputs)))\n",
        "dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1P4keFzwKDn",
        "outputId": "ecab2db3-7e55-4a44-8658-f43418b4faed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_train): 4855\n",
            "Number of seqs(hdfs_train): 46575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out.shape : [batch_size, sequence_length, hidden_size]\n",
        "        out = self.fc(out[:, -1, :]) #The : before , -1, : indicates that we want to include all elements along the first dimension (batch dimension). -1 represents the index of the last element along the second dimension (sequence length). : after , -1 indicates that we want to include all elements along the third dimension (hidden size)\n",
        "        return out\n",
        ""
      ],
      "metadata": {
        "id": "vVS_BE9S2J2p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 1\n",
        "num_layers = 2\n",
        "hidden_size = 64\n",
        "num_classes = 28  # templates + 1 abnormal output\n",
        "batch_size = 2048\n",
        "num_epochs = 150"
      ],
      "metadata": {
        "id": "R0ht4IKd2QFf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "Ve9GNCW-2zDL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "total_step = len(dataloader)\n",
        "for epoch in range(num_epochs):  # Loop over the dataset multiple times\n",
        "    train_loss = 0\n",
        "    for step, (seq, label) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
        "        output = model(seq)\n",
        "        loss = criterion(output, label.to(device))\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss / total_step))\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MRDa44Rt23Lb",
        "outputId": "a119d5f8-0968-4992-a36e-f7e97c42b63d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/150], train_loss: 2.7101\n",
            "Epoch [2/150], train_loss: 1.8622\n",
            "Epoch [3/150], train_loss: 1.7668\n",
            "Epoch [4/150], train_loss: 1.6340\n",
            "Epoch [5/150], train_loss: 1.4068\n",
            "Epoch [6/150], train_loss: 1.1704\n",
            "Epoch [7/150], train_loss: 0.9617\n",
            "Epoch [8/150], train_loss: 0.8200\n",
            "Epoch [9/150], train_loss: 0.7285\n",
            "Epoch [10/150], train_loss: 0.6682\n",
            "Epoch [11/150], train_loss: 0.6153\n",
            "Epoch [12/150], train_loss: 0.5736\n",
            "Epoch [13/150], train_loss: 0.5403\n",
            "Epoch [14/150], train_loss: 0.5183\n",
            "Epoch [15/150], train_loss: 0.5070\n",
            "Epoch [16/150], train_loss: 0.4896\n",
            "Epoch [17/150], train_loss: 0.4789\n",
            "Epoch [18/150], train_loss: 0.4691\n",
            "Epoch [19/150], train_loss: 0.4584\n",
            "Epoch [20/150], train_loss: 0.4478\n",
            "Epoch [21/150], train_loss: 0.4376\n",
            "Epoch [22/150], train_loss: 0.4236\n",
            "Epoch [23/150], train_loss: 0.4098\n",
            "Epoch [24/150], train_loss: 0.4005\n",
            "Epoch [25/150], train_loss: 0.3917\n",
            "Epoch [26/150], train_loss: 0.3838\n",
            "Epoch [27/150], train_loss: 0.3804\n",
            "Epoch [28/150], train_loss: 0.3728\n",
            "Epoch [29/150], train_loss: 0.3691\n",
            "Epoch [30/150], train_loss: 0.3640\n",
            "Epoch [31/150], train_loss: 0.3619\n",
            "Epoch [32/150], train_loss: 0.3586\n",
            "Epoch [33/150], train_loss: 0.3531\n",
            "Epoch [34/150], train_loss: 0.3495\n",
            "Epoch [35/150], train_loss: 0.3464\n",
            "Epoch [36/150], train_loss: 0.3444\n",
            "Epoch [37/150], train_loss: 0.3420\n",
            "Epoch [38/150], train_loss: 0.3389\n",
            "Epoch [39/150], train_loss: 0.3353\n",
            "Epoch [40/150], train_loss: 0.3345\n",
            "Epoch [41/150], train_loss: 0.3317\n",
            "Epoch [42/150], train_loss: 0.3301\n",
            "Epoch [43/150], train_loss: 0.3277\n",
            "Epoch [44/150], train_loss: 0.3252\n",
            "Epoch [45/150], train_loss: 0.3224\n",
            "Epoch [46/150], train_loss: 0.3243\n",
            "Epoch [47/150], train_loss: 0.3224\n",
            "Epoch [48/150], train_loss: 0.3175\n",
            "Epoch [49/150], train_loss: 0.3158\n",
            "Epoch [50/150], train_loss: 0.3140\n",
            "Epoch [51/150], train_loss: 0.3107\n",
            "Epoch [52/150], train_loss: 0.3088\n",
            "Epoch [53/150], train_loss: 0.3071\n",
            "Epoch [54/150], train_loss: 0.3060\n",
            "Epoch [55/150], train_loss: 0.3050\n",
            "Epoch [56/150], train_loss: 0.3024\n",
            "Epoch [57/150], train_loss: 0.3019\n",
            "Epoch [58/150], train_loss: 0.2984\n",
            "Epoch [59/150], train_loss: 0.2966\n",
            "Epoch [60/150], train_loss: 0.2961\n",
            "Epoch [61/150], train_loss: 0.2936\n",
            "Epoch [62/150], train_loss: 0.2922\n",
            "Epoch [63/150], train_loss: 0.3370\n",
            "Epoch [64/150], train_loss: 0.3138\n",
            "Epoch [65/150], train_loss: 0.2954\n",
            "Epoch [66/150], train_loss: 0.2907\n",
            "Epoch [67/150], train_loss: 0.2875\n",
            "Epoch [68/150], train_loss: 0.2861\n",
            "Epoch [69/150], train_loss: 0.2848\n",
            "Epoch [70/150], train_loss: 0.2835\n",
            "Epoch [71/150], train_loss: 0.2821\n",
            "Epoch [72/150], train_loss: 0.2813\n",
            "Epoch [73/150], train_loss: 0.2800\n",
            "Epoch [74/150], train_loss: 0.2795\n",
            "Epoch [75/150], train_loss: 0.2785\n",
            "Epoch [76/150], train_loss: 0.2772\n",
            "Epoch [77/150], train_loss: 0.2761\n",
            "Epoch [78/150], train_loss: 0.2752\n",
            "Epoch [79/150], train_loss: 0.2735\n",
            "Epoch [80/150], train_loss: 0.2732\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6512dba01693>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-771b634e34ae>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# out.shape : [batch_size, sequence_length, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#The : before , -1, : indicates that we want to include all elements along the first dimension (batch dimension). -1 represents the index of the last element along the second dimension (sequence length). : after , -1 indicates that we want to include all elements along the third dimension (hidden size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    814\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(name):\n",
        "    # If you what to replicate the DeepLog paper results(Actually, I have a better result than DeepLog paper results),\n",
        "    # you should use the 'list' not 'set' to obtain the full dataset, I use 'set' just for test and acceleration.\n",
        "    hdfs = set()\n",
        "    # hdfs = []\n",
        "    with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            line = [int(i) for i in row.strip().split()]\n",
        "            line = line + [0] * (window_size + 1 - len(line)) #if the length of the line is less than windows size, it covers by -1\n",
        "            hdfs.add(tuple(line))\n",
        "            # hdfs.append(tuple(line))\n",
        "    print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
        "    return hdfs\n",
        ""
      ],
      "metadata": {
        "id": "g90HG-zc7V-Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_normal_loader = generate('hdfs_test_normal')\n",
        "test_abnormal_loader = generate('hdfs_test_abnormal')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NnZp1dT75jI",
        "outputId": "ba4d841a-46ef-4351-8806-c4e882a2135a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_test_normal): 14177\n",
            "Number of sessions(hdfs_test_abnormal): 4123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_candidates = 9 # on paper is g , top-g(here top 9) probabilities to appear next are considered normal"
      ],
      "metadata": {
        "id": "dSDO2VmH8dRF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "\n",
        "TP = 0\n",
        "FP = 0\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for line in test_normal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            seq = line[i:i + window_size]\n",
        "            label = line[i + window_size]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            label = torch.tensor(label).view(-1).to(device)\n",
        "            output = model(seq)\n",
        "            predicted = torch.argsort(output, 1)[0][-num_candidates:]\n",
        "            if label not in predicted:\n",
        "                FP += 1\n",
        "                break   #with just one wrong prediction in a line , we assume , abnormal\n",
        "with torch.no_grad():\n",
        "    for line in test_abnormal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            seq = line[i:i + window_size]\n",
        "            label = line[i + window_size]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            label = torch.tensor(label).view(-1).to(device)\n",
        "            output = model(seq)\n",
        "            predicted = torch.argsort(output, 1)[0][-num_candidates:]\n",
        "            if label not in predicted:\n",
        "                TP += 1\n",
        "                break\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "# Compute precision, recall and F1-measure\n",
        "FN = len(test_abnormal_loader) - TP\n",
        "P = 100 * TP / (TP + FP)\n",
        "R = 100 * TP / (TP + FN)\n",
        "F1 = 2 * P * R / (P + R)\n",
        "print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
        "print('Finished Predicting')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIDRTh2-8ASi",
        "outputId": "9bff405d-2314-48c9-ae93-9dff8a53a643"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 148.871s\n",
            "false positive (FP): 1048, false negative (FN): 272, Precision: 78.608%, Recall: 93.403%, F1-measure: 85.369%\n",
            "Finished Predicting\n"
          ]
        }
      ]
    }
  ]
}