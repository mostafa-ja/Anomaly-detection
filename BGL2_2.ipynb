{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/BGL2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload log files\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/X_train_index'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/Xabnorm_test_index'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/Xnorm_test_index'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/log2index'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/reduced_index2embed'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i2YpVSwj8dl",
        "outputId": "d2a8c507-00cb-4944-feb4-93e9a548802b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-05 15:29:43--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/X_train_index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9341136 (8.9M) [text/plain]\n",
            "Saving to: ‘X_train_index’\n",
            "\n",
            "X_train_index       100%[===================>]   8.91M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-09-05 15:29:44 (140 MB/s) - ‘X_train_index’ saved [9341136/9341136]\n",
            "\n",
            "--2023-09-05 15:29:44--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/Xabnorm_test_index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1568608 (1.5M) [text/plain]\n",
            "Saving to: ‘Xabnorm_test_index’\n",
            "\n",
            "Xabnorm_test_index  100%[===================>]   1.50M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-09-05 15:29:44 (38.1 MB/s) - ‘Xabnorm_test_index’ saved [1568608/1568608]\n",
            "\n",
            "--2023-09-05 15:29:44--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/Xnorm_test_index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3267859 (3.1M) [text/plain]\n",
            "Saving to: ‘Xnorm_test_index’\n",
            "\n",
            "Xnorm_test_index    100%[===================>]   3.12M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-09-05 15:29:45 (76.0 MB/s) - ‘Xnorm_test_index’ saved [3267859/3267859]\n",
            "\n",
            "--2023-09-05 15:29:45--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/log2index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73231 (72K) [application/octet-stream]\n",
            "Saving to: ‘log2index’\n",
            "\n",
            "log2index           100%[===================>]  71.51K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-09-05 15:29:45 (8.78 MB/s) - ‘log2index’ saved [73231/73231]\n",
            "\n",
            "--2023-09-05 15:29:45--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL/reduced_index2embed\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 966454 (944K) [text/plain]\n",
            "Saving to: ‘reduced_index2embed’\n",
            "\n",
            "reduced_index2embed 100%[===================>] 943.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-09-05 15:29:46 (27.5 MB/s) - ‘reduced_index2embed’ saved [966454/966454]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "jd9WP1rSrLSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b20da4-2290-421a-a2f9-429dd025ace4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zwX3TMYF1zli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/content/log2index') as f:\n",
        "    templates = [line.strip() for line in f.readlines()]"
      ],
      "metadata": {
        "id": "cmL0eCjj1zU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "templates[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvxFiVkO2Czc",
        "outputId": "a392bc18-46c8-4a87-8f87-823c82d811a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ras kernel info instruction cache parity error corrected',\n",
              " 'ras linkcard info midplaneswitchcontroller performing bit sparing on bit',\n",
              " 'ras kernel info generating',\n",
              " 'ras kernel info ddr errors s detected and corrected on rank symbol bit',\n",
              " 'ras kernel info edram error s dcr detected and corrected']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Json file name\n",
        "with open('/content/reduced_index2embed') as f:\n",
        "    embeddings = [json.loads(line) for line in f.readlines()]\n",
        "\n",
        "len(embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFtNRiAhl4Cd",
        "outputId": "c6c055a1-2009-45e2-ac49-0f602edc8b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "embed = np.array(embeddings)\n",
        "matrix = np.zeros((len(templates),len(templates)))\n",
        "max_similarity = 0\n",
        "\n",
        "for i in range(len(templates)):\n",
        "  for j in range(i+1,len(templates)) :\n",
        "\n",
        "      similarity = cosine_similarity(embed[i].reshape(1, -1),embed[j].reshape(1, -1))\n",
        "      matrix[i,j] = similarity\n",
        "\n",
        "      if (similarity > 0.85) & (similarity < 0.90) :\n",
        "        print('similarity = ',similarity)\n",
        "        print(templates[i])\n",
        "        print(templates[j])\n",
        "        print('-----------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IWql7Gmr1iRO",
        "outputId": "9715bb56-4d33-4695-e57a-fc4db4b19e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity =  [[0.86446773]]\n",
            "ras kernel info instruction cache parity error corrected\n",
            "ras kernel info data cache flush parity error detected attempting to correct\n",
            "-----------------------------------\n",
            "similarity =  [[0.89088115]]\n",
            "ras kernel info ddr activating redundant bit steering rank symbol\n",
            "ras kernel info ddr unable to steer rank symbol rank is already steering symbol due to multiple symbols being over the correctable\n",
            "-----------------------------------\n",
            "similarity =  [[0.87308842]]\n",
            "ras kernel info ddr activating redundant bit steering rank symbol\n",
            "ras kernel info ddr unable to steer rank symbol rank is already steering symbol due to multiple symbols being over the correctable e\n",
            "-----------------------------------\n",
            "similarity =  [[0.89107637]]\n",
            "ras kernel info ddr activating redundant bit steering rank symbol\n",
            "ras kernel info ddr unable to steer rank symbol rank is already steering symbol due to multiple symbols being over the correctabl\n",
            "-----------------------------------\n",
            "similarity =  [[0.85654353]]\n",
            "ras app fatal ciod error loading invalid or missing program image no such file or directory\n",
            "ras app fatal ciod error loading userfuncround invalid or missing program image no such file or directory\n",
            "-----------------------------------\n",
            "similarity =  [[0.88525245]]\n",
            "ras app fatal ciod error loading invalid or missing program image no such file or directory\n",
            "ras app fatal ciod error loading userfunctopologies invalid or missing program image no such file or directory\n",
            "-----------------------------------\n",
            "similarity =  [[0.89465302]]\n",
            "ras app fatal ciod error loading invalid or missing program image no such file or directory\n",
            "ras app fatal ciod error loading runtimeverify invalid or missing program image no such file or directory\n",
            "-----------------------------------\n",
            "similarity =  [[0.86080382]]\n",
            "ras app fatal ciod error loading invalid or missing program image no such file or directory\n",
            "ras app fatal ciod error loading runtimewatchdog invalid or missing program image no such file or directory\n",
            "-----------------------------------\n",
            "similarity =  [[0.85918773]]\n",
            "ras app fatal ciod error loading invalid or missing program image no such file or directory\n",
            "ras app fatal ciod error loading memtest invalid or missing program image no such file or directory\n",
            "-----------------------------------\n",
            "similarity =  [[0.8563842]]\n",
            "ras app fatal ciod error loading invalid or missing program image no such file or directory\n",
            "ras app fatal ciod error loading invalid or missing program image permission denied\n",
            "-----------------------------------\n",
            "similarity =  [[0.87578145]]\n",
            "ras app fatal ciod error loading invalid or missing program image no such file or directory\n",
            "ras app fatal ciod error loading homecabotmiranovabglbinlukeimirandanewhack invalid or missing program image no such file or directory\n",
            "-----------------------------------\n",
            "similarity =  [[0.88014218]]\n",
            "ras app fatal ciod error loading invalid or missing program image no such file or directory\n",
            "ras app fatal ciod error loading binhostname invalid or missing program image exec format error\n",
            "-----------------------------------\n",
            "similarity =  [[0.88039629]]\n",
            "ras kernel fatal imprecise machine\n",
            "ras kernel fatal correctable\n",
            "-----------------------------------\n",
            "similarity =  [[0.89367331]]\n",
            "ras kernel fatal machine state register\n",
            "ras kernel fatal gister machine state register machine state register machine state register machine state register machine state register\n",
            "-----------------------------------\n",
            "similarity =  [[0.89071253]]\n",
            "ras kernel fatal critical input interrupt\n",
            "ras kernel fatal external input interrupt\n",
            "-----------------------------------\n",
            "similarity =  [[0.85429211]]\n",
            "ras kernel fatal critical input interrupt\n",
            "ras kernel fatal program interrupt imprecise\n",
            "-----------------------------------\n",
            "similarity =  [[0.8726815]]\n",
            "ras kernel fatal critical input interrupt\n",
            "ras kernel fatal program interrupt\n",
            "-----------------------------------\n",
            "similarity =  [[0.85552698]]\n",
            "ras kernel fatal debug interrupt\n",
            "ras kernel fatal program interrupt illegal\n",
            "-----------------------------------\n",
            "similarity =  [[0.85953194]]\n",
            "ras kernel fatal debug interrupt\n",
            "ras kernel fatal program interrupt imprecise\n",
            "-----------------------------------\n",
            "similarity =  [[0.86006855]]\n",
            "ras kernel fatal debug interrupt\n",
            "ras kernel fatal machine check interrupt\n",
            "-----------------------------------\n",
            "similarity =  [[0.87286074]]\n",
            "ras kernel fatal debug interrupt\n",
            "ras kernel fatal program interrupt\n",
            "-----------------------------------\n",
            "similarity =  [[0.89187098]]\n",
            "ras kernel fatal\n",
            "ras kernel fatal state\n",
            "-----------------------------------\n",
            "similarity =  [[0.89763818]]\n",
            "ras kernel fatal\n",
            "ras kernel fatal chip\n",
            "-----------------------------------\n",
            "similarity =  [[0.89977279]]\n",
            "ras kernel fatal\n",
            "ras kernel fatal ax\n",
            "-----------------------------------\n",
            "similarity =  [[0.86246553]]\n",
            "ras kernel fatal\n",
            "ras kernel fatal inexact\n",
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7eb33d7c4069>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mY\u001b[0m \u001b[0mwas\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_Y\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpointer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \"\"\"\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_return_float_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"check_pairwise_arrays\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_return_float_dtype\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mY_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxDE6zaF3uQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM Autoencoder model with dropout\n",
        "class LSTMAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, sequence_length, dropout_prob): #input_dim= embeddings_dim\n",
        "        super(LSTMAutoencoder, self).__init__()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True, dropout=dropout_prob)\n",
        "        self.decoder = nn.LSTM(int(hidden_dim/2), input_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, int(hidden_dim/2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded, _ = self.encoder(x)\n",
        "        #print(encoded.shape)\n",
        "        encoded = encoded[:,-1:,:] # output of last cell\n",
        "        encoded = self.fc(encoded)\n",
        "        #print(encoded.shape)\n",
        "        input_decode = torch.tile(encoded, (1, self.sequence_length, 1))\n",
        "        decoded, _ = self.decoder(input_decode)\n",
        "        return decoded"
      ],
      "metadata": {
        "id": "BMnD_BY82ZVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5\n",
        "input_size = len(embeddings[0]) #embedding vector dimension\n",
        "hidden_dim = 128\n",
        "num_layers = 2\n",
        "dropout_prob = 0.2\n",
        "\n",
        "model = LSTMAutoencoder(input_size, hidden_dim, 2, sequence_length, dropout_prob).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPQ1gUe22tIP",
        "outputId": "cec090e3-d388-4478-f01b-68074531450a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMAutoencoder(\n",
              "  (encoder): LSTM(60, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
              "  (decoder): LSTM(64, 60, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=256, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.randn(1,sequence_length, input_size) #batch_size=1\n",
        "model(data.to(device)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dloxW2iT3DWn",
        "outputId": "34e514f5-839d-4390-a993-fa6a7783988c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 60])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of parameters\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of Parameters: {num_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIEBmDYf29xi",
        "outputId": "1752b2f8-f7b6-45ca-c537-0fcb605ccce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Parameters: 665792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = sequence_length\n",
        "num_sessions = 0\n",
        "sequences = {}\n",
        "\n",
        "line = [i for i in range(20)]\n",
        "print(line)\n",
        "\n",
        "for i in range(len(line) - window_size):\n",
        "    seq = tuple(line[i:i + window_size])\n",
        "    if seq not in sequences:\n",
        "      sequences[seq] = [ embeddings[i] for i in seq]\n",
        "\n",
        "\n",
        "print(sequences.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_xLmzER-wRa",
        "outputId": "13676663-30a5-4776-dc06-c73758530075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "dict_keys([(0, 1, 2, 3, 4), (1, 2, 3, 4, 5), (2, 3, 4, 5, 6), (3, 4, 5, 6, 7), (4, 5, 6, 7, 8), (5, 6, 7, 8, 9), (6, 7, 8, 9, 10), (7, 8, 9, 10, 11), (8, 9, 10, 11, 12), (9, 10, 11, 12, 13), (10, 11, 12, 13, 14), (11, 12, 13, 14, 15), (12, 13, 14, 15, 16), (13, 14, 15, 16, 17), (14, 15, 16, 17, 18)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'X_train_index'\n",
        "window_size = sequence_length\n",
        "sequences = {}\n",
        "#outputs = []\n",
        "with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            line = [ int(i) for i in row.strip().split()]\n",
        "\n",
        "            for i in range(len(line) - window_size):\n",
        "                seq = tuple(line[i:i + window_size])\n",
        "                if seq not in sequences:\n",
        "                  sequences[seq] = [ embeddings[i] for i in seq]\n",
        "\n",
        "print('the length of dictionary : ', len(sequences))\n",
        "\n",
        "dataset = TensorDataset(torch.tensor(list(sequences.values()), dtype=torch.float))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD7-Kb3y8L63",
        "outputId": "aa69ac8c-4433-4768-a688-a1da1f6d508f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the length of dictionary :  24079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(sequences.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkAqa_vuADgT",
        "outputId": "f48c0e44-a5d6-4056-a734-609e82a1033f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0, 0, 0, 0),\n",
              " (0, 0, 0, 0, 1),\n",
              " (0, 0, 0, 1, 0),\n",
              " (0, 0, 1, 0, 0),\n",
              " (0, 0, 0, 0, 2),\n",
              " (0, 0, 0, 2, 2),\n",
              " (0, 0, 2, 2, 0),\n",
              " (0, 2, 2, 0, 2),\n",
              " (2, 2, 0, 2, 2),\n",
              " (0, 2, 2, 2, 0),\n",
              " (2, 2, 2, 0, 2),\n",
              " (2, 0, 2, 2, 2),\n",
              " (2, 2, 2, 0, 0),\n",
              " (2, 2, 0, 0, 2),\n",
              " (2, 0, 0, 2, 2),\n",
              " (0, 0, 2, 2, 2),\n",
              " (0, 2, 2, 2, 2),\n",
              " (2, 2, 2, 2, 0),\n",
              " (2, 2, 0, 2, 0),\n",
              " (2, 0, 2, 0, 0),\n",
              " (0, 2, 0, 0, 0),\n",
              " (0, 3, 4, 5, 6),\n",
              " (3, 4, 5, 6, 4),\n",
              " (4, 5, 6, 4, 4),\n",
              " (5, 6, 4, 4, 2),\n",
              " (6, 4, 4, 2, 2),\n",
              " (4, 4, 2, 2, 2),\n",
              " (4, 2, 2, 2, 2),\n",
              " (2, 2, 2, 2, 2),\n",
              " (2, 2, 2, 2, 1),\n",
              " (2, 2, 2, 1, 2),\n",
              " (2, 2, 1, 2, 2),\n",
              " (2, 1, 2, 2, 2),\n",
              " (2, 1, 7, 8, 4),\n",
              " (1, 7, 8, 4, 3),\n",
              " (7, 8, 4, 3, 3),\n",
              " (8, 4, 3, 3, 3),\n",
              " (4, 3, 3, 3, 5),\n",
              " (3, 3, 3, 5, 3),\n",
              " (3, 3, 5, 3, 5),\n",
              " (3, 5, 3, 5, 3),\n",
              " (5, 3, 5, 3, 5),\n",
              " (6, 5, 5, 5, 5),\n",
              " (5, 5, 5, 5, 5),\n",
              " (5, 5, 6, 2, 2),\n",
              " (5, 6, 2, 2, 2),\n",
              " (6, 2, 2, 2, 2),\n",
              " (2, 2, 2, 2, 9),\n",
              " (2, 2, 2, 9, 9),\n",
              " (2, 2, 9, 9, 9),\n",
              " (2, 9, 9, 9, 9),\n",
              " (9, 9, 9, 9, 9),\n",
              " (9, 9, 9, 9, 3),\n",
              " (9, 9, 9, 3, 3),\n",
              " (9, 9, 3, 3, 5),\n",
              " (9, 3, 3, 5, 5),\n",
              " (3, 3, 5, 5, 5),\n",
              " (3, 5, 5, 5, 5),\n",
              " (5, 5, 5, 5, 6),\n",
              " (5, 5, 5, 6, 5),\n",
              " (5, 5, 6, 5, 5),\n",
              " (5, 6, 5, 5, 5),\n",
              " (5, 5, 5, 6, 3),\n",
              " (5, 5, 6, 3, 4),\n",
              " (5, 6, 3, 4, 4),\n",
              " (6, 3, 4, 4, 5),\n",
              " (3, 4, 4, 5, 5),\n",
              " (4, 4, 5, 5, 5),\n",
              " (4, 5, 5, 5, 5),\n",
              " (5, 5, 6, 1, 10),\n",
              " (5, 6, 1, 10, 4),\n",
              " (6, 1, 10, 4, 2),\n",
              " (1, 10, 4, 2, 2),\n",
              " (10, 4, 2, 2, 3),\n",
              " (4, 2, 2, 3, 2),\n",
              " (2, 2, 3, 2, 2),\n",
              " (2, 3, 2, 2, 2),\n",
              " (3, 2, 2, 2, 2),\n",
              " (2, 2, 2, 2, 3),\n",
              " (2, 2, 2, 3, 5),\n",
              " (2, 2, 3, 5, 2),\n",
              " (2, 3, 5, 2, 2),\n",
              " (3, 5, 2, 2, 2),\n",
              " (5, 2, 2, 2, 2),\n",
              " (2, 2, 2, 3, 6),\n",
              " (2, 2, 3, 6, 3),\n",
              " (2, 3, 6, 3, 2),\n",
              " (3, 6, 3, 2, 3),\n",
              " (6, 3, 2, 3, 5),\n",
              " (3, 2, 3, 5, 3),\n",
              " (2, 3, 5, 3, 6),\n",
              " (3, 5, 3, 6, 5),\n",
              " (5, 3, 6, 5, 5),\n",
              " (3, 6, 5, 5, 5),\n",
              " (5, 5, 5, 6, 10),\n",
              " (5, 5, 6, 10, 10),\n",
              " (5, 6, 10, 10, 10),\n",
              " (6, 10, 10, 10, 10),\n",
              " (10, 10, 10, 10, 10),\n",
              " (10, 10, 3, 3, 3),\n",
              " (10, 3, 3, 3, 4),\n",
              " (3, 3, 3, 4, 4),\n",
              " (3, 3, 4, 4, 3),\n",
              " (3, 4, 4, 3, 3),\n",
              " (4, 4, 3, 3, 3),\n",
              " (4, 3, 3, 3, 3),\n",
              " (3, 3, 3, 3, 5),\n",
              " (3, 3, 3, 5, 5),\n",
              " (5, 6, 5, 6, 6),\n",
              " (6, 5, 6, 6, 5),\n",
              " (5, 6, 6, 5, 5),\n",
              " (6, 6, 5, 5, 5),\n",
              " (5, 5, 6, 3, 5),\n",
              " (5, 6, 3, 5, 5),\n",
              " (6, 3, 5, 5, 5),\n",
              " (2, 5, 6, 2, 2),\n",
              " (4, 5, 6, 8, 3),\n",
              " (5, 6, 8, 3, 4),\n",
              " (6, 8, 3, 4, 3),\n",
              " (8, 3, 4, 3, 3),\n",
              " (3, 4, 3, 3, 5),\n",
              " (4, 3, 3, 5, 3),\n",
              " (3, 3, 5, 3, 6),\n",
              " (3, 5, 3, 6, 3),\n",
              " (5, 3, 6, 3, 5),\n",
              " (3, 6, 3, 5, 5),\n",
              " (5, 6, 3, 4, 5),\n",
              " (6, 3, 4, 5, 6),\n",
              " (3, 4, 5, 6, 7),\n",
              " (4, 5, 6, 7, 3),\n",
              " (5, 6, 7, 3, 3),\n",
              " (6, 7, 3, 3, 3),\n",
              " (7, 3, 3, 3, 11),\n",
              " (3, 3, 3, 11, 3),\n",
              " (3, 3, 11, 3, 4),\n",
              " (5, 5, 5, 5, 3),\n",
              " (5, 5, 5, 3, 5),\n",
              " (5, 5, 3, 5, 6),\n",
              " (5, 3, 5, 6, 5),\n",
              " (3, 5, 6, 5, 6),\n",
              " (6, 5, 6, 6, 6),\n",
              " (5, 6, 6, 6, 5),\n",
              " (5, 5, 6, 3, 3),\n",
              " (5, 6, 3, 3, 3),\n",
              " (6, 3, 3, 3, 3),\n",
              " (3, 3, 3, 3, 3),\n",
              " (3, 3, 3, 3, 4),\n",
              " (3, 3, 3, 4, 3),\n",
              " (3, 3, 4, 3, 3),\n",
              " (4, 3, 3, 5, 5),\n",
              " (6, 5, 5, 5, 6),\n",
              " (5, 5, 6, 5, 6),\n",
              " (5, 6, 5, 6, 5),\n",
              " (6, 5, 6, 5, 5),\n",
              " (5, 6, 5, 5, 6),\n",
              " (6, 5, 5, 6, 5),\n",
              " (3, 5, 6, 3, 4),\n",
              " (6, 3, 4, 5, 11),\n",
              " (3, 4, 5, 11, 6),\n",
              " (4, 5, 11, 6, 2),\n",
              " (5, 11, 6, 2, 1),\n",
              " (11, 6, 2, 1, 1),\n",
              " (6, 2, 1, 1, 3),\n",
              " (2, 1, 1, 3, 5),\n",
              " (1, 1, 3, 5, 3),\n",
              " (1, 3, 5, 3, 3),\n",
              " (3, 5, 3, 3, 3),\n",
              " (5, 3, 3, 3, 3),\n",
              " (5, 3, 5, 5, 5),\n",
              " (5, 6, 5, 6, 0),\n",
              " (6, 5, 6, 0, 3),\n",
              " (5, 6, 0, 3, 3),\n",
              " (6, 0, 3, 3, 4),\n",
              " (0, 3, 3, 4, 3),\n",
              " (3, 3, 4, 3, 5),\n",
              " (3, 4, 3, 5, 5),\n",
              " (4, 3, 5, 5, 3),\n",
              " (3, 5, 5, 3, 3),\n",
              " (5, 5, 3, 3, 5),\n",
              " (5, 3, 3, 5, 6),\n",
              " (3, 3, 5, 6, 5),\n",
              " (3, 5, 6, 5, 5),\n",
              " (6, 6, 6, 1, 1),\n",
              " (6, 6, 1, 1, 4),\n",
              " (6, 1, 1, 4, 4),\n",
              " (1, 1, 4, 4, 4),\n",
              " (1, 4, 4, 4, 4),\n",
              " (4, 4, 4, 4, 4),\n",
              " (4, 4, 4, 4, 1),\n",
              " (4, 4, 4, 1, 3),\n",
              " (4, 4, 1, 3, 5),\n",
              " (4, 1, 3, 5, 6),\n",
              " (1, 3, 5, 6, 3),\n",
              " (3, 5, 6, 3, 5),\n",
              " (5, 6, 3, 5, 4),\n",
              " (6, 3, 5, 4, 6),\n",
              " (4, 5, 6, 3, 4),\n",
              " (3, 4, 5, 6, 3),\n",
              " (4, 5, 6, 3, 5),\n",
              " (3, 5, 4, 6, 1),\n",
              " (5, 4, 6, 1, 1),\n",
              " (4, 6, 1, 1, 3),\n",
              " (6, 1, 1, 3, 3),\n",
              " (1, 1, 3, 3, 4),\n",
              " (1, 3, 3, 4, 4),\n",
              " (3, 3, 4, 4, 5),\n",
              " (3, 4, 4, 5, 6),\n",
              " (4, 4, 5, 6, 8),\n",
              " (4, 5, 6, 8, 0),\n",
              " (5, 6, 8, 0, 0),\n",
              " (6, 8, 0, 0, 7),\n",
              " (8, 0, 0, 7, 7),\n",
              " (0, 0, 7, 7, 7),\n",
              " (0, 7, 7, 7, 3),\n",
              " (7, 7, 7, 3, 3),\n",
              " (7, 7, 3, 3, 3),\n",
              " (7, 3, 3, 3, 3),\n",
              " (5, 5, 5, 6, 6),\n",
              " (5, 5, 6, 6, 5),\n",
              " (5, 6, 6, 5, 6),\n",
              " (6, 6, 5, 6, 5),\n",
              " (5, 3, 5, 3, 6),\n",
              " (5, 3, 6, 5, 3),\n",
              " (3, 6, 5, 3, 5),\n",
              " (6, 5, 3, 5, 5),\n",
              " (5, 3, 5, 5, 3),\n",
              " (3, 5, 5, 3, 5),\n",
              " (5, 5, 3, 5, 5),\n",
              " (6, 5, 3, 6, 5),\n",
              " (5, 3, 6, 5, 6),\n",
              " (3, 6, 5, 6, 5),\n",
              " (3, 5, 5, 5, 6),\n",
              " (5, 5, 6, 5, 3),\n",
              " (5, 6, 5, 3, 5),\n",
              " (5, 5, 5, 6, 4),\n",
              " (5, 5, 6, 4, 5),\n",
              " (5, 6, 4, 5, 5),\n",
              " (6, 4, 5, 5, 5),\n",
              " (3, 3, 5, 3, 3),\n",
              " (3, 5, 3, 3, 4),\n",
              " (5, 3, 3, 4, 5),\n",
              " (3, 3, 4, 5, 5),\n",
              " (3, 4, 5, 5, 5),\n",
              " (4, 5, 5, 5, 6),\n",
              " (5, 5, 5, 5, 7),\n",
              " (5, 5, 5, 7, 7),\n",
              " (5, 5, 7, 7, 7),\n",
              " (3, 3, 5, 5, 3),\n",
              " (5, 3, 3, 5, 5),\n",
              " (3, 3, 5, 5, 4),\n",
              " (3, 5, 5, 4, 5),\n",
              " (5, 5, 4, 5, 5),\n",
              " (5, 3, 5, 5, 6),\n",
              " (3, 5, 5, 6, 6),\n",
              " (6, 6, 5, 5, 6),\n",
              " (6, 5, 5, 6, 6),\n",
              " (5, 5, 6, 6, 6),\n",
              " (5, 6, 6, 6, 6),\n",
              " (6, 6, 6, 6, 6),\n",
              " (6, 6, 6, 6, 5),\n",
              " (6, 6, 6, 5, 5),\n",
              " (5, 5, 5, 5, 1),\n",
              " (5, 5, 5, 1, 9),\n",
              " (5, 5, 1, 9, 9),\n",
              " (5, 1, 9, 9, 9),\n",
              " (1, 9, 9, 9, 9),\n",
              " (9, 9, 9, 3, 5),\n",
              " (3, 5, 6, 4, 3),\n",
              " (5, 6, 4, 3, 3),\n",
              " (6, 4, 3, 3, 5),\n",
              " (5, 6, 9, 9, 9),\n",
              " (6, 9, 9, 9, 9),\n",
              " (9, 9, 9, 9, 2),\n",
              " (9, 9, 9, 2, 2),\n",
              " (9, 9, 2, 2, 2),\n",
              " (9, 2, 2, 2, 2),\n",
              " (1, 2, 2, 2, 2),\n",
              " (2, 2, 2, 2, 12),\n",
              " (2, 2, 2, 12, 2),\n",
              " (2, 2, 12, 2, 2),\n",
              " (2, 12, 2, 2, 2),\n",
              " (12, 2, 2, 2, 2),\n",
              " (2, 2, 2, 1, 3),\n",
              " (4, 3, 5, 5, 5),\n",
              " (6, 6, 6, 5, 6),\n",
              " (5, 6, 3, 5, 6),\n",
              " (6, 3, 5, 6, 2),\n",
              " (3, 5, 6, 2, 2),\n",
              " (13, 14, 15, 16, 17),\n",
              " (14, 15, 16, 17, 18),\n",
              " (15, 16, 17, 18, 19),\n",
              " (16, 17, 18, 19, 20),\n",
              " (17, 18, 19, 20, 21),\n",
              " (18, 19, 20, 21, 22),\n",
              " (19, 20, 21, 22, 23),\n",
              " (20, 21, 22, 23, 24),\n",
              " (21, 22, 23, 24, 25),\n",
              " (22, 23, 24, 25, 23),\n",
              " (23, 24, 25, 23, 12),\n",
              " (24, 25, 23, 12, 26),\n",
              " (25, 23, 12, 26, 27),\n",
              " (23, 12, 26, 27, 28),\n",
              " (12, 26, 27, 28, 29),\n",
              " (3, 3, 5, 5, 31),\n",
              " (3, 5, 5, 31, 3),\n",
              " (5, 5, 31, 3, 3),\n",
              " (5, 31, 3, 3, 3),\n",
              " (31, 3, 3, 3, 3),\n",
              " (5, 3, 5, 3, 3),\n",
              " (5, 3, 3, 3, 5),\n",
              " (5, 5, 5, 5, 31),\n",
              " (5, 5, 5, 31, 5),\n",
              " (5, 5, 31, 5, 5),\n",
              " (5, 31, 5, 5, 3),\n",
              " (31, 5, 5, 3, 5),\n",
              " (3, 5, 5, 5, 3),\n",
              " (6, 5, 5, 5, 3),\n",
              " (5, 5, 3, 5, 3),\n",
              " (5, 5, 5, 33, 5),\n",
              " (5, 5, 33, 5, 5),\n",
              " (5, 33, 5, 5, 5),\n",
              " (33, 5, 5, 5, 5),\n",
              " (6, 6, 5, 6, 6),\n",
              " (3, 5, 5, 5, 11),\n",
              " (5, 5, 5, 11, 5),\n",
              " (5, 5, 11, 5, 6),\n",
              " (5, 11, 5, 6, 5),\n",
              " (11, 5, 6, 5, 5),\n",
              " (11, 6, 5, 6, 5),\n",
              " (5, 5, 5, 1, 2),\n",
              " (5, 5, 1, 2, 2),\n",
              " (5, 1, 2, 2, 2),\n",
              " (2, 2, 12, 12, 12),\n",
              " (2, 12, 12, 12, 12),\n",
              " (12, 12, 12, 12, 12),\n",
              " (12, 12, 12, 12, 26),\n",
              " (12, 12, 12, 26, 26),\n",
              " (12, 12, 26, 26, 26),\n",
              " (12, 26, 26, 26, 26),\n",
              " (26, 26, 26, 26, 26),\n",
              " (16, 16, 16, 16, 16),\n",
              " (16, 16, 16, 16, 17),\n",
              " (16, 16, 16, 17, 17),\n",
              " (16, 16, 17, 17, 17),\n",
              " (16, 17, 17, 17, 17),\n",
              " (17, 17, 17, 17, 17),\n",
              " (17, 17, 17, 17, 18),\n",
              " (18, 18, 18, 18, 18),\n",
              " (18, 18, 18, 18, 19),\n",
              " (18, 18, 18, 19, 19),\n",
              " (18, 18, 19, 19, 19),\n",
              " (18, 19, 19, 19, 19),\n",
              " (19, 19, 19, 19, 19),\n",
              " (19, 19, 19, 19, 20),\n",
              " (19, 19, 19, 20, 20),\n",
              " (19, 19, 20, 20, 20),\n",
              " (20, 20, 20, 20, 20),\n",
              " (20, 20, 20, 20, 21),\n",
              " (20, 20, 20, 21, 21),\n",
              " (20, 20, 21, 21, 21),\n",
              " (20, 21, 21, 21, 21),\n",
              " (21, 21, 21, 21, 21),\n",
              " (21, 21, 21, 21, 22),\n",
              " (21, 21, 21, 22, 22),\n",
              " (21, 21, 22, 22, 22),\n",
              " (21, 22, 22, 22, 22),\n",
              " (22, 22, 22, 22, 22),\n",
              " (22, 22, 22, 23, 23),\n",
              " (22, 22, 23, 23, 23),\n",
              " (22, 23, 23, 23, 23),\n",
              " (23, 23, 23, 23, 23),\n",
              " (23, 23, 23, 23, 24),\n",
              " (23, 23, 23, 24, 24),\n",
              " (23, 23, 24, 24, 24),\n",
              " (23, 24, 24, 24, 24),\n",
              " (24, 24, 24, 24, 24),\n",
              " (24, 25, 25, 25, 25),\n",
              " (25, 25, 25, 25, 25),\n",
              " (25, 25, 25, 25, 23),\n",
              " (25, 25, 25, 23, 23),\n",
              " (25, 25, 23, 23, 23),\n",
              " (25, 23, 23, 23, 23),\n",
              " (26, 26, 26, 26, 27),\n",
              " (26, 26, 26, 27, 27),\n",
              " (27, 27, 27, 27, 27),\n",
              " (27, 27, 27, 27, 28),\n",
              " (27, 27, 27, 28, 28),\n",
              " (27, 27, 28, 28, 28),\n",
              " (27, 28, 28, 28, 28),\n",
              " (28, 28, 28, 28, 28),\n",
              " (28, 28, 28, 28, 29),\n",
              " (28, 28, 28, 29, 29),\n",
              " (28, 28, 29, 29, 29),\n",
              " (28, 29, 29, 29, 29),\n",
              " (29, 29, 29, 29, 30),\n",
              " (29, 29, 29, 30, 30),\n",
              " (29, 29, 30, 30, 30),\n",
              " (29, 30, 30, 30, 30),\n",
              " (30, 30, 30, 30, 30),\n",
              " (30, 30, 30, 30, 34),\n",
              " (30, 30, 30, 34, 34),\n",
              " (30, 30, 34, 34, 34),\n",
              " (30, 34, 34, 34, 34),\n",
              " (34, 34, 34, 34, 34),\n",
              " (34, 34, 35, 35, 35),\n",
              " (34, 35, 35, 35, 35),\n",
              " (35, 35, 35, 35, 35),\n",
              " (35, 35, 35, 35, 36),\n",
              " (35, 35, 35, 36, 36),\n",
              " (35, 35, 36, 36, 36),\n",
              " (35, 36, 36, 36, 36),\n",
              " (36, 36, 36, 36, 36),\n",
              " (37, 37, 37, 37, 37),\n",
              " (37, 37, 37, 37, 38),\n",
              " (38, 38, 38, 38, 38),\n",
              " (38, 38, 38, 38, 39),\n",
              " (38, 38, 38, 39, 39),\n",
              " (38, 38, 39, 39, 39),\n",
              " (38, 39, 39, 39, 39),\n",
              " (39, 39, 39, 39, 39),\n",
              " (40, 40, 40, 40, 40),\n",
              " (40, 40, 40, 40, 39),\n",
              " (40, 40, 40, 39, 39),\n",
              " (40, 40, 39, 39, 39),\n",
              " (40, 39, 39, 39, 39),\n",
              " (39, 39, 39, 39, 41),\n",
              " (39, 39, 39, 41, 41),\n",
              " (42, 42, 42, 42, 42),\n",
              " (26, 26, 26, 26, 16),\n",
              " (26, 26, 26, 16, 16),\n",
              " (26, 26, 16, 16, 16),\n",
              " (26, 16, 16, 16, 16),\n",
              " (19, 20, 20, 20, 20),\n",
              " (22, 22, 22, 22, 23),\n",
              " (24, 24, 24, 24, 25),\n",
              " (24, 24, 24, 25, 25),\n",
              " (24, 24, 25, 25, 25),\n",
              " (23, 23, 23, 23, 12),\n",
              " (23, 23, 23, 12, 12),\n",
              " (23, 23, 12, 12, 12),\n",
              " (23, 12, 12, 12, 12),\n",
              " (26, 26, 27, 27, 27),\n",
              " (26, 27, 27, 27, 27),\n",
              " (36, 36, 36, 36, 37),\n",
              " (36, 36, 36, 37, 37),\n",
              " (36, 36, 37, 37, 37),\n",
              " (36, 37, 37, 37, 37),\n",
              " (39, 39, 39, 39, 40),\n",
              " (39, 39, 39, 40, 40),\n",
              " (39, 39, 40, 40, 40),\n",
              " (39, 40, 40, 40, 40),\n",
              " (2, 2, 4, 2, 2),\n",
              " (2, 4, 2, 2, 2),\n",
              " (2, 2, 2, 2, 8),\n",
              " (2, 2, 2, 8, 2),\n",
              " (2, 2, 8, 2, 2),\n",
              " (2, 2, 2, 2, 4),\n",
              " (2, 2, 2, 4, 2),\n",
              " (2, 2, 2, 2, 5),\n",
              " (2, 2, 2, 5, 5),\n",
              " (2, 2, 5, 5, 5),\n",
              " (2, 5, 5, 5, 5),\n",
              " (5, 5, 5, 6, 2),\n",
              " (2, 2, 2, 3, 2),\n",
              " (2, 2, 2, 3, 3),\n",
              " (2, 2, 3, 3, 4),\n",
              " (2, 3, 3, 4, 5),\n",
              " (3, 3, 4, 5, 2),\n",
              " (3, 4, 5, 2, 2),\n",
              " (4, 5, 2, 2, 2),\n",
              " (2, 2, 5, 5, 6),\n",
              " (2, 5, 5, 6, 6),\n",
              " (5, 6, 6, 6, 2),\n",
              " (6, 6, 6, 2, 2),\n",
              " (6, 6, 2, 2, 2),\n",
              " (2, 2, 2, 2, 6),\n",
              " (2, 2, 2, 6, 3),\n",
              " (2, 2, 6, 3, 3),\n",
              " (2, 6, 3, 3, 4),\n",
              " (6, 3, 3, 4, 5),\n",
              " (3, 4, 5, 5, 6),\n",
              " (4, 5, 5, 6, 6),\n",
              " (5, 5, 6, 6, 2),\n",
              " (5, 6, 6, 2, 2),\n",
              " (2, 2, 2, 12, 26),\n",
              " (2, 2, 12, 26, 16),\n",
              " (2, 12, 26, 16, 17),\n",
              " (26, 27, 28, 29, 30),\n",
              " (27, 28, 29, 30, 34),\n",
              " (28, 29, 30, 34, 35),\n",
              " (29, 30, 34, 35, 36),\n",
              " (30, 34, 35, 36, 37),\n",
              " (34, 35, 36, 37, 37),\n",
              " (2, 2, 2, 5, 2),\n",
              " (2, 2, 5, 2, 2),\n",
              " (2, 5, 2, 2, 2),\n",
              " (6, 6, 6, 6, 2),\n",
              " (2, 2, 2, 12, 12),\n",
              " (17, 17, 17, 18, 18),\n",
              " (17, 17, 18, 18, 18),\n",
              " (17, 18, 18, 18, 18),\n",
              " (29, 29, 29, 29, 29),\n",
              " (34, 34, 34, 34, 35),\n",
              " (34, 34, 34, 35, 35),\n",
              " (37, 37, 37, 38, 38),\n",
              " (37, 37, 38, 38, 38),\n",
              " (37, 38, 38, 38, 38),\n",
              " (2, 2, 3, 3, 2),\n",
              " (2, 3, 3, 2, 2),\n",
              " (3, 3, 2, 2, 2),\n",
              " (3, 2, 2, 2, 4),\n",
              " (2, 2, 3, 2, 3),\n",
              " (2, 3, 2, 3, 2),\n",
              " (2, 2, 2, 4, 1),\n",
              " (2, 2, 4, 1, 2),\n",
              " (2, 4, 1, 2, 2),\n",
              " (4, 1, 2, 2, 2),\n",
              " (39, 39, 41, 41, 41),\n",
              " (39, 41, 41, 41, 41),\n",
              " (41, 41, 41, 41, 41),\n",
              " (5, 5, 6, 6, 3),\n",
              " (5, 6, 6, 3, 3),\n",
              " (6, 6, 3, 3, 4),\n",
              " (6, 3, 3, 4, 3),\n",
              " (2, 2, 3, 3, 5),\n",
              " (2, 3, 3, 5, 5),\n",
              " (2, 2, 3, 5, 6),\n",
              " (2, 3, 5, 6, 2),\n",
              " (2, 2, 2, 5, 6),\n",
              " (2, 2, 5, 6, 2),\n",
              " (2, 2, 3, 5, 5),\n",
              " (2, 3, 5, 5, 6),\n",
              " (3, 5, 5, 6, 5),\n",
              " (4, 4, 5, 5, 6),\n",
              " (5, 5, 6, 6, 7),\n",
              " (5, 6, 6, 7, 3),\n",
              " (6, 6, 7, 3, 5),\n",
              " (6, 7, 3, 5, 6),\n",
              " (7, 3, 5, 6, 4),\n",
              " (3, 5, 6, 4, 4),\n",
              " (5, 6, 4, 4, 3),\n",
              " (6, 4, 4, 3, 3),\n",
              " (4, 4, 3, 3, 5),\n",
              " (5, 5, 5, 1, 3),\n",
              " (5, 5, 1, 3, 3),\n",
              " (5, 1, 3, 3, 4),\n",
              " (5, 5, 6, 6, 4),\n",
              " (5, 6, 6, 4, 4),\n",
              " (6, 6, 4, 4, 3),\n",
              " (4, 4, 3, 3, 4),\n",
              " (4, 3, 3, 4, 4),\n",
              " (5, 5, 5, 6, 7),\n",
              " (5, 5, 6, 7, 7),\n",
              " (5, 6, 7, 7, 7),\n",
              " (6, 7, 7, 7, 7),\n",
              " (7, 7, 7, 7, 7),\n",
              " (7, 8, 7, 7, 7),\n",
              " (8, 7, 7, 7, 0),\n",
              " (7, 7, 7, 0, 7),\n",
              " (7, 7, 0, 7, 7),\n",
              " (7, 0, 7, 7, 7),\n",
              " (7, 7, 7, 3, 5),\n",
              " (7, 7, 3, 5, 5),\n",
              " (7, 3, 5, 5, 3),\n",
              " (5, 5, 5, 3, 6),\n",
              " (5, 5, 3, 6, 3),\n",
              " (5, 5, 3, 3, 3),\n",
              " (3, 3, 5, 5, 6),\n",
              " (6, 5, 5, 5, 4),\n",
              " (5, 5, 5, 4, 4),\n",
              " (5, 5, 4, 4, 5),\n",
              " (5, 4, 4, 5, 5),\n",
              " (5, 5, 5, 7, 2),\n",
              " (5, 5, 7, 2, 2),\n",
              " (2, 2, 4, 2, 4),\n",
              " (2, 4, 2, 4, 2),\n",
              " (4, 2, 4, 2, 3),\n",
              " (2, 4, 2, 3, 2),\n",
              " (4, 2, 3, 2, 2),\n",
              " (2, 3, 2, 2, 3),\n",
              " (3, 2, 2, 3, 2),\n",
              " (2, 32, 2, 3, 2),\n",
              " (32, 2, 3, 2, 32),\n",
              " (2, 3, 2, 32, 2),\n",
              " (3, 2, 32, 2, 32),\n",
              " (2, 32, 2, 32, 2),\n",
              " (32, 2, 32, 2, 32),\n",
              " (32, 2, 32, 2, 2),\n",
              " (2, 32, 2, 2, 32),\n",
              " (32, 2, 2, 32, 2),\n",
              " (2, 2, 32, 2, 2),\n",
              " (2, 2, 32, 2, 32),\n",
              " (2, 32, 2, 32, 3),\n",
              " (32, 2, 32, 3, 2),\n",
              " (2, 32, 3, 2, 2),\n",
              " (32, 3, 2, 2, 32),\n",
              " (3, 2, 2, 32, 2),\n",
              " (32, 2, 32, 2, 33),\n",
              " (33, 2, 33, 2, 31),\n",
              " (2, 33, 2, 31, 31),\n",
              " (33, 2, 31, 31, 2),\n",
              " (2, 31, 31, 2, 32),\n",
              " (31, 31, 2, 32, 2),\n",
              " (31, 2, 32, 2, 31),\n",
              " (2, 32, 2, 31, 2),\n",
              " (32, 2, 31, 2, 33),\n",
              " (2, 31, 2, 33, 2),\n",
              " (31, 2, 33, 2, 32),\n",
              " (2, 33, 2, 32, 2),\n",
              " (33, 2, 32, 2, 32),\n",
              " (32, 2, 32, 2, 31),\n",
              " (2, 2, 33, 2, 32),\n",
              " (2, 33, 2, 32, 32),\n",
              " (33, 2, 32, 32, 2),\n",
              " (2, 32, 32, 2, 33),\n",
              " (32, 32, 2, 33, 32),\n",
              " (32, 2, 33, 32, 2),\n",
              " (2, 33, 32, 2, 2),\n",
              " (33, 32, 2, 2, 32),\n",
              " (32, 2, 2, 32, 33),\n",
              " (2, 2, 32, 33, 2),\n",
              " (2, 32, 33, 2, 2),\n",
              " (32, 33, 2, 2, 33),\n",
              " (33, 2, 2, 33, 2),\n",
              " (2, 2, 33, 2, 33),\n",
              " (2, 33, 2, 33, 2),\n",
              " (2, 32, 2, 33, 2),\n",
              " (32, 2, 33, 2, 2),\n",
              " (2, 33, 2, 2, 33),\n",
              " (33, 2, 33, 2, 33),\n",
              " (33, 2, 33, 2, 2),\n",
              " (33, 2, 2, 33, 4),\n",
              " (2, 2, 33, 4, 2),\n",
              " (2, 33, 4, 2, 4),\n",
              " (3, 2, 3, 2, 32),\n",
              " (3, 2, 32, 2, 33),\n",
              " (2, 33, 2, 2, 32),\n",
              " (33, 2, 2, 32, 2),\n",
              " (2, 2, 32, 2, 31),\n",
              " (32, 2, 31, 2, 2),\n",
              " (2, 31, 2, 2, 33),\n",
              " (31, 2, 2, 33, 2),\n",
              " (2, 33, 2, 32, 31),\n",
              " (33, 2, 32, 31, 2),\n",
              " (33, 2, 33, 2, 32),\n",
              " (33, 2, 32, 2, 33),\n",
              " (32, 2, 33, 2, 3),\n",
              " (2, 33, 2, 3, 2),\n",
              " (33, 2, 3, 2, 11),\n",
              " (2, 3, 2, 11, 3),\n",
              " (3, 2, 11, 3, 2),\n",
              " (2, 11, 3, 2, 2),\n",
              " (11, 3, 2, 2, 3),\n",
              " (2, 2, 2, 2, 33),\n",
              " (2, 2, 2, 33, 2),\n",
              " (2, 2, 33, 2, 2),\n",
              " (2, 33, 2, 2, 2),\n",
              " (33, 2, 2, 2, 33),\n",
              " (2, 32, 2, 32, 32),\n",
              " (32, 2, 2, 32, 32),\n",
              " (2, 2, 32, 32, 2),\n",
              " (2, 32, 32, 2, 32),\n",
              " (32, 32, 2, 32, 2),\n",
              " (32, 2, 32, 32, 2),\n",
              " (2, 32, 32, 2, 2),\n",
              " (32, 32, 2, 2, 32),\n",
              " (2, 32, 2, 2, 33),\n",
              " (32, 2, 2, 33, 2),\n",
              " (2, 33, 2, 33, 33),\n",
              " (33, 2, 33, 33, 2),\n",
              " (2, 33, 33, 2, 2),\n",
              " (33, 33, 2, 2, 33),\n",
              " (2, 2, 33, 2, 31),\n",
              " (32, 2, 33, 2, 32),\n",
              " (32, 2, 33, 2, 33),\n",
              " (33, 2, 32, 2, 11),\n",
              " (3, 2, 3, 2, 3),\n",
              " (3, 2, 3, 2, 31),\n",
              " (2, 3, 2, 31, 2),\n",
              " (3, 2, 3, 2, 43),\n",
              " (2, 3, 2, 43, 2),\n",
              " (3, 2, 43, 2, 43),\n",
              " (2, 43, 2, 43, 2),\n",
              " (43, 2, 43, 2, 3),\n",
              " (2, 43, 2, 3, 2),\n",
              " (43, 2, 3, 2, 3),\n",
              " (3, 3, 2, 2, 3),\n",
              " (3, 2, 3, 2, 2),\n",
              " (2, 2, 5, 2, 5),\n",
              " (2, 5, 2, 5, 5),\n",
              " (5, 2, 5, 5, 2),\n",
              " (2, 5, 5, 2, 32),\n",
              " (5, 5, 2, 32, 32),\n",
              " (5, 2, 32, 32, 2),\n",
              " (2, 32, 32, 2, 3),\n",
              " (32, 32, 2, 3, 2),\n",
              " (32, 2, 3, 2, 5),\n",
              " (2, 3, 2, 5, 2),\n",
              " (2, 5, 2, 5, 2),\n",
              " (5, 2, 5, 2, 5),\n",
              " (2, 5, 5, 2, 5),\n",
              " (5, 5, 2, 5, 2),\n",
              " (5, 2, 5, 2, 2),\n",
              " (2, 2, 5, 2, 6),\n",
              " (2, 5, 2, 6, 2),\n",
              " (5, 2, 6, 2, 2),\n",
              " (2, 6, 2, 2, 6),\n",
              " (6, 2, 2, 6, 2),\n",
              " (2, 33, 2, 5, 6),\n",
              " (33, 2, 5, 6, 2),\n",
              " (2, 5, 6, 2, 5),\n",
              " (5, 6, 2, 5, 2),\n",
              " (6, 2, 5, 2, 5),\n",
              " (5, 5, 2, 5, 5),\n",
              " (5, 2, 5, 2, 6),\n",
              " (2, 5, 2, 6, 5),\n",
              " (5, 2, 6, 5, 2),\n",
              " (2, 6, 2, 5, 2),\n",
              " (6, 2, 5, 2, 6),\n",
              " (5, 2, 6, 2, 5),\n",
              " (2, 5, 2, 5, 6),\n",
              " (5, 2, 5, 6, 2),\n",
              " (2, 2, 5, 2, 11),\n",
              " (2, 5, 5, 2, 2),\n",
              " (5, 5, 2, 2, 5),\n",
              " (5, 2, 2, 5, 5),\n",
              " (2, 2, 5, 5, 2),\n",
              " (2, 5, 2, 2, 11),\n",
              " (5, 2, 2, 11, 2),\n",
              " (2, 2, 11, 2, 11),\n",
              " (2, 11, 2, 11, 5),\n",
              " (11, 2, 11, 5, 2),\n",
              " (2, 11, 5, 2, 5),\n",
              " (11, 5, 2, 5, 5),\n",
              " (2, 5, 5, 2, 6),\n",
              " (5, 5, 2, 6, 5),\n",
              " (2, 6, 2, 5, 5),\n",
              " (6, 2, 5, 5, 2),\n",
              " (5, 5, 2, 6, 2),\n",
              " (5, 5, 2, 2, 2),\n",
              " (5, 2, 2, 2, 5),\n",
              " (2, 5, 2, 2, 5),\n",
              " (5, 2, 2, 5, 2),\n",
              " (2, 5, 5, 5, 2),\n",
              " (5, 5, 5, 2, 2),\n",
              " (2, 5, 2, 2, 32),\n",
              " (5, 2, 2, 32, 5),\n",
              " (2, 2, 32, 5, 32),\n",
              " (2, 32, 5, 32, 33),\n",
              " (32, 5, 32, 33, 5),\n",
              " (5, 32, 33, 5, 2),\n",
              " (32, 33, 5, 2, 32),\n",
              " (2, 5, 2, 32, 2),\n",
              " (5, 2, 32, 2, 5),\n",
              " (2, 32, 2, 5, 32),\n",
              " (32, 2, 5, 32, 32),\n",
              " (2, 5, 32, 32, 2),\n",
              " (5, 32, 32, 2, 5),\n",
              " (32, 32, 2, 5, 2),\n",
              " (32, 2, 5, 2, 2),\n",
              " (2, 2, 5, 2, 33),\n",
              " (2, 5, 2, 33, 33),\n",
              " (5, 2, 33, 33, 2),\n",
              " (2, 33, 33, 2, 5),\n",
              " (33, 33, 2, 5, 2),\n",
              " (2, 5, 2, 33, 2),\n",
              " (5, 2, 33, 2, 5),\n",
              " (2, 33, 2, 5, 2),\n",
              " (33, 2, 5, 2, 2),\n",
              " (2, 5, 2, 33, 32),\n",
              " (5, 2, 33, 32, 5),\n",
              " (2, 33, 32, 5, 32),\n",
              " (33, 32, 5, 32, 33),\n",
              " (32, 5, 32, 33, 32),\n",
              " (5, 32, 33, 32, 33),\n",
              " (32, 33, 32, 33, 5),\n",
              " (33, 32, 33, 5, 31),\n",
              " (32, 33, 5, 31, 32),\n",
              " (33, 5, 31, 32, 5),\n",
              " (5, 31, 32, 5, 32),\n",
              " (31, 5, 32, 32, 33),\n",
              " (5, 32, 32, 33, 5),\n",
              " (32, 32, 33, 5, 32),\n",
              " (32, 33, 5, 32, 33),\n",
              " (33, 5, 32, 33, 5),\n",
              " (5, 32, 33, 5, 33),\n",
              " (32, 33, 5, 33, 31),\n",
              " (33, 5, 33, 31, 5),\n",
              " (5, 33, 31, 5, 33),\n",
              " (33, 31, 5, 33, 31),\n",
              " (31, 5, 33, 31, 33),\n",
              " (5, 33, 31, 33, 5),\n",
              " (33, 31, 33, 5, 33),\n",
              " (31, 33, 5, 33, 31),\n",
              " (33, 5, 33, 31, 32),\n",
              " (33, 32, 32, 5, 33),\n",
              " (32, 32, 5, 33, 32),\n",
              " (32, 5, 33, 32, 5),\n",
              " (5, 33, 32, 5, 33),\n",
              " (33, 32, 5, 33, 11),\n",
              " (32, 5, 33, 11, 5),\n",
              " (5, 33, 11, 5, 2),\n",
              " (33, 11, 5, 2, 2),\n",
              " (11, 5, 2, 2, 2),\n",
              " (2, 5, 2, 33, 31),\n",
              " (5, 2, 33, 31, 5),\n",
              " (2, 33, 31, 5, 32),\n",
              " (33, 31, 5, 32, 33),\n",
              " (31, 5, 32, 33, 31),\n",
              " (5, 32, 33, 31, 33),\n",
              " (32, 33, 31, 33, 5),\n",
              " (33, 31, 33, 5, 31),\n",
              " (31, 33, 5, 31, 32),\n",
              " (5, 31, 32, 5, 33),\n",
              " (31, 32, 5, 33, 33),\n",
              " (32, 5, 33, 33, 32),\n",
              " (5, 33, 33, 32, 33),\n",
              " (33, 33, 5, 32, 31),\n",
              " (33, 5, 32, 31, 33),\n",
              " (5, 32, 31, 33, 32),\n",
              " (32, 31, 33, 32, 5),\n",
              " (31, 33, 32, 5, 11),\n",
              " (33, 32, 5, 11, 2),\n",
              " (32, 5, 11, 2, 5),\n",
              " (5, 11, 2, 5, 2),\n",
              " (11, 2, 5, 2, 2),\n",
              " (2, 2, 32, 5, 2),\n",
              " (2, 32, 5, 2, 2),\n",
              " (32, 5, 2, 2, 33),\n",
              " (5, 2, 2, 33, 2),\n",
              " (2, 2, 33, 2, 5),\n",
              " (2, 2, 2, 5, 32),\n",
              " (2, 2, 5, 32, 32),\n",
              " (32, 32, 2, 5, 32),\n",
              " (32, 2, 5, 32, 2),\n",
              " (2, 5, 32, 2, 32),\n",
              " (5, 32, 2, 32, 5),\n",
              " (32, 2, 32, 5, 2),\n",
              " (2, 32, 5, 2, 32),\n",
              " (32, 5, 2, 32, 2),\n",
              " (2, 32, 2, 5, 2),\n",
              " (32, 2, 5, 2, 11),\n",
              " (2, 2, 2, 2, 32),\n",
              " (2, 2, 2, 32, 32),\n",
              " (2, 2, 32, 32, 32),\n",
              " (2, 32, 32, 32, 33),\n",
              " (32, 32, 32, 33, 33),\n",
              " (32, 32, 33, 33, 33),\n",
              " (32, 33, 33, 33, 32),\n",
              " (33, 33, 33, 32, 33),\n",
              " (33, 31, 33, 31, 32),\n",
              " (31, 33, 31, 32, 32),\n",
              " (33, 31, 32, 32, 32),\n",
              " (31, 32, 32, 32, 33),\n",
              " (32, 33, 33, 33, 33),\n",
              " (33, 33, 33, 33, 33),\n",
              " (33, 33, 33, 33, 32),\n",
              " (33, 33, 33, 32, 32),\n",
              " (33, 33, 32, 32, 32),\n",
              " (33, 32, 32, 32, 33),\n",
              " (2, 2, 2, 33, 32),\n",
              " (2, 2, 33, 32, 2),\n",
              " (33, 32, 2, 2, 2),\n",
              " (32, 2, 2, 2, 32),\n",
              " (2, 2, 2, 32, 2),\n",
              " (2, 32, 2, 2, 2),\n",
              " (32, 2, 2, 2, 2),\n",
              " (33, 2, 2, 2, 2),\n",
              " (2, 2, 2, 33, 33),\n",
              " (2, 2, 33, 33, 33),\n",
              " (32, 32, 32, 32, 32),\n",
              " (32, 32, 32, 32, 33),\n",
              " (33, 33, 33, 33, 2),\n",
              " (33, 33, 33, 2, 2),\n",
              " (33, 33, 2, 2, 2),\n",
              " (32, 33, 33, 31, 33),\n",
              " (33, 33, 31, 33, 33),\n",
              " (33, 31, 33, 33, 33),\n",
              " (31, 33, 33, 33, 32),\n",
              " (33, 33, 32, 32, 33),\n",
              " (33, 32, 32, 33, 32),\n",
              " (32, 32, 33, 32, 33),\n",
              " (32, 33, 32, 33, 32),\n",
              " (33, 32, 33, 32, 31),\n",
              " (32, 33, 32, 31, 33),\n",
              " (33, 32, 31, 33, 31),\n",
              " (32, 31, 33, 31, 33),\n",
              " (31, 33, 31, 33, 33),\n",
              " (33, 31, 33, 33, 32),\n",
              " (31, 2, 32, 2, 2),\n",
              " (2, 2, 2, 2, 31),\n",
              " (31, 2, 2, 2, 2),\n",
              " (2, 33, 2, 31, 2),\n",
              " (33, 2, 31, 2, 33),\n",
              " (31, 2, 33, 2, 2),\n",
              " (2, 2, 2, 33, 5),\n",
              " (33, 32, 31, 5, 3),\n",
              " (32, 31, 5, 3, 5),\n",
              " (31, 5, 3, 5, 11),\n",
              " (5, 3, 5, 11, 11),\n",
              " (3, 5, 11, 11, 11),\n",
              " (5, 11, 11, 11, 11),\n",
              " (11, 11, 11, 11, 33),\n",
              " (11, 11, 11, 33, 11),\n",
              " (11, 11, 33, 11, 5),\n",
              " (11, 33, 11, 5, 32),\n",
              " (33, 11, 5, 32, 32),\n",
              " (11, 5, 32, 32, 33),\n",
              " (5, 32, 32, 33, 11),\n",
              " (32, 32, 33, 11, 11),\n",
              " (32, 33, 11, 11, 11),\n",
              " (11, 5, 5, 33, 11),\n",
              " (5, 5, 33, 11, 11),\n",
              " (5, 33, 11, 11, 11),\n",
              " (33, 11, 11, 11, 11),\n",
              " (11, 11, 11, 33, 32),\n",
              " (11, 11, 33, 32, 31),\n",
              " (11, 33, 32, 31, 33),\n",
              " (33, 32, 31, 33, 33),\n",
              " (32, 31, 33, 33, 32),\n",
              " (31, 33, 33, 32, 11),\n",
              " (33, 33, 32, 11, 31),\n",
              " (33, 32, 11, 31, 33),\n",
              " (32, 11, 31, 33, 32),\n",
              " (11, 31, 33, 32, 32),\n",
              " (32, 5, 3, 5, 11),\n",
              " (5, 3, 5, 11, 5),\n",
              " (3, 5, 11, 5, 32),\n",
              " (5, 11, 5, 32, 33),\n",
              " (11, 5, 32, 33, 33),\n",
              " (5, 32, 33, 33, 33),\n",
              " (32, 33, 33, 33, 5),\n",
              " (33, 33, 33, 5, 6),\n",
              " (33, 33, 5, 6, 5),\n",
              " (33, 5, 6, 5, 5),\n",
              " (6, 5, 5, 5, 11),\n",
              " (5, 5, 5, 11, 11),\n",
              " (5, 5, 11, 11, 5),\n",
              " (5, 11, 11, 5, 5),\n",
              " (11, 11, 11, 5, 6),\n",
              " (11, 11, 5, 6, 5),\n",
              " (5, 5, 5, 5, 11),\n",
              " (5, 5, 5, 11, 6),\n",
              " (5, 5, 11, 6, 5),\n",
              " (5, 11, 6, 5, 5),\n",
              " (11, 6, 5, 5, 5),\n",
              " (3, 3, 3, 3, 2),\n",
              " (3, 3, 3, 2, 2),\n",
              " (3, 5, 5, 4, 4),\n",
              " (4, 4, 5, 5, 4),\n",
              " (4, 5, 5, 4, 4),\n",
              " (5, 5, 4, 4, 3),\n",
              " (5, 4, 4, 3, 4),\n",
              " (4, 4, 3, 4, 4),\n",
              " (4, 3, 4, 4, 5),\n",
              " (3, 4, 4, 5, 3),\n",
              " (4, 4, 5, 3, 3),\n",
              " (4, 5, 3, 3, 3),\n",
              " (5, 5, 5, 6, 1),\n",
              " (5, 5, 6, 1, 3),\n",
              " (5, 6, 1, 3, 5),\n",
              " (6, 1, 3, 5, 5),\n",
              " (1, 3, 5, 5, 5),\n",
              " (5, 5, 5, 6, 44),\n",
              " (5, 5, 6, 44, 44),\n",
              " (5, 6, 44, 44, 45),\n",
              " (6, 44, 44, 45, 45),\n",
              " (5, 5, 6, 0, 1),\n",
              " (5, 6, 0, 1, 3),\n",
              " (6, 0, 1, 3, 3),\n",
              " (0, 1, 3, 3, 3),\n",
              " (1, 3, 3, 3, 3),\n",
              " (3, 6, 31, 4, 5),\n",
              " (6, 31, 4, 5, 33),\n",
              " (31, 4, 5, 33, 6),\n",
              " (4, 5, 33, 6, 11),\n",
              " (5, 33, 6, 11, 0),\n",
              " (33, 6, 11, 0, 0),\n",
              " (6, 11, 0, 0, 0),\n",
              " (11, 0, 0, 0, 0),\n",
              " (0, 0, 0, 0, 3),\n",
              " (0, 0, 0, 3, 3),\n",
              " (0, 0, 3, 3, 5),\n",
              " (0, 3, 3, 5, 3),\n",
              " (4, 4, 5, 3, 5),\n",
              " (4, 5, 3, 5, 6),\n",
              " (5, 3, 5, 6, 3),\n",
              " (3, 5, 6, 3, 6),\n",
              " (5, 6, 3, 6, 3),\n",
              " (6, 3, 6, 3, 5),\n",
              " (5, 5, 6, 4, 4),\n",
              " (5, 6, 4, 4, 7),\n",
              " (6, 4, 4, 7, 3),\n",
              " (4, 4, 7, 3, 3),\n",
              " (4, 7, 3, 3, 3),\n",
              " (7, 3, 3, 3, 31),\n",
              " (3, 3, 3, 31, 2),\n",
              " (3, 3, 31, 2, 5),\n",
              " (3, 31, 2, 5, 5),\n",
              " (31, 2, 5, 5, 5),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "print(len(dataloader)) # regarding to batch size\n",
        "\n",
        "\n",
        "for step, (seq) in enumerate(dataloader):\n",
        "  print(seq[0].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyvu0ClgBRC3",
        "outputId": "678f2978-1a35-4634-e0f4-4aacf9ebc35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189\n",
            "torch.Size([128, 5, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, lr_step=(30,60,90,100), lr_decay_ratio=0.5):\n",
        "    \"\"\"Adjust the learning rate based on the epoch number.\"\"\"\n",
        "    if epoch == 0:\n",
        "        optimizer.param_groups[0]['lr'] /= 8\n",
        "    elif epoch in [1, 2, 3]:  # in step five , we finish warm up ,and start normal learning rate\n",
        "        optimizer.param_groups[0]['lr'] *= 2\n",
        "    if epoch in lr_step: # in these steps , we are geting close to optimal point so we need to have shorter step\n",
        "        optimizer.param_groups[0]['lr'] *= lr_decay_ratio\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "HHyNWe1DfYPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 60\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Loss and optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "iHdDOptGaLCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.train()\n",
        "start_time = time.time()\n",
        "total_step = len(dataloader)\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Processing Rows\"):  # Loop over the dataset multiple times\n",
        "    optimizer = adjust_learning_rate(optimizer, epoch)\n",
        "    train_loss = 0\n",
        "    for step, (seq) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        seq = seq[0].clone().detach().view(-1, window_size, input_size).to(device)\n",
        "        output = model(seq)\n",
        "        loss = criterion(output, seq.to(device))\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, num_epochs, (train_loss*100) / total_step))\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ_t5bz35SYq",
        "outputId": "3d9af16b-6f03-42dd-f303-253a5b95d78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows:   2%|▏         | 1/60 [00:01<00:59,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/60], train_loss: 0.0978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:   3%|▎         | 2/60 [00:01<00:54,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/60], train_loss: 0.0976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:   5%|▌         | 3/60 [00:02<00:52,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/60], train_loss: 0.0978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:   7%|▋         | 4/60 [00:03<00:54,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/60], train_loss: 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:   8%|▊         | 5/60 [00:04<00:56,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/60], train_loss: 0.0984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  10%|█         | 6/60 [00:05<00:54,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/60], train_loss: 0.0977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  12%|█▏        | 7/60 [00:06<00:51,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/60], train_loss: 0.0974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  13%|█▎        | 8/60 [00:07<00:49,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/60], train_loss: 0.0967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  15%|█▌        | 9/60 [00:08<00:47,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/60], train_loss: 0.0963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  17%|█▋        | 10/60 [00:09<00:46,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/60], train_loss: 0.0960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  18%|█▊        | 11/60 [00:10<00:44,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/60], train_loss: 0.0959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  20%|██        | 12/60 [00:11<00:43,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/60], train_loss: 0.0954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  22%|██▏       | 13/60 [00:12<00:42,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/60], train_loss: 0.0947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  23%|██▎       | 14/60 [00:13<00:41,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/60], train_loss: 0.0943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  25%|██▌       | 15/60 [00:14<00:40,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/60], train_loss: 0.0938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  27%|██▋       | 16/60 [00:14<00:40,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/60], train_loss: 0.0935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  28%|██▊       | 17/60 [00:15<00:40,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/60], train_loss: 0.0933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  30%|███       | 18/60 [00:17<00:41,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/60], train_loss: 0.0930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  32%|███▏      | 19/60 [00:18<00:40,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/60], train_loss: 0.0924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  33%|███▎      | 20/60 [00:18<00:38,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/60], train_loss: 0.0924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  35%|███▌      | 21/60 [00:19<00:36,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/60], train_loss: 0.0917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  37%|███▋      | 22/60 [00:20<00:35,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/60], train_loss: 0.0918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  38%|███▊      | 23/60 [00:21<00:34,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/60], train_loss: 0.0913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  40%|████      | 24/60 [00:22<00:33,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/60], train_loss: 0.0912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  42%|████▏     | 25/60 [00:23<00:32,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/60], train_loss: 0.0907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  43%|████▎     | 26/60 [00:24<00:31,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/60], train_loss: 0.0904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  45%|████▌     | 27/60 [00:25<00:30,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/60], train_loss: 0.0903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  47%|████▋     | 28/60 [00:26<00:29,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/60], train_loss: 0.0898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  48%|████▊     | 29/60 [00:27<00:28,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/60], train_loss: 0.0899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  50%|█████     | 30/60 [00:28<00:28,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/60], train_loss: 0.0891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  52%|█████▏    | 31/60 [00:29<00:28,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/60], train_loss: 0.0881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  53%|█████▎    | 32/60 [00:30<00:28,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/60], train_loss: 0.0877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  55%|█████▌    | 33/60 [00:31<00:26,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/60], train_loss: 0.0876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  57%|█████▋    | 34/60 [00:32<00:24,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/60], train_loss: 0.0873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  58%|█████▊    | 35/60 [00:33<00:23,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/60], train_loss: 0.0871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  60%|██████    | 36/60 [00:34<00:22,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/60], train_loss: 0.0872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  62%|██████▏   | 37/60 [00:34<00:21,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/60], train_loss: 0.0871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  63%|██████▎   | 38/60 [00:35<00:20,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/60], train_loss: 0.0869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  65%|██████▌   | 39/60 [00:36<00:19,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/60], train_loss: 0.0866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  67%|██████▋   | 40/60 [00:37<00:18,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/60], train_loss: 0.0864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  68%|██████▊   | 41/60 [00:38<00:17,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/60], train_loss: 0.0862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  70%|███████   | 42/60 [00:39<00:16,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/60], train_loss: 0.0865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  72%|███████▏  | 43/60 [00:40<00:15,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/60], train_loss: 0.0864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  73%|███████▎  | 44/60 [00:41<00:15,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/60], train_loss: 0.0861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  75%|███████▌  | 45/60 [00:42<00:15,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/60], train_loss: 0.0860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  77%|███████▋  | 46/60 [00:43<00:13,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/60], train_loss: 0.0863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  78%|███████▊  | 47/60 [00:44<00:12,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/60], train_loss: 0.0860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  80%|████████  | 48/60 [00:45<00:11,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/60], train_loss: 0.0858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  82%|████████▏ | 49/60 [00:46<00:10,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/60], train_loss: 0.0850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  83%|████████▎ | 50/60 [00:47<00:09,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/60], train_loss: 0.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  85%|████████▌ | 51/60 [00:48<00:08,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [51/60], train_loss: 0.0853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  87%|████████▋ | 52/60 [00:48<00:07,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [52/60], train_loss: 0.0850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  88%|████████▊ | 53/60 [00:49<00:06,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [53/60], train_loss: 0.0851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  90%|█████████ | 54/60 [00:51<00:06,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [54/60], train_loss: 0.0850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  92%|█████████▏| 55/60 [00:51<00:04,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [55/60], train_loss: 0.0848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  93%|█████████▎| 56/60 [00:52<00:03,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [56/60], train_loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  95%|█████████▌| 57/60 [00:54<00:03,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [57/60], train_loss: 0.0845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  97%|█████████▋| 58/60 [00:55<00:02,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [58/60], train_loss: 0.0844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Rows:  98%|█████████▊| 59/60 [00:55<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [59/60], train_loss: 0.0842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 60/60 [00:56<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [60/60], train_loss: 0.0842\n",
            "elapsed_time: 56.911s\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to save datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_7Qgbv7Qp7AW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "6f47c6f9-172b-45e7-e0ba-deb4582802a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-72bb6fb7deac>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive to save datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/BGL1_parameters.pth')"
      ],
      "metadata": {
        "id": "G_xbylKoiwAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EVALUATION**"
      ],
      "metadata": {
        "id": "fTKswHBdbfBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "in cpu\n",
        "```\n",
        "my_model = model.load_state_dict(torch.load('model_parameters.pth', map_location=torch.device(device)))\n",
        "\n",
        "# Put the model in evaluation mode if necessary\n",
        "model.eval()\n",
        "```\n",
        "\n",
        "in cuda\n",
        "\n",
        "\n",
        "```\n",
        "model.load_state_dict(torch.load('model_parameters.pth'))\n",
        "\n",
        "# Put the model in evaluation mode if necessary\n",
        "model.eval()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ppqwoB9ITsac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "id": "wm0bhoHL5yjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef17744-1a68-4d1e-9335-045ac53dde22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "736"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(name):\n",
        "    window_size = sequence_length\n",
        "    hdfs = {} #store the unique sequences and their counts.\n",
        "    length = 0\n",
        "    with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            line = [int(i) for i in row.strip().split()]\n",
        "            hdfs[tuple(line)] = hdfs.get(tuple(line), 0) + 1   #If the tuple is not present in the dictionary, hdfs.get(tuple(ln), 0) returns 0, and the code initializes the count to 1.\n",
        "            length += 1\n",
        "            # hdfs.append(tuple(line))\n",
        "    print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
        "    return hdfs, length"
      ],
      "metadata": {
        "id": "zeXyQLVK5zAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_normal_loader, test_normal_length = generate('Xnorm_test_index')\n",
        "test_abnormal_loader, test_abnormal_length = generate('Xabnorm_test_index')"
      ],
      "metadata": {
        "id": "pUyqMSfg7Ba-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3efa4cc-88fe-4ec4-b510-d7557b278aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(Xnorm_test_index): 17191\n",
            "Number of sessions(Xabnorm_test_index): 3595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(threshold):\n",
        "  # Test the model\n",
        "  model.eval()\n",
        "\n",
        "  TP = 0\n",
        "  FP = 0\n",
        "\n",
        "  start_time = time.time()\n",
        "  with torch.no_grad():\n",
        "      for line in tqdm(test_normal_loader.keys(), desc=\"Processing Rows\"):\n",
        "          for i in range(len(line) - window_size):\n",
        "              session = line[i:i + window_size]\n",
        "              seq = [embeddings[temp] for temp in session]\n",
        "              seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "              output = model(seq)\n",
        "\n",
        "              loss = criterion(output, seq)\n",
        "\n",
        "              if (loss.cpu().detach().numpy()>threshold):\n",
        "                FP += test_normal_loader[line] # numbers of that set we have\n",
        "                break\n",
        "  with torch.no_grad():\n",
        "      for line in tqdm(test_abnormal_loader.keys(), desc=\"Processing Rows\"):\n",
        "          losses = 0\n",
        "          for i in range(len(line) - window_size):\n",
        "              session = line[i:i + window_size]\n",
        "              seq = [embeddings[temp] for temp in session]\n",
        "              seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "              output = model(seq)\n",
        "\n",
        "              loss = criterion(output, seq)\n",
        "              losses += loss.cpu().detach().numpy()\n",
        "          if (losses>threshold):\n",
        "            TP += test_abnormal_loader[line]\n",
        "\n",
        "  elapsed_time = time.time() - start_time\n",
        "  print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "  # Compute precision, recall and F1-measure\n",
        "  FN = test_abnormal_length - TP\n",
        "  P = 100 * TP / (TP + FP)\n",
        "  R = 100 * TP / (TP + FN)\n",
        "  F1 = 2 * P * R / (P + R)\n",
        "  print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
        "  print('Finished Predicting')"
      ],
      "metadata": {
        "id": "xtAPzH7h9cZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = [0.005,0.0055,0.006,0.0065]\n",
        "for i in threshold:\n",
        "  print('-------------------------------------------------------------------------')\n",
        "  print('threshold = ',i)\n",
        "  evaluation(i)"
      ],
      "metadata": {
        "id": "dCegQ5i4-ZKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375c8e88-9dfb-420f-b66d-cdf7a20bbf22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------\n",
            "threshold =  0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 17191/17191 [03:36<00:00, 79.39it/s]\n",
            "Processing Rows: 100%|██████████| 3595/3595 [00:44<00:00, 80.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 261.170s\n",
            "false positive (FP): 103, false negative (FN): 419, Precision: 99.484%, Recall: 97.932%, F1-measure: 98.702%\n",
            "Finished Predicting\n",
            "-------------------------------------------------------------------------\n",
            "threshold =  0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 17191/17191 [03:35<00:00, 79.82it/s]\n",
            "Processing Rows: 100%|██████████| 3595/3595 [00:45<00:00, 79.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 260.403s\n",
            "false positive (FP): 58, false negative (FN): 437, Precision: 99.708%, Recall: 97.843%, F1-measure: 98.767%\n",
            "Finished Predicting\n",
            "-------------------------------------------------------------------------\n",
            "threshold =  0.006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 17191/17191 [03:34<00:00, 79.96it/s]\n",
            "Processing Rows: 100%|██████████| 3595/3595 [00:44<00:00, 80.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 259.901s\n",
            "false positive (FP): 26, false negative (FN): 452, Precision: 99.869%, Recall: 97.769%, F1-measure: 98.808%\n",
            "Finished Predicting\n",
            "-------------------------------------------------------------------------\n",
            "threshold =  0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 17191/17191 [03:33<00:00, 80.56it/s]\n",
            "Processing Rows: 100%|██████████| 3595/3595 [00:44<00:00, 80.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 258.241s\n",
            "false positive (FP): 15, false negative (FN): 460, Precision: 99.924%, Recall: 97.730%, F1-measure: 98.815%\n",
            "Finished Predicting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = [0.0067,0.0069]\n",
        "for i in threshold:\n",
        "  print('-------------------------------------------------------------------------')\n",
        "  print('threshold = ', i)\n",
        "  evaluation(i)"
      ],
      "metadata": {
        "id": "1_m-pTgN9pGf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "509fb6e6-9892-493b-ce40-2032fbdc0718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------\n",
            "threshold =  0.0067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 17191/17191 [03:33<00:00, 80.44it/s]\n",
            "Processing Rows: 100%|██████████| 3595/3595 [00:45<00:00, 79.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 258.861s\n",
            "false positive (FP): 15, false negative (FN): 470, Precision: 99.924%, Recall: 97.680%, F1-measure: 98.790%\n",
            "Finished Predicting\n",
            "-------------------------------------------------------------------------\n",
            "threshold =  0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows:   9%|▉         | 1620/17191 [00:20<03:17, 78.82it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-03b25772ab91>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'threshold = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-2e5be927b63a>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(threshold)\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m               \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m               \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-c677fc1448c9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(encoded.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# output of last cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#print(encoded.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minput_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1599\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXQ0F98wQo78"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}