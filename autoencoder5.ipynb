{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpTXO31cl2kI5YYa8Cv3a/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/autoencoder5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIppU8PXpm-J",
        "outputId": "c63f4116-4b32-48f7-a052-0d1624e084ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# we upload, in case that we cant parse logs(a lot of time and ram consumption)\n",
        "\n",
        "# Mount Google Drive to save datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#copy log file\n",
        "!cp '/content/drive/MyDrive/zHDFS2/logs_train' '/content/'\n",
        "!cp '/content/drive/MyDrive/zHDFS2/logs_ntest' '/content/'\n",
        "!cp '/content/drive/MyDrive/zHDFS2/logs_atest' '/content/'\n",
        "!cp '/content/drive/MyDrive/zHDFS2/log2index' '/content/'\n",
        "!cp '/content/drive/MyDrive/zHDFS2/reduced_embeddings' '/content/'\n"
      ],
      "metadata": {
        "id": "jIINrPiNqE_a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "jd9WP1rSrLSh"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/reduced_embeddings', 'r') as json_file:\n",
        "    embeddings = json.load(json_file)"
      ],
      "metadata": {
        "id": "gG19wcyUyWyv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySn0vNy33IL_",
        "outputId": "7b776512-3943-4c3d-a4b7-c09f44693cd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all unique templates in our train datasets\n",
        "\n",
        "dataset = 'logs_train'\n",
        "templates = set()\n",
        "\n",
        "with open('/content/' + dataset, 'r') as f:\n",
        "        for row in f:\n",
        "          for temp in row.split():\n",
        "            templates.add(temp)\n",
        "\n",
        "print(sorted(templates))\n",
        "print('nember of templates : ',len(templates))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxhTbLkMzdpG",
        "outputId": "bbb0c195-4504-4004-ea7a-9e6204c199a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '10', '11', '12', '13', '14', '15', '16', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "nember of templates :  17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all unique templates in our test datasets\n",
        "\n",
        "datasets = ['logs_ntest','logs_atest']\n",
        "templates = set()\n",
        "\n",
        "for dataset in datasets:\n",
        "  with open('/content/' + dataset, 'r') as f:\n",
        "          for row in f:\n",
        "            for temp in row.split():\n",
        "              templates.add(temp)\n",
        "\n",
        "print(sorted(templates))\n",
        "print('nember of templates : ',len(templates))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTykxgPp0Q3i",
        "outputId": "8c0db4b3-a86c-4d11-ffa4-a8f3c8c08c6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '6', '7', '8', '9']\n",
            "nember of templates :  52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "name = 'logs_train'\n",
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "#outputs = []\n",
        "\n",
        "with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            num_sessions += 1\n",
        "            line = [ embeddings[int(i)] for i in row.strip().split()]\n",
        "            for i in range(len(line) - window_size):\n",
        "                inputs.append(line[i:i + window_size])\n",
        "                #outputs.append(line[i + window_size])\n",
        "\n",
        "print('Number of sessions({}): {}'.format(name, num_sessions))\n",
        "print('Number of seqs({}): {}'.format(name, len(inputs)))\n",
        "#dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs))\n",
        "dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIwHnSfe0f3k",
        "outputId": "1a7191c4-0687-4d08-bc49-63ac1a59503d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(logs_train): 446578\n",
            "Number of seqs(logs_train): 4704000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnJelwhq5M9E",
        "outputId": "7d740f5a-225d-4d1e-d602-00b3d326ed58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.3891972303390503, 0.12810246646404266, -0.07853731513023376, -0.10766388475894928, 0.23173417150974274, -0.08228960633277893, 0.017653826624155045, -0.030952107161283493, 0.040218982845544815, 0.030139772221446037], [0.38630372285842896, -0.12673094868659973, -0.11596252024173737, -0.18444840610027313, 0.08815333247184753, -0.02099493145942688, 0.10797911882400513, -0.09289209544658661, -0.05879585072398186, 0.03421926125884056], [-0.3891972303390503, 0.12810246646404266, -0.07853731513023376, -0.10766388475894928, 0.23173417150974274, -0.08228960633277893, 0.017653826624155045, -0.030952107161283493, 0.040218982845544815, 0.030139772221446037], [-0.3891972303390503, 0.12810246646404266, -0.07853731513023376, -0.10766388475894928, 0.23173417150974274, -0.08228960633277893, 0.017653826624155045, -0.030952107161283493, 0.040218982845544815, 0.030139772221446037], [-0.21878856420516968, -0.2136467546224594, 0.04706411808729172, 0.20318950712680817, -0.24529194831848145, 0.021229250356554985, 0.27597615122795105, -0.07408243417739868, 0.07361564040184021, 0.026193594560027122], [-0.21878856420516968, -0.2136467546224594, 0.04706411808729172, 0.20318950712680817, -0.24529194831848145, 0.021229250356554985, 0.27597615122795105, -0.07408243417739868, 0.07361564040184021, 0.026193594560027122], [-0.22215509414672852, -0.19491028785705566, -0.1123443990945816, 0.38605520129203796, 0.0065366122871637344, 0.06525123864412308, 0.11776842176914215, 0.06551230698823929, -0.07805070281028748, -0.0737701952457428], [-0.22215509414672852, -0.19491028785705566, -0.1123443990945816, 0.38605520129203796, 0.0065366122871637344, 0.06525123864412308, 0.11776842176914215, 0.06551230698823929, -0.07805070281028748, -0.0737701952457428], [-0.21878856420516968, -0.2136467546224594, 0.04706411808729172, 0.20318950712680817, -0.24529194831848145, 0.021229250356554985, 0.27597615122795105, -0.07408243417739868, 0.07361564040184021, 0.026193594560027122], [-0.22215509414672852, -0.19491028785705566, -0.1123443990945816, 0.38605520129203796, 0.0065366122871637344, 0.06525123864412308, 0.11776842176914215, 0.06551230698823929, -0.07805070281028748, -0.0737701952457428]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i0YPVmq8besu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers): #embedding dimensions\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.rnn = nn.LSTM(input_dim, hid_dim, n_layers, bidirectional=True,batch_first=True)\n",
        "\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "        #src = [src len, batch size]\n",
        "\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(src)\n",
        "\n",
        "        #outputs = [batch size,src len, hid dim * n directions]\n",
        "        #hidden = [batch size,n layers * n directions,  hid dim]\n",
        "        #cell = [batch size, n layers * n directions, hid dim]\n",
        "\n",
        "        #outputs are always from the top hidden layer\n",
        "\n",
        "        return outputs[:,-1:,:]  #outputs[:,-1:,:]=output of the end of blocks which is concatenated of two directions(we use -1: for keeping the dimensions)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers):       #input _dim depends on encoder's output\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.rnn = nn.LSTM(input_dim, hid_dim, n_layers, bidirectional=False,batch_first=True)\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "        #src = [src len, batch size]\n",
        "        src = torch.tile(src, (1, 10, 1)) # give the output of encoder to each cell of decoder\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(src)\n",
        "\n",
        "        #outputs = [batch size,src len, hid dim * n directions]\n",
        "        #hidden = [batch size,n layers * n directions,  hid dim]\n",
        "        #cell = [batch size, n layers * n directions, hid dim]\n",
        "\n",
        "        #outputs are always from the top hidden layer\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src):\n",
        "        encoded = self.encoder(src)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ],
      "metadata": {
        "id": "0dSvcyAmbfOF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(10,32,1)\n",
        "decoder = Decoder(64,10,1)\n",
        "model = Autoencoder(encoder, decoder).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj2LqqcP2wRs",
        "outputId": "01bd3703-4653-41ed-8572-c262990cb3bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Autoencoder(\n",
              "  (encoder): Encoder(\n",
              "    (rnn): LSTM(10, 32, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (rnn): LSTM(64, 10, batch_first=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = torch.rand(1, 10, 10).to(device) #(batch,sequence_length,embedding)\n",
        "output= model(input_data)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fggcANCy2y0e",
        "outputId": "8f02867a-c3c3-4301-fbbf-a61e10f01bd1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of parameters\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of Parameters: {num_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIEBmDYf29xi",
        "outputId": "f8f304ff-239e-480a-e3f2-e67c15e3b2fb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Parameters: 14304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=128)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "SyLp6yyx4PGb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataloader) # regard to batch size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7LwOnm84llY",
        "outputId": "47d12245-9acc-4ad3-9ca1-3c9a1282cfed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36750"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step, (seq) in enumerate(dataloader):\n",
        "  print(seq[0].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOy2RaCB6AWx",
        "outputId": "4a2c7126-d1f0-4273-8b7c-9a9e363ef6fc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epochs = 100\n",
        "input_size = 10 # embedding size\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "total_step = len(dataloader)\n",
        "for epoch in range(num_epochs):  # Loop over the dataset multiple times\n",
        "    train_loss = 0\n",
        "    for step, (seq) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        seq = seq[0].clone().detach().view(-1, window_size, input_size).to(device)\n",
        "        output = model(seq)\n",
        "        loss = criterion(output, seq.to(device))\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss / total_step))\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "print('Finished Training')\n",
        ""
      ],
      "metadata": {
        "id": "vQ_t5bz35SYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq[0].reshape(1,10,10)"
      ],
      "metadata": {
        "id": "GqHsHKB-_6U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = seq[0].reshape(1,10,10)\n",
        "output= model(input_data)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb89rs3K_o5s",
        "outputId": "610815f0-8447-443b-ab00-298e3c0ad9fe"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = input_data.cpu().detach().numpy()[0] - output.cpu().detach().numpy()[0]"
      ],
      "metadata": {
        "id": "d4eov5n9Ff2p"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(a[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsKxnMk4FsUc",
        "outputId": "1f311ab2-b748-47c6-dd69-4dc07c72c17c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.073634475"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(seq[0][0]-seq[0][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCGvYagOF0Jn",
        "outputId": "9f45dd8e-6ed8-4eef-fe01-af5184312c0d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.1362, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(input_data.cpu().detach().numpy()[0],output.cpu().detach().numpy()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn0hgd1PGcuG",
        "outputId": "649c61a7-960a-4707-cc83-a2981cd03b46"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.9610373 ,  0.02295969,  0.04059182, -0.00797994,  0.06608871,\n",
              "        -0.11450423,  0.06367902, -0.538867  , -0.54200083, -0.5351264 ],\n",
              "       [ 0.06265119,  0.99223757,  0.66928744,  0.9965995 ,  0.65959114,\n",
              "         0.99361   ,  0.64131004, -0.45647153, -0.4406333 , -0.45387778],\n",
              "       [ 0.20867422,  0.61992234,  0.99156976,  0.6591899 ,  0.9915739 ,\n",
              "         0.6456291 ,  0.9953552 , -0.03214208, -0.0064817 , -0.00773428],\n",
              "       [ 0.06265119,  0.99223757,  0.66928744,  0.9965995 ,  0.65959114,\n",
              "         0.99361   ,  0.64131004, -0.45647153, -0.4406333 , -0.45387778],\n",
              "       [ 0.20867422,  0.61992234,  0.99156976,  0.6591899 ,  0.9915739 ,\n",
              "         0.6456291 ,  0.9953552 , -0.03214208, -0.0064817 , -0.00773428],\n",
              "       [ 0.06265119,  0.99223757,  0.66928744,  0.9965995 ,  0.65959114,\n",
              "         0.99361   ,  0.64131004, -0.45647153, -0.4406333 , -0.45387778],\n",
              "       [ 0.20867422,  0.61992234,  0.99156976,  0.6591899 ,  0.9915739 ,\n",
              "         0.6456291 ,  0.9953552 , -0.03214208, -0.0064817 , -0.00773428],\n",
              "       [-0.50432396, -0.5002737 ,  0.01721406, -0.49029037,  0.0115145 ,\n",
              "        -0.42218503,  0.01042278,  0.99311066,  0.9932233 ,  0.9951805 ],\n",
              "       [-0.50432396, -0.5002737 ,  0.01721406, -0.49029037,  0.0115145 ,\n",
              "        -0.42218503,  0.01042278,  0.99311066,  0.9932233 ,  0.9951805 ],\n",
              "       [-0.50432396, -0.5002737 ,  0.01721406, -0.49029037,  0.0115145 ,\n",
              "        -0.42218503,  0.01042278,  0.99311066,  0.9932233 ,  0.9951805 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9U1hmDPIYxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khB2OHytIYpR",
        "outputId": "4e7b122b-1e3a-436b-b8b0-a1e283edb6bc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.append([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
      ],
      "metadata": {
        "id": "mfxo5LPaI6fX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.append([-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0])"
      ],
      "metadata": {
        "id": "52KSbuCyLZWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[52]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQYjzEgHJhe_",
        "outputId": "8d4dcd4d-52c4-418d-ec6c-1a7ee6865b6d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[53]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AXmwYE6JkkB",
        "outputId": "494c80b3-4045-4410-f4f0-de782df01e03"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q759aa-FLYKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(name):\n",
        "    # If you what to replicate the DeepLog paper results(Actually, I have a better result than DeepLog paper results),\n",
        "    # you should use the 'list' not 'set' to obtain the full dataset, I use 'set' just for test and acceleration.\n",
        "    hdfs = set()\n",
        "    # hdfs = []\n",
        "    with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            line = [int(i) for i in row.strip().split()]\n",
        "            line = line + [53] * (window_size + 1 - len(line)) #if the length of the line is less than windows size, it covers by 30 a template with zeros vector\n",
        "            hdfs.add(tuple(line))\n",
        "            # hdfs.append(tuple(line))\n",
        "    print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
        "    return hdfs"
      ],
      "metadata": {
        "id": "EjoUJph-IZQK"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_normal_loader = generate('logs_ntest')\n",
        "test_abnormal_loader = generate('logs_atest')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtM4hqffJxNB",
        "outputId": "c96e7216-6036-4138-bd0c-58eb7e7aa952"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(logs_ntest): 1091\n",
            "Number of sessions(logs_atest): 4126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for line in test_normal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            session = line[i:i + window_size]\n",
        "            seq = [embeddings[temp] for temp in session]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            output = model(seq)\n",
        "            break\n",
        "        break"
      ],
      "metadata": {
        "id": "jiFRAVdVLp9l"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XLRqmxqMjZ7",
        "outputId": "f7dbf4b7-4601-4aed-9659-915464e3820c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0, 0, 0, 2, 3, 4, 2, 3, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[:,0,:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzTXBgvtMvFM",
        "outputId": "023e35ac-c803-48f2-d41d-4460d1a5053e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(embeddings).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTmfoRrFNBWI",
        "outputId": "63b1bec3-7d3a-4ea7-84f8-7e0f8bcbcb46"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(cosine_similarity(output.cpu().detach().numpy()[0,:,:],np.array(embeddings)) ,axis=1 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esEVg45NMlb1",
        "outputId": "8456af4b-e731-4841-f531-fbe497334f5e"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 9, 2, 3, 4, 2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(output.cpu().detach().numpy()[:,3,:],np.array(embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPwMtdaoOZcr",
        "outputId": "322abb2d-b2ef-4f70-e4b5-f4e1626b0b57"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.93364596, -0.4434544 ,  0.21914434,  0.19454281, -0.65147745,\n",
              "         0.71474941,  0.53797707,  0.15221624, -0.06525082,  0.96791527,\n",
              "        -0.5763621 , -0.31966809, -0.08581298,  0.3525665 , -0.51343656,\n",
              "        -0.54429658, -0.57737701,  0.69773972,  0.21558633,  0.38540546,\n",
              "         0.6757934 ,  0.67971468,  0.53628898,  0.30833949,  0.2453729 ,\n",
              "         0.46184703,  0.71523791,  0.25231187,  0.29977316,  0.3604768 ,\n",
              "         0.3592888 ,  0.63598188,  0.18424333,  0.61498045,  0.03822683,\n",
              "         0.21031395,  0.38700118,  0.67300933,  0.42254237,  0.68351357,\n",
              "        -0.30130725,  0.29635648, -0.40252998, -0.23298372,  0.7300521 ,\n",
              "         0.22557606,  0.6841217 ,  0.68081174,  0.69443181, -0.40250046,\n",
              "         0.18954596,  0.39670442,  0.        ,  0.30450481]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = cosine_similarity(seq.cpu().detach().numpy()[0],output.cpu().detach().numpy()[0])\n",
        "np.diag(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvJuDbMqMP9x",
        "outputId": "5f9c165d-84c5-4657-98ab-982b615e4d6a"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.94757855, 0.99033636, 0.9951027 , 0.93364596, 0.96575195,\n",
              "       0.9642491 , 0.9754004 , 0.97802216, 0.9820594 , 0.9909105 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(np.diag(matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5vStqPERcOu",
        "outputId": "0cb5272e-b1cd-440c-d483-7ecacaddbf4c"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9390317"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    c=0\n",
        "    w=0\n",
        "    for line in test_normal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            session = line[i:i + window_size]\n",
        "            seq = [embeddings[temp] for temp in session]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            output = model(seq)\n",
        "            matrix = cosine_similarity(seq.cpu().detach().numpy()[0],output.cpu().detach().numpy()[0])\n",
        "            if np.min(np.diag(matrix))<0.9:\n",
        "              w+=1\n",
        "            else:\n",
        "              c+=1\n",
        "\n",
        "print(w)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh09BueBQr6b",
        "outputId": "53b0107a-8a97-4c40-d238-9de5fb32b3c1"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6396\n",
            "2334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    c=0\n",
        "    w=0\n",
        "    for line in test_abnormal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            session = line[i:i + window_size]\n",
        "            seq = [embeddings[temp] for temp in session]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            output = model(seq)\n",
        "            matrix = cosine_similarity(seq.cpu().detach().numpy()[0],output.cpu().detach().numpy()[0])\n",
        "            if np.min(np.diag(matrix))<0.9:\n",
        "              w+=1\n",
        "            else:\n",
        "              c+=1\n",
        "\n",
        "print(w)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUFWD0lSczo",
        "outputId": "20ed4f23-ce24-42ed-c4e4-9242de106cae"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70593\n",
            "9773\n"
          ]
        }
      ]
    }
  ]
}