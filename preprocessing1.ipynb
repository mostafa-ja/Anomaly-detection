{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMZ4IHYT6otz3mgZ1ITd7zB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/preprocessing1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download datasets\n",
        "! wget 'https://raw.githubusercontent.com/wuyifan18/DeepLog/master/data/hdfs_train'\n",
        "! wget 'https://raw.githubusercontent.com/wuyifan18/DeepLog/master/data/hdfs_test_normal'\n",
        "! wget 'https://raw.githubusercontent.com/wuyifan18/DeepLog/master/data/hdfs_test_abnormal'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxO267KLNeBo",
        "outputId": "3043f79c-2468-4892-df4a-cb096d68d8a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-11 09:11:21--  https://raw.githubusercontent.com/wuyifan18/DeepLog/master/data/hdfs_train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253021 (247K) [text/plain]\n",
            "Saving to: ‘hdfs_train’\n",
            "\n",
            "\rhdfs_train            0%[                    ]       0  --.-KB/s               \rhdfs_train          100%[===================>] 247.09K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-11 09:11:21 (7.74 MB/s) - ‘hdfs_train’ saved [253021/253021]\n",
            "\n",
            "--2023-07-11 09:11:22--  https://raw.githubusercontent.com/wuyifan18/DeepLog/master/data/hdfs_test_normal\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28730917 (27M) [text/plain]\n",
            "Saving to: ‘hdfs_test_normal’\n",
            "\n",
            "hdfs_test_normal    100%[===================>]  27.40M   175MB/s    in 0.2s    \n",
            "\n",
            "2023-07-11 09:11:22 (175 MB/s) - ‘hdfs_test_normal’ saved [28730917/28730917]\n",
            "\n",
            "--2023-07-11 09:11:22--  https://raw.githubusercontent.com/wuyifan18/DeepLog/master/data/hdfs_test_abnormal\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 765642 (748K) [text/plain]\n",
            "Saving to: ‘hdfs_test_abnormal’\n",
            "\n",
            "hdfs_test_abnormal  100%[===================>] 747.70K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-07-11 09:11:22 (15.9 MB/s) - ‘hdfs_test_abnormal’ saved [765642/765642]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "DY20jHF8KUmK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count rows of the hdfs_train\n",
        "\n",
        "with open('/content/hdfs_train', \"r\") as file:\n",
        "    totaln=0\n",
        "    for line in file:\n",
        "        totaln += 1\n",
        "\n",
        "print('There are a total of {} lines'.format(totaln))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6I2yQF-UhD8",
        "outputId": "4b95cd84-a15f-484c-d274-c19ee8ec8429"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are a total of 4855 lines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "important point:\n",
        "if you need to modify the elements of the line later on, using a list would be more suitable. If you want to ensure that the elements remain immutable, using a tuple would be appropriate."
      ],
      "metadata": {
        "id": "86E6FrUzT3Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "outputs = []\n",
        "with open('/content/hdfs_train', 'r') as f:\n",
        "        for line in f:\n",
        "            print(line)\n",
        "            num_sessions += 1\n",
        "            line = [int(n) - 1 for n in line.strip().split()]\n",
        "            for i in range(len(line) - window_size):\n",
        "                inputs.append(line[i:i + window_size])\n",
        "                outputs.append(line[i + window_size])\n",
        "            break\n",
        "\n",
        "print(line)\n",
        "print(inputs)\n",
        "print(outputs)\n",
        "print(num_sessions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgqHCZFlTNAr",
        "outputId": "507caf9e-1cd9-457e-aa13-010045cf7e3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 5 5 22 11 9 11 9 11 9 26 26 26 23 23 23 21 21 21 \n",
            "\n",
            "[4, 4, 4, 21, 10, 8, 10, 8, 10, 8, 25, 25, 25, 22, 22, 22, 20, 20, 20]\n",
            "[[4, 4, 4, 21, 10, 8, 10, 8, 10, 8], [4, 4, 21, 10, 8, 10, 8, 10, 8, 25], [4, 21, 10, 8, 10, 8, 10, 8, 25, 25], [21, 10, 8, 10, 8, 10, 8, 25, 25, 25], [10, 8, 10, 8, 10, 8, 25, 25, 25, 22], [8, 10, 8, 10, 8, 25, 25, 25, 22, 22], [10, 8, 10, 8, 25, 25, 25, 22, 22, 22], [8, 10, 8, 25, 25, 25, 22, 22, 22, 20], [10, 8, 25, 25, 25, 22, 22, 22, 20, 20]]\n",
            "[25, 25, 25, 22, 22, 22, 20, 20, 20]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what happen if the line is smaller than windows size or equal\n",
        "\n",
        "line = '5 5 5 22 11 9 11'\n",
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "line = [int(n) - 1 for n in line.strip().split()]\n",
        "for i in range(len(line) - window_size):\n",
        "    inputs.append(line[i:i + window_size])\n",
        "    outputs.append(line[i + window_size])\n",
        "\n",
        "print(line)\n",
        "print(inputs)\n",
        "print(outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyV6nQP2V7Q6",
        "outputId": "8626be3f-369e-4494-dde2-f3641dbd0cfe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 4, 4, 21, 10, 8, 10]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line = '5 5 5 22 11 9 11 9 11 9'\n",
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "line = [int(n) - 1 for n in line.strip().split()]\n",
        "for i in range(len(line) - window_size):\n",
        "    inputs.append(line[i:i + window_size])\n",
        "    outputs.append(line[i + window_size])\n",
        "\n",
        "print(line)\n",
        "print(inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tKNqEyBWmGW",
        "outputId": "45d46b10-2422-4871-8d60-e8625d91eac4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 4, 4, 21, 10, 8, 10, 8, 10, 8]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "name = 'hdfs_train'\n",
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            num_sessions += 1\n",
        "            line = [int(i) - 1 for i in row.strip().split()] # we substract by one from templates index for starting from zero\n",
        "            for i in range(len(line) - window_size):\n",
        "                inputs.append(line[i:i + window_size])\n",
        "                outputs.append(line[i + window_size])\n",
        "\n",
        "print('Number of sessions({}): {}'.format(name, num_sessions))\n",
        "print('Number of seqs({}): {}'.format(name, len(inputs)))\n",
        "dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWjsmwEvKYd8",
        "outputId": "7aa52743-bfe5-4dd9-c8e0-150c07b7744e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_train): 4855\n",
            "Number of seqs(hdfs_train): 46575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ba carefull, we substract by one\n",
        "inputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78AKB933NMAF",
        "outputId": "9758dc11-c823-498e-fe2f-2641350580ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 4, 4, 21, 10, 8, 10, 8, 10, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcfIi0uNVWQB",
        "outputId": "b34491ae-b8f7-450c-aefe-4fc7362b7971"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.max(outputs))\n",
        "print(np.min(outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Sxl7UKz7Vq",
        "outputId": "ac453de1-60f8-43f1-8865-626b0f4f4e9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique outputs\n",
        "print(set(outputs))\n",
        "len(set(outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2llz4X_p1YXc",
        "outputId": "6a95c022-d103-426a-da8f-54d8068809f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 2, 3, 4, 5, 8, 10, 15, 17, 20, 21, 22, 24, 25}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLYWKxu5XWmz",
        "outputId": "062d4979-09df-4df1-e8c9-292a61c4719d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 4.,  4.,  4., 21., 10.,  8., 10.,  8., 10.,  8.]), tensor(25))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "1g0Vk-aTynIC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 1 # means each input has one feature(template's code)\n",
        "num_layers = 2\n",
        "hidden_size = 64\n",
        "num_classes = 28\n",
        "batch_size = 2048\n",
        "num_epochs = 300\n",
        "model_dir = 'model'"
      ],
      "metadata": {
        "id": "DV_Ix0rNyzsw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log = 'Adam_batch_size={}_epoch={}'.format(str(batch_size), str(num_epochs))\n",
        "writer = SummaryWriter(log_dir='log/' + log)\n",
        "\n",
        "\n",
        "model = Model(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "yG5EDgWS4in1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step, (seq, label) in enumerate(dataloader):\n",
        "  print(seq.shape)\n",
        "  print(label.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfpaMvNb5m3C",
        "outputId": "b2312b24-eb83-4ff2-91ad-1cbd5df89abc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2048, 10])\n",
            "torch.Size([2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "start_time = time.time()\n",
        "total_step = len(dataloader)\n",
        "for epoch in range(num_epochs):  # Loop over the dataset multiple times\n",
        "    train_loss = 0\n",
        "    for step, (seq, label) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
        "        output = model(seq)\n",
        "        loss = criterion(output, label.to(device))\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss / total_step))\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k8RYuMq46NF",
        "outputId": "0c533cf7-5f16-4a2d-f2c5-a489e4ea739f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/300], train_loss: 2.8119\n",
            "Epoch [2/300], train_loss: 1.8651\n",
            "Epoch [3/300], train_loss: 1.7024\n",
            "Epoch [4/300], train_loss: 1.5077\n",
            "Epoch [5/300], train_loss: 1.2718\n",
            "Epoch [6/300], train_loss: 1.0642\n",
            "Epoch [7/300], train_loss: 0.9039\n",
            "Epoch [8/300], train_loss: 0.7843\n",
            "Epoch [9/300], train_loss: 0.6997\n",
            "Epoch [10/300], train_loss: 0.6421\n",
            "Epoch [11/300], train_loss: 0.6031\n",
            "Epoch [12/300], train_loss: 0.5709\n",
            "Epoch [13/300], train_loss: 0.5424\n",
            "Epoch [14/300], train_loss: 0.5159\n",
            "Epoch [15/300], train_loss: 0.4896\n",
            "Epoch [16/300], train_loss: 0.4695\n",
            "Epoch [17/300], train_loss: 0.4545\n",
            "Epoch [18/300], train_loss: 0.4432\n",
            "Epoch [19/300], train_loss: 0.4299\n",
            "Epoch [20/300], train_loss: 0.4206\n",
            "Epoch [21/300], train_loss: 0.4098\n",
            "Epoch [22/300], train_loss: 0.4010\n",
            "Epoch [23/300], train_loss: 0.3926\n",
            "Epoch [24/300], train_loss: 0.3872\n",
            "Epoch [25/300], train_loss: 0.3821\n",
            "Epoch [26/300], train_loss: 0.3753\n",
            "Epoch [27/300], train_loss: 0.3717\n",
            "Epoch [28/300], train_loss: 0.3666\n",
            "Epoch [29/300], train_loss: 0.3694\n",
            "Epoch [30/300], train_loss: 0.3618\n",
            "Epoch [31/300], train_loss: 0.3546\n",
            "Epoch [32/300], train_loss: 0.3513\n",
            "Epoch [33/300], train_loss: 0.3484\n",
            "Epoch [34/300], train_loss: 0.3446\n",
            "Epoch [35/300], train_loss: 0.3419\n",
            "Epoch [36/300], train_loss: 0.3399\n",
            "Epoch [37/300], train_loss: 0.3383\n",
            "Epoch [38/300], train_loss: 0.3348\n",
            "Epoch [39/300], train_loss: 0.3319\n",
            "Epoch [40/300], train_loss: 0.3284\n",
            "Epoch [41/300], train_loss: 0.3250\n",
            "Epoch [42/300], train_loss: 0.3235\n",
            "Epoch [43/300], train_loss: 0.3214\n",
            "Epoch [44/300], train_loss: 0.3212\n",
            "Epoch [45/300], train_loss: 0.3162\n",
            "Epoch [46/300], train_loss: 0.3149\n",
            "Epoch [47/300], train_loss: 0.3133\n",
            "Epoch [48/300], train_loss: 0.3127\n",
            "Epoch [49/300], train_loss: 0.3135\n",
            "Epoch [50/300], train_loss: 0.3102\n",
            "Epoch [51/300], train_loss: 0.3066\n",
            "Epoch [52/300], train_loss: 0.3044\n",
            "Epoch [53/300], train_loss: 0.3034\n",
            "Epoch [54/300], train_loss: 0.3003\n",
            "Epoch [55/300], train_loss: 0.2986\n",
            "Epoch [56/300], train_loss: 0.2972\n",
            "Epoch [57/300], train_loss: 0.2975\n",
            "Epoch [58/300], train_loss: 0.2950\n",
            "Epoch [59/300], train_loss: 0.2936\n",
            "Epoch [60/300], train_loss: 0.2915\n",
            "Epoch [61/300], train_loss: 0.2891\n",
            "Epoch [62/300], train_loss: 0.2874\n",
            "Epoch [63/300], train_loss: 0.2881\n",
            "Epoch [64/300], train_loss: 0.2844\n",
            "Epoch [65/300], train_loss: 0.2833\n",
            "Epoch [66/300], train_loss: 0.2804\n",
            "Epoch [67/300], train_loss: 0.2799\n",
            "Epoch [68/300], train_loss: 0.2789\n",
            "Epoch [69/300], train_loss: 0.2775\n",
            "Epoch [70/300], train_loss: 0.2754\n",
            "Epoch [71/300], train_loss: 0.2748\n",
            "Epoch [72/300], train_loss: 0.2731\n",
            "Epoch [73/300], train_loss: 0.2711\n",
            "Epoch [74/300], train_loss: 0.2705\n",
            "Epoch [75/300], train_loss: 0.2682\n",
            "Epoch [76/300], train_loss: 0.2681\n",
            "Epoch [77/300], train_loss: 0.2669\n",
            "Epoch [78/300], train_loss: 0.2665\n",
            "Epoch [79/300], train_loss: 0.2645\n",
            "Epoch [80/300], train_loss: 0.2637\n",
            "Epoch [81/300], train_loss: 0.2640\n",
            "Epoch [82/300], train_loss: 0.2633\n",
            "Epoch [83/300], train_loss: 0.2605\n",
            "Epoch [84/300], train_loss: 0.2598\n",
            "Epoch [85/300], train_loss: 0.2604\n",
            "Epoch [86/300], train_loss: 0.2580\n",
            "Epoch [87/300], train_loss: 0.2572\n",
            "Epoch [88/300], train_loss: 0.2557\n",
            "Epoch [89/300], train_loss: 0.2548\n",
            "Epoch [90/300], train_loss: 0.2544\n",
            "Epoch [91/300], train_loss: 0.2531\n",
            "Epoch [92/300], train_loss: 0.2530\n",
            "Epoch [93/300], train_loss: 0.2522\n",
            "Epoch [94/300], train_loss: 0.2524\n",
            "Epoch [95/300], train_loss: 0.2514\n",
            "Epoch [96/300], train_loss: 0.2495\n",
            "Epoch [97/300], train_loss: 0.2472\n",
            "Epoch [98/300], train_loss: 0.2471\n",
            "Epoch [99/300], train_loss: 0.2465\n",
            "Epoch [100/300], train_loss: 0.2453\n",
            "Epoch [101/300], train_loss: 0.2450\n",
            "Epoch [102/300], train_loss: 0.2433\n",
            "Epoch [103/300], train_loss: 0.2432\n",
            "Epoch [104/300], train_loss: 0.2428\n",
            "Epoch [105/300], train_loss: 0.2429\n",
            "Epoch [106/300], train_loss: 0.2401\n",
            "Epoch [107/300], train_loss: 0.2396\n",
            "Epoch [108/300], train_loss: 0.2392\n",
            "Epoch [109/300], train_loss: 0.2389\n",
            "Epoch [110/300], train_loss: 0.2380\n",
            "Epoch [111/300], train_loss: 0.2378\n",
            "Epoch [112/300], train_loss: 0.2373\n",
            "Epoch [113/300], train_loss: 0.2359\n",
            "Epoch [114/300], train_loss: 0.2358\n",
            "Epoch [115/300], train_loss: 0.2374\n",
            "Epoch [116/300], train_loss: 0.2341\n",
            "Epoch [117/300], train_loss: 0.2333\n",
            "Epoch [118/300], train_loss: 0.2329\n",
            "Epoch [119/300], train_loss: 0.2341\n",
            "Epoch [120/300], train_loss: 0.2318\n",
            "Epoch [121/300], train_loss: 0.2316\n",
            "Epoch [122/300], train_loss: 0.2309\n",
            "Epoch [123/300], train_loss: 0.2305\n",
            "Epoch [124/300], train_loss: 0.2294\n",
            "Epoch [125/300], train_loss: 0.2299\n",
            "Epoch [126/300], train_loss: 0.2291\n",
            "Epoch [127/300], train_loss: 0.2280\n",
            "Epoch [128/300], train_loss: 0.2274\n",
            "Epoch [129/300], train_loss: 0.2276\n",
            "Epoch [130/300], train_loss: 0.2277\n",
            "Epoch [131/300], train_loss: 0.2267\n",
            "Epoch [132/300], train_loss: 0.2259\n",
            "Epoch [133/300], train_loss: 0.2259\n",
            "Epoch [134/300], train_loss: 0.2258\n",
            "Epoch [135/300], train_loss: 0.2254\n",
            "Epoch [136/300], train_loss: 0.2244\n",
            "Epoch [137/300], train_loss: 0.2239\n",
            "Epoch [138/300], train_loss: 0.2250\n",
            "Epoch [139/300], train_loss: 0.2237\n",
            "Epoch [140/300], train_loss: 0.2228\n",
            "Epoch [141/300], train_loss: 0.2372\n",
            "Epoch [142/300], train_loss: 0.3257\n",
            "Epoch [143/300], train_loss: 0.2418\n",
            "Epoch [144/300], train_loss: 0.2318\n",
            "Epoch [145/300], train_loss: 0.2265\n",
            "Epoch [146/300], train_loss: 0.2248\n",
            "Epoch [147/300], train_loss: 0.2221\n",
            "Epoch [148/300], train_loss: 0.2220\n",
            "Epoch [149/300], train_loss: 0.2211\n",
            "Epoch [150/300], train_loss: 0.2210\n",
            "Epoch [151/300], train_loss: 0.2200\n",
            "Epoch [152/300], train_loss: 0.2191\n",
            "Epoch [153/300], train_loss: 0.2189\n",
            "Epoch [154/300], train_loss: 0.2192\n",
            "Epoch [155/300], train_loss: 0.2180\n",
            "Epoch [156/300], train_loss: 0.2178\n",
            "Epoch [157/300], train_loss: 0.2169\n",
            "Epoch [158/300], train_loss: 0.2177\n",
            "Epoch [159/300], train_loss: 0.2170\n",
            "Epoch [160/300], train_loss: 0.2164\n",
            "Epoch [161/300], train_loss: 0.2165\n",
            "Epoch [162/300], train_loss: 0.2162\n",
            "Epoch [163/300], train_loss: 0.2161\n",
            "Epoch [164/300], train_loss: 0.2158\n",
            "Epoch [165/300], train_loss: 0.2151\n",
            "Epoch [166/300], train_loss: 0.2156\n",
            "Epoch [167/300], train_loss: 0.2142\n",
            "Epoch [168/300], train_loss: 0.2142\n",
            "Epoch [169/300], train_loss: 0.2145\n",
            "Epoch [170/300], train_loss: 0.2144\n",
            "Epoch [171/300], train_loss: 0.2135\n",
            "Epoch [172/300], train_loss: 0.2128\n",
            "Epoch [173/300], train_loss: 0.2127\n",
            "Epoch [174/300], train_loss: 0.2127\n",
            "Epoch [175/300], train_loss: 0.2126\n",
            "Epoch [176/300], train_loss: 0.2124\n",
            "Epoch [177/300], train_loss: 0.2114\n",
            "Epoch [178/300], train_loss: 0.2118\n",
            "Epoch [179/300], train_loss: 0.2112\n",
            "Epoch [180/300], train_loss: 0.2121\n",
            "Epoch [181/300], train_loss: 0.2112\n",
            "Epoch [182/300], train_loss: 0.2109\n",
            "Epoch [183/300], train_loss: 0.2106\n",
            "Epoch [184/300], train_loss: 0.2105\n",
            "Epoch [185/300], train_loss: 0.2101\n",
            "Epoch [186/300], train_loss: 0.2104\n",
            "Epoch [187/300], train_loss: 0.2090\n",
            "Epoch [188/300], train_loss: 0.2090\n",
            "Epoch [189/300], train_loss: 0.2095\n",
            "Epoch [190/300], train_loss: 0.2094\n",
            "Epoch [191/300], train_loss: 0.2092\n",
            "Epoch [192/300], train_loss: 0.2094\n",
            "Epoch [193/300], train_loss: 0.2087\n",
            "Epoch [194/300], train_loss: 0.2083\n",
            "Epoch [195/300], train_loss: 0.2089\n",
            "Epoch [196/300], train_loss: 0.2089\n",
            "Epoch [197/300], train_loss: 0.2069\n",
            "Epoch [198/300], train_loss: 0.2075\n",
            "Epoch [199/300], train_loss: 0.2076\n",
            "Epoch [200/300], train_loss: 0.2073\n",
            "Epoch [201/300], train_loss: 0.2068\n",
            "Epoch [202/300], train_loss: 0.2066\n",
            "Epoch [203/300], train_loss: 0.2061\n",
            "Epoch [204/300], train_loss: 0.2068\n",
            "Epoch [205/300], train_loss: 0.2055\n",
            "Epoch [206/300], train_loss: 0.2063\n",
            "Epoch [207/300], train_loss: 0.2072\n",
            "Epoch [208/300], train_loss: 0.2057\n",
            "Epoch [209/300], train_loss: 0.2057\n",
            "Epoch [210/300], train_loss: 0.2056\n",
            "Epoch [211/300], train_loss: 0.2050\n",
            "Epoch [212/300], train_loss: 0.2050\n",
            "Epoch [213/300], train_loss: 0.2047\n",
            "Epoch [214/300], train_loss: 0.2043\n",
            "Epoch [215/300], train_loss: 0.2041\n",
            "Epoch [216/300], train_loss: 0.2039\n",
            "Epoch [217/300], train_loss: 0.2041\n",
            "Epoch [218/300], train_loss: 0.2031\n",
            "Epoch [219/300], train_loss: 0.2035\n",
            "Epoch [220/300], train_loss: 0.2037\n",
            "Epoch [221/300], train_loss: 0.2029\n",
            "Epoch [222/300], train_loss: 0.2024\n",
            "Epoch [223/300], train_loss: 0.2033\n",
            "Epoch [224/300], train_loss: 0.2034\n",
            "Epoch [225/300], train_loss: 0.2020\n",
            "Epoch [226/300], train_loss: 0.2020\n",
            "Epoch [227/300], train_loss: 0.2023\n",
            "Epoch [228/300], train_loss: 0.2020\n",
            "Epoch [229/300], train_loss: 0.2024\n",
            "Epoch [230/300], train_loss: 0.2023\n",
            "Epoch [231/300], train_loss: 0.2020\n",
            "Epoch [232/300], train_loss: 0.2022\n",
            "Epoch [233/300], train_loss: 0.2017\n",
            "Epoch [234/300], train_loss: 0.2021\n",
            "Epoch [235/300], train_loss: 0.2014\n",
            "Epoch [236/300], train_loss: 0.2013\n",
            "Epoch [237/300], train_loss: 0.2008\n",
            "Epoch [238/300], train_loss: 0.2003\n",
            "Epoch [239/300], train_loss: 0.2009\n",
            "Epoch [240/300], train_loss: 0.1999\n",
            "Epoch [241/300], train_loss: 0.1994\n",
            "Epoch [242/300], train_loss: 0.1991\n",
            "Epoch [243/300], train_loss: 0.1997\n",
            "Epoch [244/300], train_loss: 0.2002\n",
            "Epoch [245/300], train_loss: 0.1995\n",
            "Epoch [246/300], train_loss: 0.1992\n",
            "Epoch [247/300], train_loss: 0.2277\n",
            "Epoch [248/300], train_loss: 0.2245\n",
            "Epoch [249/300], train_loss: 0.2050\n",
            "Epoch [250/300], train_loss: 0.2003\n",
            "Epoch [251/300], train_loss: 0.1999\n",
            "Epoch [252/300], train_loss: 0.1998\n",
            "Epoch [253/300], train_loss: 0.1989\n",
            "Epoch [254/300], train_loss: 0.1982\n",
            "Epoch [255/300], train_loss: 0.1980\n",
            "Epoch [256/300], train_loss: 0.1975\n",
            "Epoch [257/300], train_loss: 0.1981\n",
            "Epoch [258/300], train_loss: 0.1973\n",
            "Epoch [259/300], train_loss: 0.1969\n",
            "Epoch [260/300], train_loss: 0.1972\n",
            "Epoch [261/300], train_loss: 0.1968\n",
            "Epoch [262/300], train_loss: 0.1966\n",
            "Epoch [263/300], train_loss: 0.1968\n",
            "Epoch [264/300], train_loss: 0.1960\n",
            "Epoch [265/300], train_loss: 0.1971\n",
            "Epoch [266/300], train_loss: 0.1969\n",
            "Epoch [267/300], train_loss: 0.1963\n",
            "Epoch [268/300], train_loss: 0.1962\n",
            "Epoch [269/300], train_loss: 0.1959\n",
            "Epoch [270/300], train_loss: 0.1959\n",
            "Epoch [271/300], train_loss: 0.1961\n",
            "Epoch [272/300], train_loss: 0.1955\n",
            "Epoch [273/300], train_loss: 0.1952\n",
            "Epoch [274/300], train_loss: 0.1955\n",
            "Epoch [275/300], train_loss: 0.1949\n",
            "Epoch [276/300], train_loss: 0.1956\n",
            "Epoch [277/300], train_loss: 0.1946\n",
            "Epoch [278/300], train_loss: 0.1945\n",
            "Epoch [279/300], train_loss: 0.1954\n",
            "Epoch [280/300], train_loss: 0.1948\n",
            "Epoch [281/300], train_loss: 0.1949\n",
            "Epoch [282/300], train_loss: 0.1943\n",
            "Epoch [283/300], train_loss: 0.1944\n",
            "Epoch [284/300], train_loss: 0.1942\n",
            "Epoch [285/300], train_loss: 0.1939\n",
            "Epoch [286/300], train_loss: 0.1950\n",
            "Epoch [287/300], train_loss: 0.1944\n",
            "Epoch [288/300], train_loss: 0.1934\n",
            "Epoch [289/300], train_loss: 0.1942\n",
            "Epoch [290/300], train_loss: 0.1933\n",
            "Epoch [291/300], train_loss: 0.1936\n",
            "Epoch [292/300], train_loss: 0.1929\n",
            "Epoch [293/300], train_loss: 0.1935\n",
            "Epoch [294/300], train_loss: 0.1932\n",
            "Epoch [295/300], train_loss: 0.1931\n",
            "Epoch [296/300], train_loss: 0.1930\n",
            "Epoch [297/300], train_loss: 0.1923\n",
            "Epoch [298/300], train_loss: 0.1931\n",
            "Epoch [299/300], train_loss: 0.1923\n",
            "Epoch [300/300], train_loss: 0.1937\n",
            "elapsed_time: 213.023s\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n"
      ],
      "metadata": {
        "id": "R5j0mAkD9Nmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba111437-213b-490b-d2c1-fa2f6ad81486"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "lstm.weight_ih_l0 \t torch.Size([256, 1])\n",
            "lstm.weight_hh_l0 \t torch.Size([256, 64])\n",
            "lstm.bias_ih_l0 \t torch.Size([256])\n",
            "lstm.bias_hh_l0 \t torch.Size([256])\n",
            "lstm.weight_ih_l1 \t torch.Size([256, 64])\n",
            "lstm.weight_hh_l1 \t torch.Size([256, 64])\n",
            "lstm.bias_ih_l1 \t torch.Size([256])\n",
            "lstm.bias_hh_l1 \t torch.Size([256])\n",
            "fc.weight \t torch.Size([28, 64])\n",
            "fc.bias \t torch.Size([28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/model_parameter')\n"
      ],
      "metadata": {
        "id": "Eygupki2EpNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1266533-c028-48d5-b995-ac3cf87dcd77"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = dataset[0]\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "ny24xENd8_rH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181fff1b-6ecb-4262-c9c1-aba5d2f4053c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4.,  4.,  4., 21., 10.,  8., 10.,  8., 10.,  8.])\n",
            "tensor(25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  output = model(x.view(-1, 10, 1).to(device))\n",
        "\n",
        "print(output)\n",
        "print(np.argmax(output.cpu()))"
      ],
      "metadata": {
        "id": "hnx84gzX8eB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca183be9-d3f3-4412-ee26-756f884a5921"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.7508,  1.8236, -0.0566,  1.1453, -2.2462, -5.7327, -3.7104, -4.8342,\n",
            "          0.3210, -4.9804,  2.0385, -4.7240, -5.0413, -4.0583, -4.7007, -4.2532,\n",
            "         -4.7936, -1.1776, -4.9065, -4.6588, -0.4992,  0.7799, -0.6379, -4.8290,\n",
            "          1.5140, 12.9225, -4.7461, -4.4651]], device='cuda:0')\n",
            "tensor(25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = dataset[5]\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "HpO5xqME_Ml-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294c4460-40f6-455c-a4ba-9855a978a65c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8., 10.,  8., 10.,  8., 25., 25., 25., 22., 22.])\n",
            "tensor(22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  output = model(x.view(-1, 10, 1).to(device))\n",
        "\n",
        "print(output)\n",
        "print(np.argmax(output.cpu()))"
      ],
      "metadata": {
        "id": "2S0W--j7_QOV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbc7a91-0538-4999-e672-39747011fe6c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.4647,  1.0807,  0.6209, -0.5563,  3.2914, -4.0438, -3.9144, -4.2281,\n",
            "         -9.1934, -4.3735, -5.6101, -4.3301, -4.5008, -4.4556, -4.7793, -6.1979,\n",
            "         -4.3460,  3.8124, -4.8607, -4.0699,  2.1028, -3.4791, 11.7600, -4.3012,\n",
            "          1.8787, -4.2657, -4.2527, -4.2237]], device='cuda:0')\n",
            "tensor(22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# part2 : testing"
      ],
      "metadata": {
        "id": "KF0B371JBZQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(name):\n",
        "    # If you what to replicate the DeepLog paper results(Actually, I have a better result than DeepLog paper results),\n",
        "    # you should use the 'list' not 'set' to obtain the full dataset, I use 'set' just for test and acceleration.\n",
        "    hdfs = set()\n",
        "    # hdfs = []\n",
        "    with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            line = [int(i) - 1 for i in row.strip().split()]\n",
        "            line = line + [-1] * (window_size + 1 - len(line)) #if the length of the line is less than windows size, it covers by -1\n",
        "            hdfs.add(tuple(line))\n",
        "            # hdfs.append(tuple(line))\n",
        "    print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
        "    return hdfs"
      ],
      "metadata": {
        "id": "w86EQhvsBY7l"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate2(name):\n",
        "    # If you what to replicate the DeepLog paper results(Actually, I have a better result than DeepLog paper results),\n",
        "    # you should use the 'list' not 'set' to obtain the full dataset, I use 'set' just for test and acceleration.\n",
        "    #hdfs = set()\n",
        "    hdfs = []\n",
        "    with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            line = [int(i) - 1 for i in row.strip().split()]\n",
        "            line = line + [-1] * (window_size + 1 - len(line)) #if the length of the line is less than windows size, it covers by -1\n",
        "            #hdfs.add(tuple(line))\n",
        "            hdfs.append(tuple(line))\n",
        "    print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
        "    return hdfs"
      ],
      "metadata": {
        "id": "9kwHLT-KRMUb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[-1] * 3"
      ],
      "metadata": {
        "id": "37cUZQKLC5Xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f68e3f-a132-4630-f236-c285056f0d69"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1, -1, -1]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[-1] * -2"
      ],
      "metadata": {
        "id": "ImjAr9piC7io",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e29518e-c416-4af3-a9fe-10b1ff23e76d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/' + 'hdfs_test_abnormal', 'r') as f:\n",
        "        for row in f:\n",
        "            print(row)\n",
        "            line = [int(i) - 1 for i in row.strip().split()]\n",
        "            print(line)\n",
        "            line = line + [-1] * (window_size + 1 - len(line)) #if the length of the line is less than windows size + 1(1 for prediction), it covers by -1\n",
        "            print(line)\n",
        "            break"
      ],
      "metadata": {
        "id": "NEBt4sqaCP7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d122df73-e6c7-41f7-a799-54addcd9fd3a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 5 22 5 11 9 11 9 11 9 26 26 26 4 4 3 2 23 23 23 21 21 28 26 21 \n",
            "\n",
            "[4, 4, 21, 4, 10, 8, 10, 8, 10, 8, 25, 25, 25, 3, 3, 2, 1, 22, 22, 22, 20, 20, 27, 25, 20]\n",
            "[4, 4, 21, 4, 10, 8, 10, 8, 10, 8, 25, 25, 25, 3, 3, 2, 1, 22, 22, 22, 20, 20, 27, 25, 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row = '5 5 22 5 11 9 11'\n",
        "line = [int(i) - 1 for i in row.strip().split()]\n",
        "print(line)\n",
        "line = line + [-1] * (window_size + 1 - len(line)) #if the length of the line is less than windows size + 1(1 for prediction), it covers by -1\n",
        "print(line)"
      ],
      "metadata": {
        "id": "p0_TAxQoDQ9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e43e76-b2fa-4a35-e6c0-526f7cf71e02"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 4, 21, 4, 10, 8, 10]\n",
            "[4, 4, 21, 4, 10, 8, 10, -1, -1, -1, -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_keys):\n",
        "        super(Model, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_keys)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "V5sNoFwzATJ5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 28\n",
        "input_size = 1\n",
        "num_candidates = 9 # on paper is g , top-g(here top 9) probabilities to appear next are considered normal\n",
        "model = Model(input_size, hidden_size, num_layers, num_classes).to(device)"
      ],
      "metadata": {
        "id": "guopod6nEFvd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload the model\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = '/content/drive/MyDrive/model_parameter'\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "id": "7Mh9nXz1FbD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00694d8b-e18d-4ae9-88b5-4deb2bbdd62a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if we use whole data , large part of it is duplicated\n",
        "test_normal_loader = generate2('hdfs_test_normal')\n",
        "test_abnormal_loader = generate2('hdfs_test_abnormal')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIddkUtBRJV2",
        "outputId": "3e40e06d-052b-4705-c039-1e8533fd2746"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_test_normal): 553366\n",
            "Number of sessions(hdfs_test_abnormal): 16838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_normal_loader = generate('hdfs_test_normal')\n",
        "test_abnormal_loader = generate('hdfs_test_abnormal')"
      ],
      "metadata": {
        "id": "9XuVpCXUGMoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a27f8e2-510b-4e24-f2cd-ef7aad2edca6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_test_normal): 14177\n",
            "Number of sessions(hdfs_test_abnormal): 4123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "\n",
        "model.eval()\n",
        "\n",
        "TP = 0\n",
        "FP = 0\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for line in test_normal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            seq = line[i:i + window_size]\n",
        "            print(seq)\n",
        "            label = line[i + window_size]\n",
        "            print(label)\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            print(seq)\n",
        "            label = torch.tensor(label).view(-1).to(device)\n",
        "            print(label)\n",
        "            output = model(seq)\n",
        "\n",
        "            predicted = torch.argsort(output, 1)[0][num_candidates:]\n",
        "            break\n",
        "        break"
      ],
      "metadata": {
        "id": "-sVxN1CdEZGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e01092-144c-4edd-9999-4f3630a16443"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 4, 4, 21, 10, 8, 25, 25, 10, 8)\n",
            "10\n",
            "tensor([[[ 4.],\n",
            "         [ 4.],\n",
            "         [ 4.],\n",
            "         [21.],\n",
            "         [10.],\n",
            "         [ 8.],\n",
            "         [25.],\n",
            "         [25.],\n",
            "         [10.],\n",
            "         [ 8.]]], device='cuda:0')\n",
            "tensor([10], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "2qgT9AfBIUAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a99b30-971d-4efc-cebf-4c3f1e3ecc28"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.4265,  0.6027,  0.9818,  2.0122, -4.1019, -0.6238, -3.0547, -3.7285,\n",
              "          4.8899, -3.5270, 12.8156, -3.1909, -3.2499, -3.0170, -3.1875, -2.2732,\n",
              "         -3.5635, -3.4264, -3.5696, -3.2081,  1.6847,  0.3453, -2.4102, -3.3496,\n",
              "         -1.0149,  2.7546, -2.9334, -3.3896]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmin(output.cpu())"
      ],
      "metadata": {
        "id": "DNAvnuzpIk00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e5b579-1570-4eb5-c5e1-c31303c8bfee"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argsort(output, 1)"
      ],
      "metadata": {
        "id": "jiZEcRuNIWjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb592e8-0e44-437f-8232-0e4b814b1031"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  7, 18, 16,  9,  0, 17, 27, 23, 12, 19, 11, 14,  6, 13, 26, 22, 15,\n",
              "         24,  5, 21,  1,  2, 20,  3, 25,  8, 10]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "TP = 0\n",
        "FP = 0\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for line in test_normal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            seq = line[i:i + window_size]\n",
        "            label = line[i + window_size]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            label = torch.tensor(label).view(-1).to(device)\n",
        "            output = model(seq)\n",
        "            predicted = torch.argsort(output, 1)[0][-num_candidates:]\n",
        "            if label not in predicted:\n",
        "                FP += 1\n",
        "                break   #with just one wrong prediction in a line , we assume , abnormal\n",
        "with torch.no_grad():\n",
        "    for line in test_abnormal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            seq = line[i:i + window_size]\n",
        "            label = line[i + window_size]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            label = torch.tensor(label).view(-1).to(device)\n",
        "            output = model(seq)\n",
        "            predicted = torch.argsort(output, 1)[0][-num_candidates:]\n",
        "            if label not in predicted:\n",
        "                TP += 1\n",
        "                break\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "# Compute precision, recall and F1-measure\n",
        "FN = len(test_abnormal_loader) - TP\n",
        "P = 100 * TP / (TP + FP)\n",
        "R = 100 * TP / (TP + FN)\n",
        "F1 = 2 * P * R / (P + R)\n",
        "print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
        "print('Finished Predicting')"
      ],
      "metadata": {
        "id": "eSSB2qJAJLGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67fdfdbc-8473-41df-d33a-7abec84fa06d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 157.939s\n",
            "false positive (FP): 489, false negative (FN): 327, Precision: 88.588%, Recall: 92.069%, F1-measure: 90.295%\n",
            "Finished Predicting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_abnormal_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBFFPPd5Q3R0",
        "outputId": "c48b7260-809e-491d-d3a9-05199c1be88f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4123"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}