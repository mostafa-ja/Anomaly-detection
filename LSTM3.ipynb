{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/rZnCEqMEVBJCz8+JcAne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/LSTM3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XoqK7HxH8-EF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/hdfs_event2semantic_vec.json') as f:\n",
        "    # Step1-1 open file\n",
        "    gdp_list = json.load(f)\n",
        "    value = list(gdp_list.values())"
      ],
      "metadata": {
        "id": "-oP1ng-Z9k60"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(value))\n",
        "print(len(value[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quck6Dp39mFP",
        "outputId": "4668d640-fa75-45fd-c5b3-da85dd4cd92c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "components = None\n",
        "pca = PCA(n_components = 20) # n_components can not be greater than 29 , because we have 29 data and if they are compeletely independent , we could have 29D, same as one hot encoding\n",
        "# perform PCA on the scaled data\n",
        "pca_result = pca.fit_transform(value)\n",
        "\n",
        "# print the explained variances\n",
        "print(\"Variances (Percentage):\")\n",
        "print(pca.explained_variance_ratio_ * 100)\n",
        "print(sum(pca.explained_variance_ratio_ * 100)) #the percentage of variance for 20D\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9WAnqITAecY",
        "outputId": "1df11738-8e72-4c47-c304-b9de8e1e4f7a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variances (Percentage):\n",
            "[26.38436577 11.54957801  8.87619262  8.09854493  5.83096291  4.95880394\n",
            "  4.05582561  3.81095343  3.24716904  2.76424442  2.52277546  2.38701665\n",
            "  1.98277494  1.86786663  1.6366585   1.51299209  1.47744943  1.28605957\n",
            "  1.2501469   0.99433261]\n",
            "96.49471344390082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca_result.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dH12x9NCTyy",
        "outputId": "7cae6b7d-1f35-4bc5-8647-6074259640b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/hdfs_event2semantic_vec.json') as f:\n",
        "    # Step1-1 open file\n",
        "    gdp_list = json.load(f)\n",
        "    value = list(gdp_list.values())\n",
        "\n",
        "    # Step1-2 PCA: Dimensionality reduction to 20-dimensional data\n",
        "    from sklearn.decomposition import PCA\n",
        "    estimator = PCA(n_components=20)\n",
        "    pca_result = estimator.fit_transform(value)\n",
        "\n",
        "    # Step1-3 PPA: De-averaged\n",
        "    ppa_result = []\n",
        "    result = pca_result - np.mean(pca_result)\n",
        "    pca = PCA(n_components=20)\n",
        "    pca_result = pca.fit_transform(result)\n",
        "    U = pca.components_\n",
        "    for i, x in enumerate(result):\n",
        "        for u in U[0:7]:\n",
        "            x = x - np.dot(u.transpose(), x) * u\n",
        "        ppa_result.append(list(x))\n",
        "    ppa_result = np.array(ppa_result)\n"
      ],
      "metadata": {
        "id": "78xulLsb8-7s"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logs_series = pd.read_csv(path)\n",
        "logs_series = logs_series.values\n",
        "label = logs_series[:,1]\n",
        "logs_data = logs_series[:,0]\n",
        "logs = []\n",
        "for i in range(0,len(logs_data)):\n",
        "    padding = np.zeros((300,20))\n",
        "    data = logs_data[i]\n",
        "    data = [int(n) for n in data.split()]\n",
        "    for j in range(0,len(data)):\n",
        "        padding[j] = ppa_result[data[j]]\n",
        "    padding = list(padding)\n",
        "    logs.append(padding)\n",
        "logs = np.array(logs)\n",
        "split_boundary = int(logs.shape[0] * split)\n",
        "train_x = logs[: split_boundary]\n",
        "valid_x = logs[split_boundary:]\n",
        "train_y = label[: split_boundary]\n",
        "valid_y = label[split_boundary:]\n",
        "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 20))\n",
        "valid_x = np.reshape(valid_x, (valid_x.shape[0], valid_x.shape[1], 20))\n",
        "train_y = keras.utils.to_categorical(np.array(train_y))\n",
        "valid_y = keras.utils.to_categorical(np.array(valid_y))"
      ],
      "metadata": {
        "id": "eQhm_OGoEs2r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}