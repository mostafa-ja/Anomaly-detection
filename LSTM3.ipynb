{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOtFUmlyLdUl4ErDLxcrGz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/LSTM3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XoqK7HxH8-EF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    norm1 = np.linalg.norm(vector1)\n",
        "    norm2 = np.linalg.norm(vector2)\n",
        "    cosine_similarity = dot_product / (norm1 * norm2)\n",
        "    return cosine_similarity\n"
      ],
      "metadata": {
        "id": "QauBIBsLgDgA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/hdfs_event2semantic_vec.json') as f:\n",
        "    # Step1-1 open file\n",
        "    gdp_list = json.load(f)\n",
        "    value = list(gdp_list.values())"
      ],
      "metadata": {
        "id": "-oP1ng-Z9k60"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(value))\n",
        "print(len(value[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quck6Dp39mFP",
        "outputId": "dabe4aba-781e-4afc-dc62-73fe6437a35b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "components = None\n",
        "pca = PCA(n_components = 20) # n_components can not be greater than 29 , because we have 29 data and if they are compeletely independent , we could have 29D, same as one hot encoding\n",
        "# perform PCA on the scaled data\n",
        "pca_result = pca.fit_transform(value)\n",
        "\n",
        "# print the explained variances\n",
        "print(\"Variances (Percentage):\")\n",
        "print(pca.explained_variance_ratio_ * 100)\n",
        "print(sum(pca.explained_variance_ratio_ * 100)) #the percentage of variance for 20D\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9WAnqITAecY",
        "outputId": "df29555a-3434-431f-e7f6-0d196512ddd7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variances (Percentage):\n",
            "[26.38436577 11.54957801  8.87619262  8.09854493  5.83096291  4.95880394\n",
            "  4.05582561  3.81095343  3.24716904  2.76424442  2.52277546  2.38701665\n",
            "  1.98277494  1.86786663  1.6366585   1.51299209  1.47744943  1.28605957\n",
            "  1.2501469   0.99433261]\n",
            "96.49471344390082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pca_result.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dH12x9NCTyy",
        "outputId": "d27c6046-4e44-47a1-d8a3-f5bd9b2ebb2f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/hdfs_event2semantic_vec.json') as f:\n",
        "    # Step1-1 open file\n",
        "    gdp_list = json.load(f)\n",
        "    value = list(gdp_list.values())\n",
        "\n",
        "    # Step1-2 PCA: Dimensionality reduction to 20-dimensional data\n",
        "\n",
        "    estimator = PCA(n_components=20)\n",
        "    pca_result = estimator.fit_transform(value)\n",
        "\n",
        "    # Step1-3 PPA: De-averaged\n",
        "    ppa_result = []\n",
        "    result = pca_result - np.mean(pca_result)\n",
        "    pca = PCA(n_components=20)\n",
        "    pca_result = pca.fit_transform(result)\n",
        "    U = pca.components_\n",
        "    for i, x in enumerate(result):\n",
        "        for u in U[0:7]:\n",
        "            x = x - np.dot(u.transpose(), x) * u\n",
        "        ppa_result.append(list(x))\n",
        "    ppa_result = np.array(ppa_result)\n"
      ],
      "metadata": {
        "id": "78xulLsb8-7s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity(value[0], value[1])\n",
        "print(\"Cosine Similarity:\", similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8Gr9f1FgF6d",
        "outputId": "670aa14f-c1a4-46b5-8758-be730f575b65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.27651085126256936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity(pca_result[0], pca_result[1])\n",
        "print(\"Cosine Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YWefGQWgnUW",
        "outputId": "9bd18e02-95d5-4cb0-d7d0-577789effd8e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.21585695356706583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity(ppa_result[0], ppa_result[1])\n",
        "print(\"Cosine Similarity:\", similarity) # we get lower score , it means that we separate diffrent templates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp0Xq014ggF3",
        "outputId": "eeea2352-20aa-42b3-9c83-f26282221459"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.1741783979116341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "eZroAtxpmOTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(value[22], value[23])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6_NUsAOlvFg",
        "outputId": "0fefb040-3fe6-4512-f2c3-2ea97e3b9ee0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6125285006859826"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(value[4], value[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlBTJ23amRiG",
        "outputId": "d16f6fce-5b41-4fab-a215-ae4bba475572"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9637073461058401"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(value)):\n",
        "  similarity = cosine_similarity(value[0], value[i])\n",
        "  print(\"Cosine Similarity\", i, \":\", similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLgpLoZWFgcf",
        "outputId": "82394a07-3123-4b1e-fd2a-7aacdbe9a3f4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity 0 : 0.9999999999999998\n",
            "Cosine Similarity 1 : 0.27651085126256936\n",
            "Cosine Similarity 2 : 0.18122023805649887\n",
            "Cosine Similarity 3 : 0.3267673760215494\n",
            "Cosine Similarity 4 : 0.19405120213133703\n",
            "Cosine Similarity 5 : 0.20316513371303502\n",
            "Cosine Similarity 6 : 0.2639310231083585\n",
            "Cosine Similarity 7 : 0.15637567678739486\n",
            "Cosine Similarity 8 : 0.24820938538048493\n",
            "Cosine Similarity 9 : 0.1561963943455993\n",
            "Cosine Similarity 10 : 0.2372774115291913\n",
            "Cosine Similarity 11 : 0.29712514758161357\n",
            "Cosine Similarity 12 : 0.2278927913226847\n",
            "Cosine Similarity 13 : 0.28872930529168567\n",
            "Cosine Similarity 14 : 0.4392014716690768\n",
            "Cosine Similarity 15 : 0.13692091522222488\n",
            "Cosine Similarity 16 : 0.25919821759075473\n",
            "Cosine Similarity 17 : 0.36363383721916986\n",
            "Cosine Similarity 18 : 0.28679718478954275\n",
            "Cosine Similarity 19 : 0.36286394372749203\n",
            "Cosine Similarity 20 : 0.3932855801000819\n",
            "Cosine Similarity 21 : 0.381467123264216\n",
            "Cosine Similarity 22 : 0.5077544939704627\n",
            "Cosine Similarity 23 : 0.5305253280777736\n",
            "Cosine Similarity 24 : 0.24469862383974658\n",
            "Cosine Similarity 25 : 0.593324124312568\n",
            "Cosine Similarity 26 : 0.6387564190658435\n",
            "Cosine Similarity 27 : 0.5479711274645406\n",
            "Cosine Similarity 28 : 0.2561833310642217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(value)):\n",
        "  similarity = cosine_similarity(ppa_result[0], ppa_result[i])\n",
        "  print(\"Cosine Similarity\", i, \":\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWTA4uXehLSp",
        "outputId": "890bf169-9c22-4f21-d9ba-46595205739c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity 0 : 1.0\n",
            "Cosine Similarity 1 : 0.1741783979116341\n",
            "Cosine Similarity 2 : 0.0493952189889063\n",
            "Cosine Similarity 3 : -0.12110205166171253\n",
            "Cosine Similarity 4 : 0.4949030223096774\n",
            "Cosine Similarity 5 : -0.36309477407223495\n",
            "Cosine Similarity 6 : -0.15579346821526416\n",
            "Cosine Similarity 7 : 0.15441210513430262\n",
            "Cosine Similarity 8 : -0.39983119924253396\n",
            "Cosine Similarity 9 : 0.17218881653353296\n",
            "Cosine Similarity 10 : 0.27673970945399423\n",
            "Cosine Similarity 11 : -0.003356796468733433\n",
            "Cosine Similarity 12 : -0.02221830077151306\n",
            "Cosine Similarity 13 : 0.058041876946014086\n",
            "Cosine Similarity 14 : -0.05381434457666614\n",
            "Cosine Similarity 15 : -0.026950592332469072\n",
            "Cosine Similarity 16 : -0.5163487074011823\n",
            "Cosine Similarity 17 : -0.03393731379219344\n",
            "Cosine Similarity 18 : -0.024216832845201562\n",
            "Cosine Similarity 19 : -0.31041876009404873\n",
            "Cosine Similarity 20 : -0.3879588455974878\n",
            "Cosine Similarity 21 : 0.06479137940119888\n",
            "Cosine Similarity 22 : -0.2168865550818318\n",
            "Cosine Similarity 23 : 0.43676821484485134\n",
            "Cosine Similarity 24 : 0.26553421969243385\n",
            "Cosine Similarity 25 : 0.0772144163116586\n",
            "Cosine Similarity 26 : 0.42466439065802625\n",
            "Cosine Similarity 27 : 0.13064142784514993\n",
            "Cosine Similarity 28 : -0.15253015410183746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L6JuuCwIppmd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yG7sV91ippd8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the JSON file\n",
        "with open('/content/templates2vec.json', 'r') as file:\n",
        "    vector_list = json.load(file)\n",
        "\n",
        "# Convert the list of lists back to a list of numpy arrays\n",
        "templates2vec = [np.array(vector) for vector in vector_list]"
      ],
      "metadata": {
        "id": "tuPFT0o1yc5B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(templates2vec))\n",
        "print(len(templates2vec[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXL4NZoq0x1L",
        "outputId": "64df2096-476d-46e6-a697-9145372f4986"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding template 30 with zeros vector for session with less than windows size\n",
        "templates2vec.append(np.zeros((384,)))"
      ],
      "metadata": {
        "id": "5YPsCbWcAbp8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Step1-2 PCA: Dimensionality reduction to 20-dimensional data\n",
        "\n",
        "estimator = PCA(n_components=20)\n",
        "pca_result = estimator.fit_transform(templates2vec)\n",
        "\n",
        "# Step1-3 PPA: De-averaged\n",
        "ppa_result = []\n",
        "result = pca_result - np.mean(pca_result)\n",
        "pca = PCA(n_components=20)\n",
        "pca_result = pca.fit_transform(result)\n",
        "U = pca.components_\n",
        "for i, x in enumerate(result):\n",
        "    for u in U[0:7]:\n",
        "        x = x - np.dot(u.transpose(), x) * u\n",
        "    ppa_result.append(list(x))\n",
        "ppa_result = np.array(ppa_result)\n"
      ],
      "metadata": {
        "id": "LD-HYrwV0jgs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the explained variances\n",
        "print(\"Variances (Percentage):\")\n",
        "print(estimator.explained_variance_ratio_ * 100)\n",
        "print(sum(estimator.explained_variance_ratio_ * 100)) #the percentage of variance for 20D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGUXSRN30jdm",
        "outputId": "92014c79-2eba-4ae0-86bc-9bc474b3f2b7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variances (Percentage):\n",
            "[16.95108926  9.71132818  7.55464857  7.04759043  6.38652924  5.76441679\n",
            "  4.85326883  4.5453545   4.18886277  3.4996711   3.22281884  2.91269412\n",
            "  2.62583848  2.48996362  2.32962006  1.9817766   1.91291862  1.75078388\n",
            "  1.60065955  1.51227075]\n",
            "92.84210418748184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ppa_result))\n",
        "print(len(ppa_result[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnXNbpiU1abH",
        "outputId": "98f2d743-c7b5-4816-dfbf-d9dacdf82f13"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMSEW9n72IA4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPXOotba0jbZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lkWT_oWv0jYy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aoq7vTsa0jWS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "McGLrSUr0jTr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSsHW7ez0jQ3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7VGhaV4pqBE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z7U4p6skT_u",
        "outputId": "b52270a4-4c41-44df-c130-05851636f8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-20 23:20:49--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257875 (252K) [text/plain]\n",
            "Saving to: ‘hdfs_train’\n",
            "\n",
            "hdfs_train          100%[===================>] 251.83K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-07-20 23:20:49 (48.3 MB/s) - ‘hdfs_train’ saved [257875/257875]\n",
            "\n",
            "--2023-07-20 23:20:49--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_normal\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29284282 (28M) [text/plain]\n",
            "Saving to: ‘hdfs_test_normal’\n",
            "\n",
            "hdfs_test_normal    100%[===================>]  27.93M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-07-20 23:20:49 (371 MB/s) - ‘hdfs_test_normal’ saved [29284282/29284282]\n",
            "\n",
            "--2023-07-20 23:20:49--  https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_abnormal\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 782479 (764K) [text/plain]\n",
            "Saving to: ‘hdfs_test_abnormal’\n",
            "\n",
            "hdfs_test_abnormal  100%[===================>] 764.14K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-07-20 23:20:49 (104 MB/s) - ‘hdfs_test_abnormal’ saved [782479/782479]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download datasets\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_train'\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_normal'\n",
        "!wget 'https://raw.githubusercontent.com/donglee-afar/logdeep/master/data/hdfs/hdfs_test_abnormal'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "rNI34FVblAMn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['hdfs_train','hdfs_test_normal','hdfs_test_abnormal']\n",
        "templates = set()\n",
        "\n",
        "for name in names:\n",
        "  with open('/content/' + name, 'r') as f:\n",
        "          for row in f:\n",
        "            for temp in row.split():\n",
        "              templates.add(temp)\n",
        "\n",
        "print(templates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFchHkYHi2uB",
        "outputId": "80363b38-1b97-46aa-b7b5-a0a7dba06995"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'21', '6', '1', '27', '5', '2', '28', '19', '15', '4', '20', '14', '18', '25', '7', '9', '26', '23', '10', '24', '3', '13', '17', '8', '22', '11', '12', '16'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted([int(num) for num in templates])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsxxaYg_jqKf",
        "outputId": "1fb6ceaf-e8fb-4061-fa17-4d0c189a04fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'hdfs_train'\n",
        "window_size = 10\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            num_sessions += 1\n",
        "            line = [ppa_result[int(i) - 1] for i in row.strip().split()] # we substract by one from templates index for starting from zero\n",
        "            for i in range(len(line) - window_size):\n",
        "                inputs.append(line[i:i + window_size])\n",
        "                outputs.append(line[i + window_size])\n",
        "\n",
        "print('Number of sessions({}): {}'.format(name, num_sessions))\n",
        "print('Number of seqs({}): {}'.format(name, len(inputs)))\n",
        "dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs,dtype=torch.float ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EMsKC8NthzK",
        "outputId": "25a4a5ef-7072-4bf4-c98f-d10a64f8734d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_train): 4855\n",
            "Number of seqs(hdfs_train): 46575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-5ae3517f921c>:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs,dtype=torch.float ))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out.shape : [batch_size, sequence_length, hidden_size]\n",
        "        out = self.fc(out[:, -1, :]) #The : before , -1, : indicates that we want to include all elements along the first dimension (batch dimension). -1 represents the index of the last element along the second dimension (sequence length). : after , -1 indicates that we want to include all elements along the third dimension (hidden size)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Pck9q_A7uV47"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 20\n",
        "num_layers = 2\n",
        "hidden_size = 64\n",
        "num_classes = 20\n",
        "batch_size = 2048\n",
        "num_epochs = 200"
      ],
      "metadata": {
        "id": "fbnCcSOiudxf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "EV1cKoL2uj7I"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "start_time = time.time()\n",
        "total_step = len(dataloader)\n",
        "for epoch in range(num_epochs):  # Loop over the dataset multiple times\n",
        "    train_loss = 0\n",
        "    for step, (seq, label) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        seq = seq.clone().detach().view(-1, window_size, input_size).to(device)\n",
        "        output = model(seq)\n",
        "        loss = criterion(output, label.to(device))\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss / total_step))\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWAjr1QOvB-n",
        "outputId": "fbfd12db-8989-4ea3-dca6-19c6a56d3549"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/200], train_loss: 0.0091\n",
            "Epoch [2/200], train_loss: 0.0071\n",
            "Epoch [3/200], train_loss: 0.0060\n",
            "Epoch [4/200], train_loss: 0.0047\n",
            "Epoch [5/200], train_loss: 0.0040\n",
            "Epoch [6/200], train_loss: 0.0035\n",
            "Epoch [7/200], train_loss: 0.0032\n",
            "Epoch [8/200], train_loss: 0.0030\n",
            "Epoch [9/200], train_loss: 0.0028\n",
            "Epoch [10/200], train_loss: 0.0027\n",
            "Epoch [11/200], train_loss: 0.0026\n",
            "Epoch [12/200], train_loss: 0.0025\n",
            "Epoch [13/200], train_loss: 0.0025\n",
            "Epoch [14/200], train_loss: 0.0024\n",
            "Epoch [15/200], train_loss: 0.0024\n",
            "Epoch [16/200], train_loss: 0.0023\n",
            "Epoch [17/200], train_loss: 0.0023\n",
            "Epoch [18/200], train_loss: 0.0023\n",
            "Epoch [19/200], train_loss: 0.0023\n",
            "Epoch [20/200], train_loss: 0.0022\n",
            "Epoch [21/200], train_loss: 0.0022\n",
            "Epoch [22/200], train_loss: 0.0022\n",
            "Epoch [23/200], train_loss: 0.0021\n",
            "Epoch [24/200], train_loss: 0.0021\n",
            "Epoch [25/200], train_loss: 0.0021\n",
            "Epoch [26/200], train_loss: 0.0020\n",
            "Epoch [27/200], train_loss: 0.0020\n",
            "Epoch [28/200], train_loss: 0.0020\n",
            "Epoch [29/200], train_loss: 0.0019\n",
            "Epoch [30/200], train_loss: 0.0019\n",
            "Epoch [31/200], train_loss: 0.0019\n",
            "Epoch [32/200], train_loss: 0.0019\n",
            "Epoch [33/200], train_loss: 0.0019\n",
            "Epoch [34/200], train_loss: 0.0019\n",
            "Epoch [35/200], train_loss: 0.0018\n",
            "Epoch [36/200], train_loss: 0.0018\n",
            "Epoch [37/200], train_loss: 0.0018\n",
            "Epoch [38/200], train_loss: 0.0018\n",
            "Epoch [39/200], train_loss: 0.0018\n",
            "Epoch [40/200], train_loss: 0.0018\n",
            "Epoch [41/200], train_loss: 0.0018\n",
            "Epoch [42/200], train_loss: 0.0018\n",
            "Epoch [43/200], train_loss: 0.0018\n",
            "Epoch [44/200], train_loss: 0.0018\n",
            "Epoch [45/200], train_loss: 0.0018\n",
            "Epoch [46/200], train_loss: 0.0018\n",
            "Epoch [47/200], train_loss: 0.0018\n",
            "Epoch [48/200], train_loss: 0.0017\n",
            "Epoch [49/200], train_loss: 0.0017\n",
            "Epoch [50/200], train_loss: 0.0017\n",
            "Epoch [51/200], train_loss: 0.0017\n",
            "Epoch [52/200], train_loss: 0.0017\n",
            "Epoch [53/200], train_loss: 0.0017\n",
            "Epoch [54/200], train_loss: 0.0017\n",
            "Epoch [55/200], train_loss: 0.0017\n",
            "Epoch [56/200], train_loss: 0.0017\n",
            "Epoch [57/200], train_loss: 0.0017\n",
            "Epoch [58/200], train_loss: 0.0017\n",
            "Epoch [59/200], train_loss: 0.0017\n",
            "Epoch [60/200], train_loss: 0.0017\n",
            "Epoch [61/200], train_loss: 0.0017\n",
            "Epoch [62/200], train_loss: 0.0017\n",
            "Epoch [63/200], train_loss: 0.0017\n",
            "Epoch [64/200], train_loss: 0.0017\n",
            "Epoch [65/200], train_loss: 0.0017\n",
            "Epoch [66/200], train_loss: 0.0016\n",
            "Epoch [67/200], train_loss: 0.0017\n",
            "Epoch [68/200], train_loss: 0.0016\n",
            "Epoch [69/200], train_loss: 0.0016\n",
            "Epoch [70/200], train_loss: 0.0016\n",
            "Epoch [71/200], train_loss: 0.0016\n",
            "Epoch [72/200], train_loss: 0.0016\n",
            "Epoch [73/200], train_loss: 0.0016\n",
            "Epoch [74/200], train_loss: 0.0016\n",
            "Epoch [75/200], train_loss: 0.0016\n",
            "Epoch [76/200], train_loss: 0.0016\n",
            "Epoch [77/200], train_loss: 0.0016\n",
            "Epoch [78/200], train_loss: 0.0016\n",
            "Epoch [79/200], train_loss: 0.0016\n",
            "Epoch [80/200], train_loss: 0.0016\n",
            "Epoch [81/200], train_loss: 0.0016\n",
            "Epoch [82/200], train_loss: 0.0016\n",
            "Epoch [83/200], train_loss: 0.0016\n",
            "Epoch [84/200], train_loss: 0.0016\n",
            "Epoch [85/200], train_loss: 0.0016\n",
            "Epoch [86/200], train_loss: 0.0016\n",
            "Epoch [87/200], train_loss: 0.0016\n",
            "Epoch [88/200], train_loss: 0.0016\n",
            "Epoch [89/200], train_loss: 0.0016\n",
            "Epoch [90/200], train_loss: 0.0016\n",
            "Epoch [91/200], train_loss: 0.0016\n",
            "Epoch [92/200], train_loss: 0.0016\n",
            "Epoch [93/200], train_loss: 0.0016\n",
            "Epoch [94/200], train_loss: 0.0016\n",
            "Epoch [95/200], train_loss: 0.0016\n",
            "Epoch [96/200], train_loss: 0.0016\n",
            "Epoch [97/200], train_loss: 0.0016\n",
            "Epoch [98/200], train_loss: 0.0016\n",
            "Epoch [99/200], train_loss: 0.0016\n",
            "Epoch [100/200], train_loss: 0.0016\n",
            "Epoch [101/200], train_loss: 0.0016\n",
            "Epoch [102/200], train_loss: 0.0016\n",
            "Epoch [103/200], train_loss: 0.0016\n",
            "Epoch [104/200], train_loss: 0.0015\n",
            "Epoch [105/200], train_loss: 0.0016\n",
            "Epoch [106/200], train_loss: 0.0015\n",
            "Epoch [107/200], train_loss: 0.0016\n",
            "Epoch [108/200], train_loss: 0.0015\n",
            "Epoch [109/200], train_loss: 0.0016\n",
            "Epoch [110/200], train_loss: 0.0015\n",
            "Epoch [111/200], train_loss: 0.0015\n",
            "Epoch [112/200], train_loss: 0.0015\n",
            "Epoch [113/200], train_loss: 0.0015\n",
            "Epoch [114/200], train_loss: 0.0015\n",
            "Epoch [115/200], train_loss: 0.0015\n",
            "Epoch [116/200], train_loss: 0.0015\n",
            "Epoch [117/200], train_loss: 0.0015\n",
            "Epoch [118/200], train_loss: 0.0015\n",
            "Epoch [119/200], train_loss: 0.0015\n",
            "Epoch [120/200], train_loss: 0.0015\n",
            "Epoch [121/200], train_loss: 0.0015\n",
            "Epoch [122/200], train_loss: 0.0015\n",
            "Epoch [123/200], train_loss: 0.0015\n",
            "Epoch [124/200], train_loss: 0.0015\n",
            "Epoch [125/200], train_loss: 0.0015\n",
            "Epoch [126/200], train_loss: 0.0015\n",
            "Epoch [127/200], train_loss: 0.0015\n",
            "Epoch [128/200], train_loss: 0.0015\n",
            "Epoch [129/200], train_loss: 0.0015\n",
            "Epoch [130/200], train_loss: 0.0015\n",
            "Epoch [131/200], train_loss: 0.0015\n",
            "Epoch [132/200], train_loss: 0.0015\n",
            "Epoch [133/200], train_loss: 0.0015\n",
            "Epoch [134/200], train_loss: 0.0015\n",
            "Epoch [135/200], train_loss: 0.0015\n",
            "Epoch [136/200], train_loss: 0.0015\n",
            "Epoch [137/200], train_loss: 0.0015\n",
            "Epoch [138/200], train_loss: 0.0015\n",
            "Epoch [139/200], train_loss: 0.0015\n",
            "Epoch [140/200], train_loss: 0.0015\n",
            "Epoch [141/200], train_loss: 0.0015\n",
            "Epoch [142/200], train_loss: 0.0015\n",
            "Epoch [143/200], train_loss: 0.0015\n",
            "Epoch [144/200], train_loss: 0.0015\n",
            "Epoch [145/200], train_loss: 0.0015\n",
            "Epoch [146/200], train_loss: 0.0015\n",
            "Epoch [147/200], train_loss: 0.0015\n",
            "Epoch [148/200], train_loss: 0.0015\n",
            "Epoch [149/200], train_loss: 0.0015\n",
            "Epoch [150/200], train_loss: 0.0015\n",
            "Epoch [151/200], train_loss: 0.0015\n",
            "Epoch [152/200], train_loss: 0.0015\n",
            "Epoch [153/200], train_loss: 0.0015\n",
            "Epoch [154/200], train_loss: 0.0015\n",
            "Epoch [155/200], train_loss: 0.0015\n",
            "Epoch [156/200], train_loss: 0.0015\n",
            "Epoch [157/200], train_loss: 0.0015\n",
            "Epoch [158/200], train_loss: 0.0015\n",
            "Epoch [159/200], train_loss: 0.0015\n",
            "Epoch [160/200], train_loss: 0.0015\n",
            "Epoch [161/200], train_loss: 0.0015\n",
            "Epoch [162/200], train_loss: 0.0015\n",
            "Epoch [163/200], train_loss: 0.0015\n",
            "Epoch [164/200], train_loss: 0.0015\n",
            "Epoch [165/200], train_loss: 0.0015\n",
            "Epoch [166/200], train_loss: 0.0015\n",
            "Epoch [167/200], train_loss: 0.0015\n",
            "Epoch [168/200], train_loss: 0.0015\n",
            "Epoch [169/200], train_loss: 0.0015\n",
            "Epoch [170/200], train_loss: 0.0015\n",
            "Epoch [171/200], train_loss: 0.0015\n",
            "Epoch [172/200], train_loss: 0.0015\n",
            "Epoch [173/200], train_loss: 0.0015\n",
            "Epoch [174/200], train_loss: 0.0015\n",
            "Epoch [175/200], train_loss: 0.0015\n",
            "Epoch [176/200], train_loss: 0.0015\n",
            "Epoch [177/200], train_loss: 0.0015\n",
            "Epoch [178/200], train_loss: 0.0015\n",
            "Epoch [179/200], train_loss: 0.0015\n",
            "Epoch [180/200], train_loss: 0.0015\n",
            "Epoch [181/200], train_loss: 0.0015\n",
            "Epoch [182/200], train_loss: 0.0015\n",
            "Epoch [183/200], train_loss: 0.0015\n",
            "Epoch [184/200], train_loss: 0.0015\n",
            "Epoch [185/200], train_loss: 0.0015\n",
            "Epoch [186/200], train_loss: 0.0015\n",
            "Epoch [187/200], train_loss: 0.0015\n",
            "Epoch [188/200], train_loss: 0.0015\n",
            "Epoch [189/200], train_loss: 0.0015\n",
            "Epoch [190/200], train_loss: 0.0015\n",
            "Epoch [191/200], train_loss: 0.0015\n",
            "Epoch [192/200], train_loss: 0.0015\n",
            "Epoch [193/200], train_loss: 0.0015\n",
            "Epoch [194/200], train_loss: 0.0015\n",
            "Epoch [195/200], train_loss: 0.0015\n",
            "Epoch [196/200], train_loss: 0.0015\n",
            "Epoch [197/200], train_loss: 0.0015\n",
            "Epoch [198/200], train_loss: 0.0015\n",
            "Epoch [199/200], train_loss: 0.0015\n",
            "Epoch [200/200], train_loss: 0.0015\n",
            "elapsed_time: 155.958s\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_candidates = 9 # on paper is g , top-g(here top 9) probabilities to appear next are considered normal\n"
      ],
      "metadata": {
        "id": "MOkcg6QZssbC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(name):\n",
        "    # If you what to replicate the DeepLog paper results(Actually, I have a better result than DeepLog paper results),\n",
        "    # you should use the 'list' not 'set' to obtain the full dataset, I use 'set' just for test and acceleration.\n",
        "    hdfs = set()\n",
        "    # hdfs = []\n",
        "    with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            line = [int(i) - 1 for i in row.strip().split()]\n",
        "            line = line + [30] * (window_size + 1 - len(line)) #if the length of the line is less than windows size, it covers by 30 a template with zeros vector\n",
        "            hdfs.add(tuple(line))\n",
        "            # hdfs.append(tuple(line))\n",
        "    print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
        "    return hdfs"
      ],
      "metadata": {
        "id": "-wdcBKVIszz4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_normal_loader = generate('hdfs_test_normal')\n",
        "test_abnormal_loader = generate('hdfs_test_abnormal')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-FjaSnr3VNs",
        "outputId": "35c33592-8548-491c-9570-28874bddaa9e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(hdfs_test_normal): 14177\n",
            "Number of sessions(hdfs_test_abnormal): 4123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppa_result[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GixnJXFUBO0e",
        "outputId": "ce18ee43-4bb6-412c-d09b-fdc8e52fc2d2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00000000e+00,  1.05725075e-16,  2.23860680e-16, -1.91633583e-16,\n",
              "        2.29297043e-16,  5.33327984e-17,  3.13117587e-16, -9.63968152e-02,\n",
              "       -2.97057767e-04,  4.03384685e-02,  5.60153159e-02,  2.55694891e-02,\n",
              "        1.05996333e-02, -9.02890729e-02, -4.59559163e-02,  1.29812077e-01,\n",
              "       -4.33909911e-02, -6.78539087e-02, -7.97822469e-02,  7.21287747e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJNv3ejsBo_q",
        "outputId": "fb9645eb-04bc-4208-fca5-544cff8011fd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000e+00,  1.0573e-16,  2.2386e-16, -1.9163e-16,  2.2930e-16,\n",
              "         5.3333e-17,  3.1312e-16, -9.6397e-02, -2.9706e-04,  4.0338e-02,\n",
              "         5.6015e-02,  2.5569e-02,  1.0600e-02, -9.0289e-02, -4.5956e-02,\n",
              "         1.2981e-01, -4.3391e-02, -6.7854e-02, -7.9782e-02,  7.2129e-02],\n",
              "       device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TizamszzBRp2",
        "outputId": "ab05b3fc-a1ff-42cb-c402-6d3dc358e99d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.7094e-03,  6.5550e-04,  1.3084e-03, -1.0537e-04, -2.2506e-03,\n",
              "        -5.0772e-04, -2.1036e-04, -9.3410e-02, -1.5077e-02,  2.9976e-02,\n",
              "         4.0161e-02,  1.2393e-02,  1.6254e-02, -9.2929e-02, -4.9094e-02,\n",
              "         1.1717e-01, -4.5852e-02, -5.2237e-02, -7.1752e-02,  6.4094e-02],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(ppa_result[10],output[0].cpu()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch3OrRVvCuxO",
        "outputId": "43ed1ff6-06e1-4ee2-abfa-8ef3a43b2832"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.991195049883028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(label.cpu(),output[0].cpu())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fRFE-t5B6np",
        "outputId": "8ea9c4a1-9349-41a1-8d7e-1908894b4848"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.991195049883028"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppa_result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kFXRjvQqQiL",
        "outputId": "e1ae9fe4-be2c-47f9-c3e0-b4ced9325f3c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label.cpu().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X06W31H7pmEj",
        "outputId": "c8e2557c-1cd8-49a0-b831-a171a192bab6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.cpu().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbzM-FRFpoPd",
        "outputId": "c9abb066-eac9-4809-d815-4bb2d2daa19d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute cosine similarity between vec1 and vec2\n",
        "similarity_matrix = cosine_similarity(label.cpu().reshape(1, -1), output.cpu().reshape(1, -1))\n",
        "\n",
        "# The result will be a 2D array representing the cosine similarity between the vectors\n",
        "print(similarity_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RrYn6GDpCWq",
        "outputId": "c1ee02c9-654a-46d2-db18-40377df730f0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99119509]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argsort(cosine_similarity(output.cpu().reshape(1, -1),ppa_result))[0][-num_candidates:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbYdZxCFqHIw",
        "outputId": "5f2620e5-884e-4e17-9b06-b1a8c54733a2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6, 27, 11, 20, 14, 23,  1,  7, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for line in test_normal_loader:\n",
        "        print(line)\n",
        "        for i in range(len(line) - window_size):\n",
        "            session = line[i:i + window_size]\n",
        "            print(session)\n",
        "            seq = [ppa_result[temp] for temp in session]\n",
        "            label = line[i + window_size]\n",
        "            print(label)\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            print(label)\n",
        "            output = model(seq)\n",
        "            predicted = np.argsort(cosine_similarity(output.cpu().reshape(1, -1),ppa_result))[0][-num_candidates:]\n",
        "            print(predicted)\n",
        "            if label not in predicted:\n",
        "                print('ok')\n",
        "                FP += 1\n",
        "                fp_set.add(line)\n",
        "                break\n",
        "        break\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvkPkVjF--I2",
        "outputId": "4410c184-9284-48c9-c54e-972a9ef1c7b3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 4, 4, 21, 10, 8, 25, 25, 10, 8, 10, 8, 25, 22, 22, 22, 20, 20, 20)\n",
            "(4, 4, 4, 21, 10, 8, 25, 25, 10, 8)\n",
            "10\n",
            "10\n",
            "[ 6 27 11 20 14 23  1  7 10]\n",
            "(4, 4, 21, 10, 8, 25, 25, 10, 8, 10)\n",
            "8\n",
            "8\n",
            "[26 28 17 18  6 25 11 20  8]\n",
            "(4, 21, 10, 8, 25, 25, 10, 8, 10, 8)\n",
            "25\n",
            "25\n",
            "[18 13  6 24 11 28  8 19 25]\n",
            "(21, 10, 8, 25, 25, 10, 8, 10, 8, 25)\n",
            "22\n",
            "22\n",
            "[11 13  3 10 15  2  4 21 22]\n",
            "(10, 8, 25, 25, 10, 8, 10, 8, 25, 22)\n",
            "22\n",
            "22\n",
            "[16 12 10 11 13 15  4 21 22]\n",
            "(8, 25, 25, 10, 8, 10, 8, 25, 22, 22)\n",
            "22\n",
            "22\n",
            "[16  2 10 11 13 15  4 21 22]\n",
            "(25, 25, 10, 8, 10, 8, 25, 22, 22, 22)\n",
            "20\n",
            "20\n",
            "[17  6 26 28 10  8 23 27 20]\n",
            "(25, 10, 8, 10, 8, 25, 22, 22, 22, 20)\n",
            "20\n",
            "20\n",
            "[17  6 28 26 10  8 23 27 20]\n",
            "(10, 8, 10, 8, 25, 22, 22, 22, 20, 20)\n",
            "20\n",
            "20\n",
            "[17  6 28 26 10  8 23 27 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "TP = 0\n",
        "FP = 0\n",
        "\n",
        "fp_set = set()\n",
        "fn_set = set()  # Initialize the FN list\n",
        "\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for line in test_normal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            session = line[i:i + window_size]\n",
        "            seq = [ppa_result[temp] for temp in session]\n",
        "            label = line[i + window_size]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            output = model(seq)\n",
        "            predicted = np.argsort(cosine_similarity(output.cpu().reshape(1, -1),ppa_result))[0][-num_candidates:]\n",
        "            if label not in predicted:\n",
        "                FP += 1\n",
        "                fp_set.add(line)\n",
        "                break   #with just one wrong prediction in a line , we assume , abnormal\n",
        "with torch.no_grad():\n",
        "    for line in test_abnormal_loader:\n",
        "        for i in range(len(line) - window_size):\n",
        "            session = line[i:i + window_size]\n",
        "            seq = [ppa_result[temp] for temp in session]\n",
        "            label = line[i + window_size]\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            output = model(seq)\n",
        "            predicted = np.argsort(cosine_similarity(output.cpu().reshape(1, -1),ppa_result))[0][-num_candidates:]\n",
        "            if label not in predicted:\n",
        "                TP += 1\n",
        "                break\n",
        "            else:\n",
        "                fn_set.add(line)  # Append the line to the FN list when a false negative occurs\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "# Compute precision, recall and F1-measure\n",
        "FN = len(test_abnormal_loader) - TP\n",
        "P = 100 * TP / (TP + FP)\n",
        "R = 100 * TP / (TP + FN)\n",
        "F1 = 2 * P * R / (P + R)\n",
        "print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
        "print('Finished Predicting')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9oqMZAbC_so",
        "outputId": "352c0eed-0f27-4d28-b3a9-9b52e2983361"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 161.869s\n",
            "false positive (FP): 8303, false negative (FN): 11, Precision: 33.121%, Recall: 99.733%, F1-measure: 49.728%\n",
            "Finished Predicting\n"
          ]
        }
      ]
    }
  ]
}