{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafa-ja/Anomaly-detection/blob/main/BGL2_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload log files\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/X_train_index'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/Xabnorm_test_index'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/Xnorm_test_index'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/log2index'\n",
        "!wget 'https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/reduced_index2embed'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i2YpVSwj8dl",
        "outputId": "f3d51354-abee-420b-9ea5-7df1247829ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-05 09:02:59--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/X_train_index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9024878 (8.6M) [text/plain]\n",
            "Saving to: ‘X_train_index’\n",
            "\n",
            "X_train_index       100%[===================>]   8.61M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-05 09:03:15 (79.5 MB/s) - ‘X_train_index’ saved [9024878/9024878]\n",
            "\n",
            "--2023-09-05 09:03:16--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/Xabnorm_test_index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1775490 (1.7M) [text/plain]\n",
            "Saving to: ‘Xabnorm_test_index’\n",
            "\n",
            "Xabnorm_test_index  100%[===================>]   1.69M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-09-05 09:03:45 (30.8 MB/s) - ‘Xabnorm_test_index’ saved [1775490/1775490]\n",
            "\n",
            "--2023-09-05 09:03:45--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/Xnorm_test_index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 502 Bad Gateway\n",
            "2023-09-05 09:04:09 ERROR 502: Bad Gateway.\n",
            "\n",
            "--2023-09-05 09:04:09--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/log2index\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73231 (72K) [application/octet-stream]\n",
            "Saving to: ‘log2index’\n",
            "\n",
            "log2index           100%[===================>]  71.51K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-09-05 09:04:11 (6.10 MB/s) - ‘log2index’ saved [73231/73231]\n",
            "\n",
            "--2023-09-05 09:04:11--  https://raw.githubusercontent.com/mostafa-ja/Anomaly-detection/main/datasets/BGL100/reduced_index2embed\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 885491 (865K) [text/plain]\n",
            "Saving to: ‘reduced_index2embed’\n",
            "\n",
            "reduced_index2embed 100%[===================>] 864.74K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-09-05 09:04:25 (18.9 MB/s) - ‘reduced_index2embed’ saved [885491/885491]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "jd9WP1rSrLSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b09fa3-f702-4653-9229-1b9d887a7b7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Json file name\n",
        "with open('/content/reduced_index2embed') as f:\n",
        "    embeddings = [json.loads(line) for line in f.readlines()]\n",
        "\n",
        "len(embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFtNRiAhl4Cd",
        "outputId": "ac670677-a1b4-4416-ecee-44ffc6fab4ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM Autoencoder model with dropout\n",
        "class LSTMAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, sequence_length, dropout_prob): #input_dim= embeddings_dim\n",
        "        super(LSTMAutoencoder, self).__init__()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True, dropout=dropout_prob)\n",
        "        self.decoder = nn.LSTM(hidden_dim , input_dim, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded, _ = self.encoder(x)\n",
        "        #print(encoded.shape)\n",
        "        encoded = encoded[:,-1:,:] # output of last cell\n",
        "        encoded = self.fc(encoded)\n",
        "        #print(encoded.shape)\n",
        "        input_decode = torch.tile(encoded, (1, self.sequence_length, 1))\n",
        "        decoded, _ = self.decoder(input_decode)\n",
        "        return decoded"
      ],
      "metadata": {
        "id": "BMnD_BY82ZVd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5\n",
        "input_size = len(embeddings[0]) #embedding vector dimension\n",
        "hidden_dim = 64\n",
        "num_layers = 2\n",
        "dropout_prob = 0.2\n",
        "\n",
        "model = LSTMAutoencoder(input_size, hidden_dim, 2, sequence_length, dropout_prob).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPQ1gUe22tIP",
        "outputId": "57f0a30f-2d56-4128-a13d-43999df71fb9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMAutoencoder(\n",
              "  (encoder): LSTM(55, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
              "  (decoder): LSTM(64, 55, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=128, out_features=64, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.randn(1,sequence_length, input_size) #batch_size=1\n",
        "model(data.to(device)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dloxW2iT3DWn",
        "outputId": "a5886416-482d-448b-9753-8b3f3e6f78a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 55])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of parameters\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of Parameters: {num_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIEBmDYf29xi",
        "outputId": "b7958aa0-9120-4697-ebcc-46c2d074a887"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Parameters: 220796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'X_train_index'\n",
        "window_size = sequence_length\n",
        "num_sessions = 0\n",
        "inputs = []\n",
        "#outputs = []\n",
        "\n",
        "with open('/content/' + name, 'r') as f:\n",
        "        for row in tqdm(f, desc=\"Processing Rows\"):\n",
        "            num_sessions += 1\n",
        "            line = [ embeddings[int(i)] for i in row.strip().split()]\n",
        "            for i in range(len(line) - window_size):\n",
        "                inputs.append(line[i:i + window_size])\n",
        "                #outputs.append(line[i + window_size])\n",
        "\n",
        "print('Number of sessions({}): {}'.format(name, num_sessions))\n",
        "print('Number of seqs({}): {}'.format(name, len(inputs)))\n",
        "#dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float), torch.tensor(outputs))\n",
        "dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIwHnSfe0f3k",
        "outputId": "f65766fa-ab3e-458b-e3b5-2c404b0fe0f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 34141it [00:04, 6934.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(X_train_index): 34141\n",
            "Number of seqs(X_train_index): 3243395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
        "len(dataloader) # regarding to batch size"
      ],
      "metadata": {
        "id": "SyLp6yyx4PGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf9466a-9553-4ebc-f1f1-50e4f9cffa0b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6335"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step, (seq) in enumerate(dataloader):\n",
        "  print(seq[0].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOy2RaCB6AWx",
        "outputId": "9c031630-753e-4881-e464-b80cce123b76"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 5, 55])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, lr_step=(8,12,16), lr_decay_ratio=0.2):\n",
        "    \"\"\"Adjust the learning rate based on the epoch number.\"\"\"\n",
        "    if epoch == 0:\n",
        "        optimizer.param_groups[0]['lr'] /= 8\n",
        "    elif epoch in [1, 2, 3]:  # in step five , we finish warm up ,and start normal learning rate\n",
        "        optimizer.param_groups[0]['lr'] *= 2\n",
        "    if epoch in lr_step: # in these steps , we are geting close to optimal point so we need to have shorter step\n",
        "        optimizer.param_groups[0]['lr'] *= lr_decay_ratio\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "HHyNWe1DfYPq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Loss and optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "iHdDOptGaLCt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.train()\n",
        "start_time = time.time()\n",
        "total_step = len(dataloader)\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Processing Rows\"):  # Loop over the dataset multiple times\n",
        "    optimizer = adjust_learning_rate(optimizer, epoch)\n",
        "    train_loss = 0\n",
        "    for step, (seq) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        seq = seq[0].clone().detach().view(-1, window_size, input_size).to(device)\n",
        "        output = model(seq)\n",
        "        loss = criterion(output, seq.to(device))\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], train_loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss / total_step))\n",
        "elapsed_time = time.time() - start_time\n",
        "print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "vQ_t5bz35SYq",
        "outputId": "557d1d62-ab01-41d4-e3ca-091cac6549d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows:   0%|          | 0/20 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-746aff5b46b8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjust_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to save datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_7Qgbv7Qp7AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/BGL1_parameters.pth')"
      ],
      "metadata": {
        "id": "G_xbylKoiwAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EVALUATION**"
      ],
      "metadata": {
        "id": "fTKswHBdbfBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "in cpu\n",
        "```\n",
        "my_model = model.load_state_dict(torch.load('model_parameters.pth', map_location=torch.device(device)))\n",
        "\n",
        "# Put the model in evaluation mode if necessary\n",
        "model.eval()\n",
        "```\n",
        "\n",
        "in cuda\n",
        "\n",
        "\n",
        "```\n",
        "model.load_state_dict(torch.load('model_parameters.pth'))\n",
        "\n",
        "# Put the model in evaluation mode if necessary\n",
        "model.eval()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ppqwoB9ITsac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "id": "wm0bhoHL5yjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa5151df-a5c8-4c5e-fdb7-556fee159225"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "736"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(name):\n",
        "    window_size = sequence_length\n",
        "    hdfs = {} #store the unique sequences and their counts.\n",
        "    length = 0\n",
        "    with open('/content/' + name, 'r') as f:\n",
        "        for row in f:\n",
        "            line = [int(i) for i in row.strip().split()]\n",
        "            hdfs[tuple(line)] = hdfs.get(tuple(line), 0) + 1   #If the tuple is not present in the dictionary, hdfs.get(tuple(ln), 0) returns 0, and the code initializes the count to 1.\n",
        "            length += 1\n",
        "            # hdfs.append(tuple(line))\n",
        "    print('Number of sessions({}): {}'.format(name, len(hdfs)))\n",
        "    return hdfs, length"
      ],
      "metadata": {
        "id": "zeXyQLVK5zAO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_normal_loader, test_normal_length = generate('Xnorm_test_index')\n",
        "test_abnormal_loader, test_abnormal_length = generate('Xabnorm_test_index')"
      ],
      "metadata": {
        "id": "pUyqMSfg7Ba-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ba0cb2-3585-45d5-bcfa-580833703959"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sessions(Xnorm_test_index): 4207\n",
            "Number of sessions(Xabnorm_test_index): 1893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(threshold):\n",
        "  # Test the model\n",
        "  model.eval()\n",
        "\n",
        "  TP = 0\n",
        "  FP = 0\n",
        "\n",
        "  start_time = time.time()\n",
        "  with torch.no_grad():\n",
        "      for line in tqdm(test_normal_loader.keys(), desc=\"Processing Rows\"):\n",
        "          for i in range(len(line) - window_size):\n",
        "              session = line[i:i + window_size]\n",
        "              seq = [embeddings[temp] for temp in session]\n",
        "              seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "              output = model(seq)\n",
        "\n",
        "              loss = criterion(output, seq)\n",
        "\n",
        "              if (loss.cpu().detach().numpy()>threshold):\n",
        "                FP += test_normal_loader[line] # numbers of that set we have\n",
        "                break\n",
        "  with torch.no_grad():\n",
        "      for line in tqdm(test_abnormal_loader.keys(), desc=\"Processing Rows\"):\n",
        "          for i in range(len(line) - window_size):\n",
        "              session = line[i:i + window_size]\n",
        "              seq = [embeddings[temp] for temp in session]\n",
        "              seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "              output = model(seq)\n",
        "\n",
        "              loss = criterion(output, seq)\n",
        "\n",
        "              if (loss.cpu().detach().numpy()>threshold):\n",
        "                TP += test_abnormal_loader[line]\n",
        "                break\n",
        "  elapsed_time = time.time() - start_time\n",
        "  print('elapsed_time: {:.3f}s'.format(elapsed_time))\n",
        "  # Compute precision, recall and F1-measure\n",
        "  FN = test_abnormal_length - TP\n",
        "  P = 100 * TP / (TP + FP)\n",
        "  R = 100 * TP / (TP + FN)\n",
        "  F1 = 2 * P * R / (P + R)\n",
        "  print('false positive (FP): {}, false negative (FN): {}, Precision: {:.3f}%, Recall: {:.3f}%, F1-measure: {:.3f}%'.format(FP, FN, P, R, F1))\n",
        "  print('Finished Predicting')"
      ],
      "metadata": {
        "id": "xtAPzH7h9cZK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = [0.0004,0.0006,0.0008,0.001]\n",
        "for i in threshold:\n",
        "  print('-------------------------------------------------------------------------')\n",
        "  print('threshold = ',i)\n",
        "  evaluation(i)"
      ],
      "metadata": {
        "id": "dCegQ5i4-ZKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2084d59-166e-4ab1-e1c4-d46036220ef7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------\n",
            "threshold =  0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 4207/4207 [00:51<00:00, 82.45it/s] \n",
            "Processing Rows: 100%|██████████| 1893/1893 [00:13<00:00, 138.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 64.733s\n",
            "false positive (FP): 4572, false negative (FN): 5, Precision: 51.201%, Recall: 99.896%, F1-measure: 67.702%\n",
            "Finished Predicting\n",
            "-------------------------------------------------------------------------\n",
            "threshold =  0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 4207/4207 [01:02<00:00, 67.83it/s] \n",
            "Processing Rows: 100%|██████████| 1893/1893 [00:15<00:00, 123.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 77.379s\n",
            "false positive (FP): 4400, false negative (FN): 5, Precision: 52.158%, Recall: 99.896%, F1-measure: 68.533%\n",
            "Finished Predicting\n",
            "-------------------------------------------------------------------------\n",
            "threshold =  0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 4207/4207 [01:04<00:00, 65.02it/s]\n",
            "Processing Rows: 100%|██████████| 1893/1893 [00:15<00:00, 121.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 80.251s\n",
            "false positive (FP): 4367, false negative (FN): 6, Precision: 52.341%, Recall: 99.875%, F1-measure: 68.686%\n",
            "Finished Predicting\n",
            "-------------------------------------------------------------------------\n",
            "threshold =  0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 4207/4207 [01:12<00:00, 57.88it/s]\n",
            "Processing Rows: 100%|██████████| 1893/1893 [00:17<00:00, 108.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 90.083s\n",
            "false positive (FP): 4238, false negative (FN): 549, Precision: 50.088%, Recall: 88.567%, F1-measure: 63.989%\n",
            "Finished Predicting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = [0.002]\n",
        "for i in threshold:\n",
        "  print('-------------------------------------------------------------------------')\n",
        "  print('threshold = ', i)\n",
        "  evaluation(i)"
      ],
      "metadata": {
        "id": "1_m-pTgN9pGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6345a608-4a36-414f-f980-199d39ae1cdd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------\n",
            "threshold =  0.002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Rows: 100%|██████████| 4207/4207 [01:31<00:00, 45.85it/s]\n",
            "Processing Rows: 100%|██████████| 1893/1893 [00:35<00:00, 53.56it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed_time: 127.117s\n",
            "false positive (FP): 3943, false negative (FN): 979, Precision: 49.227%, Recall: 79.613%, F1-measure: 60.837%\n",
            "Finished Predicting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "j0F_RGOHqHBT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in test_normal_loader:\n",
        "  print(line)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC5W-0TiqSRy",
        "outputId": "c44eebd2-f9fb-4302-ee3b-a4bfd27d5b96"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343, 343)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "    k=0\n",
        "    for line in test_normal_loader:\n",
        "        lable = 0\n",
        "        for i in range(len(line) - window_size):\n",
        "            session = line[i:i + window_size]\n",
        "            #print('session : ',session)\n",
        "            seq = [embeddings[temp] for temp in session]\n",
        "\n",
        "            seq = torch.tensor(seq, dtype=torch.float).view(-1, window_size, input_size).to(device)\n",
        "            output = model(seq)\n",
        "            #print('embeddings ',np.array(embeddings).shape)\n",
        "            #print('output ',output.shape)\n",
        "            matrix = cosine_similarity(output.cpu().detach().numpy()[0],np.array(embeddings))\n",
        "            #print('matrix ',matrix.shape)\n",
        "            a = np.argsort(matrix)\n",
        "\n",
        "            s=[]\n",
        "            for i in range(5):\n",
        "              index = np.where(a[i]==session[i])[0][0]\n",
        "              s.append(index)\n",
        "              if index<500:\n",
        "                lable = 1\n",
        "            #print(s)\n",
        "            #break\n",
        "        if lable == 1:\n",
        "          k+=1\n",
        "        #break\n",
        "        #print('==========') #to show this block finished\n",
        "\n",
        "print(k)"
      ],
      "metadata": {
        "id": "cGkx5JDDqGVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOt_RI6Es8SL",
        "outputId": "d7cda531-d545-4677-b5bd-59c0845a74b1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "735"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}